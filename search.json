[{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Code of Conduct - LightLogR","text":"interest fostering open welcoming environment, contributors maintainers pledge make participation project community harassment-free experience everyone, regardless age, body size, disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation.","code":""},{"path":"https://tscnlab.github.io/LightLogR/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Code of Conduct - LightLogR","text":"Examples behaviour contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologising affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behaviour include: use sexualised language imagery, sexual attention advances Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://tscnlab.github.io/LightLogR/CODE_OF_CONDUCT.html","id":"our-responsibilities","dir":"","previous_headings":"","what":"Our Responsibilities","title":"Code of Conduct - LightLogR","text":"Project maintainers responsible clarifying enforcing standards acceptable behaviour take appropriate fair corrective action response instances unacceptable behaviour. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, ban temporarily permanently contributor behaviours deem inappropriate, threatening, offensive, harmful.","code":""},{"path":"https://tscnlab.github.io/LightLogR/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Code of Conduct - LightLogR","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://tscnlab.github.io/LightLogR/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Code of Conduct - LightLogR","text":"Instances abusive, harassing, otherwise unacceptable behaviour may reported community leaders responsible enforcement Technical University Munich. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://tscnlab.github.io/LightLogR/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Code of Conduct - LightLogR","text":"Code Conduct adapted Contributor Covenant, version 1.4 2.0, generated contributing.md.","code":""},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to LightLogR","title":"Contributing to LightLogR","text":"First , thanks taking time contribute! ❤️ types contributions encouraged valued. See Table Contents different ways help details project handles . Please make sure read relevant section making contribution. make lot easier us maintainers smooth experience involved. community looks forward contributions. 🎉 like project, just don’t time contribute, ’s fine. easy ways support project show appreciation, also happy : - Star project - Tweet - Refer project project’s readme publications make use software - Mention project local meetups tell friends/colleagues","code":""},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"table-of-contents","dir":"","previous_headings":"","what":"Table of Contents","title":"Contributing to LightLogR","text":"Code Conduct Question light logger, dosimeter, wearable device supported LightLogR want News LightLogR Want Contribute Reporting Bugs Suggesting Enhancements First Code Contribution Improving Documentation Styleguides Commit Messages Join Project Team","code":""},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to LightLogR","text":"project everyone participating governed LightLogR Code Conduct. participating, expected uphold code. Please report unacceptable behavior lead developer.","code":""},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"i-have-a-question","dir":"","previous_headings":"","what":"I Have a Question","title":"Contributing to LightLogR","text":"want ask question, assume read available Documentation. ask question, best search existing Issues might help . case found suitable issue still need clarification, can write question issue. also advisable search internet answers first. still feel need ask question need clarification, recommend following: Open Issue. Provide much context can ’re running . Provide project platform versions, depending seems relevant. take care issue soon possible.","code":""},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"why-is-my-light-logger-dosimeter-or-other-wearable-device-not-supported-by-lightlogr","dir":"","previous_headings":"","what":"Why is my light logger, dosimeter, or other wearable device not supported by LightLogR","title":"Contributing to LightLogR","text":"using device currently supported, please contact us. can find list supported devices LightLogR documentation imports. always looking expand range supported devices. easiest trackable way get contact opening new issue Github repository. Please also provide sample file data, can test import function.","code":""},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"i-want-news-about-lightlogr","dir":"","previous_headings":"","what":"I want News about LightLogR","title":"Contributing to LightLogR","text":"interested project want know , can subscribe LightLogR mailing list","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"legal-notice","dir":"","previous_headings":"I Want To Contribute","what":"Legal Notice","title":"Contributing to LightLogR","text":"contributing project, must agree authored 100% content, necessary rights content content contribute may provided project licence.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"before-submitting-a-bug-report","dir":"","previous_headings":"I Want To Contribute > Reporting Bugs","what":"Before Submitting a Bug Report","title":"Contributing to LightLogR","text":"good bug report shouldn’t leave others needing chase information. Therefore, ask investigate carefully, collect information describe issue detail report. Please complete following steps advance help us fix potential bug fast possible. Make sure using latest version. Determine bug really bug error side e.g. using incompatible environment components/versions (Make sure read documentation. looking support, might want check section). see users experienced (potentially already solved) issue , check already bug report existing bug error bug tracker. Also make sure search internet (including Stack Overflow) see users outside GitHub community discussed issue. Collect information bug: Stack trace (Traceback) OS, Platform Version (Windows, Linux, macOS, x86, ARM) Version LightLogR Possibly input output Can reliably reproduce issue? can also reproduce older versions?","code":""},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"how-do-i-submit-a-good-bug-report","dir":"","previous_headings":"I Want To Contribute > Reporting Bugs","what":"How Do I Submit a Good Bug Report?","title":"Contributing to LightLogR","text":"must never report security related issues, vulnerabilities bugs including sensitive information issue tracker, elsewhere public. Instead sensitive bugs must sent email lead developer. use GitHub issues track bugs errors. run issue project: Open Issue. issue template bugs can use opening new issue. Explain behavior expect actual behavior. Please provide much context possible describe reproduction steps someone else can follow recreate issue . usually includes code. good bug reports isolate problem create reduced test case. Provide information collected previous section. ’s filed: project team label issue accordingly. team member try reproduce issue provided steps. reproduction steps obvious way reproduce issue, team ask steps mark issue needs-repro. Bugs needs-repro tag addressed reproduced. team able reproduce issue, marked needs-fix, well possibly tags (critical), issue left implemented someone.","code":""},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"suggesting-enhancements","dir":"","previous_headings":"I Want To Contribute","what":"Suggesting Enhancements","title":"Contributing to LightLogR","text":"section guides submitting enhancement suggestion LightLogR, including completely new features minor improvements existing functionality. Following guidelines help maintainers community understand suggestion find related suggestions.","code":""},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"before-submitting-an-enhancement","dir":"","previous_headings":"I Want To Contribute > Suggesting Enhancements","what":"Before Submitting an Enhancement","title":"Contributing to LightLogR","text":"Make sure using latest version. Read documentation carefully find functionality already covered, maybe individual configuration. Perform search see enhancement already suggested. , add comment existing issue instead opening new one. Find whether idea fits scope aims project. ’s make strong case convince project’s developers merits feature. Keep mind want features useful majority users just small subset. ’re just targeting minority users, consider writing add-/plugin library.","code":""},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"how-do-i-submit-a-good-enhancement-suggestion","dir":"","previous_headings":"I Want To Contribute > Suggesting Enhancements","what":"How Do I Submit a Good Enhancement Suggestion?","title":"Contributing to LightLogR","text":"Enhancement suggestions tracked GitHub issues. issue template enhancement suggestions can use opening new issue. Use clear descriptive title issue identify suggestion. Provide step--step description suggested enhancement many details possible. Describe current behavior explain behavior expected see instead . point can also tell alternatives work . may want include screenshots screen recordings help demonstrate steps point part suggestion related . can use LICEcap record GIFs macOS Windows, built-screen recorder GNOME SimpleScreenRecorder Linux. Explain enhancement useful LightLogR users. may also want point projects solved better serve inspiration.","code":""},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"your-first-code-contribution","dir":"","previous_headings":"I Want To Contribute","what":"Your First Code Contribution","title":"Contributing to LightLogR","text":"LightLogR written R, using devtools package. using RStudio IDE Posit, feel free use different IDE. can suggest changes additions code via pull requests. Pull requests reviewed approved least one reviewer, can merged main project branch. Please use main branch basis pull requests.","code":""},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"I Want To Contribute > Your First Code Contribution","what":"Pull request process","title":"Contributing to LightLogR","text":"recommend create Git branch pull request (PR). New code follow tidyverse style guide. can use styler package apply styles, please don’t restyle code nothing PR. use roxygen2, Markdown syntax, documentation. use testthat. Contributions test cases included easier accept. user-facing changes, add bullet top NEWS.md current development version header describing changes made followed GitHub username, links relevant issue(s)/PR(s).","code":""},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"I Want To Contribute > Your First Code Contribution","what":"Fixing typos","title":"Contributing to LightLogR","text":"Small typos grammatical errors documentation may edited directly using GitHub web interface, long changes made source file. YES: edit roxygen comment .R file R/. : edit .Rd file man/.","code":""},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"prerequisites","dir":"","previous_headings":"I Want To Contribute > Your First Code Contribution","what":"Prerequisites","title":"Contributing to LightLogR","text":"make substantial pull request, always file issue make sure someone team agrees ’s problem. ’ve found bug, create associated issue illustrate bug minimal reprex.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"commit-messages","dir":"","previous_headings":"Styleguides","what":"Commit Messages","title":"Contributing to LightLogR","text":"Commits contain small changes can judged . .e., approval commit depend yet written code functionality. Commit messages state changes necessary/helpful, , changes complex, accomplish.","code":""},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"join-the-project-team","dir":"","previous_headings":"","what":"Join The Project Team","title":"Contributing to LightLogR","text":"can join project team simply contributing package. can take form new improved functions, documentation, unit tests. eager join unsure , contact lead developer.","code":""},{"path":"https://tscnlab.github.io/LightLogR/CONTRIBUTING.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributing to LightLogR","text":"guide based contributing.md! Parts guide taken pkgdown contributing.md.","code":""},{"path":"https://tscnlab.github.io/LightLogR/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 LightLogR authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/articles/Day.html","id":"importing-data","dir":"Articles","previous_headings":"","what":"Importing Data","title":"The whole game","text":"data need part LightLogR package. unprocessed (device export) data light loggers (diary app capturing sleep times). data anonymous, can access following paths:","code":"path <- system.file(\"extdata\",                package = \"LightLogR\")  file.LL <- \"205_actlumus_Log_1020_20230904101707532.txt.zip\" file.env <- \"cyepiamb_CW35_Log_1431_20230904081953614.txt.zip\" file.sleep <- \"205_sleepdiary_all_20230904.csv\""},{"path":"https://tscnlab.github.io/LightLogR/articles/Day.html","id":"participant-light-logger-data","dir":"Articles","previous_headings":"Importing Data","what":"Participant Light Logger Data","title":"The whole game","text":"LightLogR provides convenient import functions range supported devices (use command supported_devices() want see devices supported present). LightLogR knows files devices structured, needs little input. fact, mere filepath suffice. , however, good idea also provide timezone argument tz specify measurements made Europe/Berlin timezone. makes data future-proof used comparison geolocations. Every light logger dataset needs Id connect separate observations different participant/device/study/etc. don´t provide Id import function (dataset doesn´t contain Id column), filename used Id. rather cumbersome case, use regex extract first three digits filename, serve purpose .  can see, import accompanied (hopefully) helpful message imported data. contains number ob measurements, timezone, start- enddate, timespan, observation intervals. case, measurements follow 10 second epoch. also get plotted overview data. case, particularly helpful, quickly helps assess different datasets compare one another timeline. deactivate plot setting auto.plot = FALSE import, create separately gg_overview() function. missing values deal first, dataset already good go. , e.g., want know range melanopic EDI (measure stimulus strength nonvisual system) every day dataset, can : goes visualization - always helpful get good look data immediately import. gg_day() function creates simple ggplot data, stacked vertically Days. function needs little input beyond dataset (fact, even work without size input, just makes default point size smaller, interactive command sends output plotly facilitate data exploration). gg_day() features lot flexibility, can adapted extended fit various needs, see shortly. can already see patterns features luminous exposure across days. general, participant seems woken (least started wearing light logger) 9:00 went bed (, , stopped wearing device) around 23:00.","code":"tz <- \"Europe/Berlin\" dataset.LL <- import$ActLumus(file.LL, path, auto.id = \"^(\\\\d{3})\", tz = tz) #>  #> Successfully read in 61'016 observations across 1 Ids from 1 ActLumus-file(s). #> Timezone set is Europe/Berlin. #> The system timezone is UTC. Please correct if necessary! #>  #> First Observation: 2023-08-28 08:47:54 #> Last Observation: 2023-09-04 10:17:04 #> Timespan: 7.1 days #>  #> Observation intervals:  #>   Id    interval.time     n pct   #> 1 205   10s           61015 100% dataset.LL |>    group_by(Date = as_date(Datetime)) |>    summarize(     range.MEDI = range(MEDI) |> str_flatten(\" - \")     ) |>    gt() dataset.LL |> gg_day(size = 0.25, interactive = TRUE)"},{"path":"https://tscnlab.github.io/LightLogR/articles/Day.html","id":"environmental-light-data","dir":"Articles","previous_headings":"Importing Data","what":"Environmental Light Data","title":"The whole game","text":"next dataset. one contains measurement data type device, recorded rooftop position unobstructed daylight roughly location participant data. device type , import well. since filename contain participant´s ID time, give manual id: \"CW35\".  can see follow roughly time span, measurement epoch 30 seconds, one odd interval one second shorter.","code":"dataset.env <- import$ActLumus(file.env, path, manual.id = \"CW35\", tz = tz) #>  #> Successfully read in 20'143 observations across 1 Ids from 1 ActLumus-file(s). #> Timezone set is Europe/Berlin. #> The system timezone is UTC. Please correct if necessary! #>  #> First Observation: 2023-08-28 08:28:39 #> Last Observation: 2023-09-04 08:19:38 #> Timespan: 7 days #>  #> Observation intervals:  #>   Id    interval.time     n pct   #> 1 CW35  29s               1 0%    #> 2 CW35  30s           20141 100%"},{"path":"https://tscnlab.github.io/LightLogR/articles/Day.html","id":"participant-sleep-data","dir":"Articles","previous_headings":"Importing Data","what":"Participant Sleep Data","title":"The whole game","text":"last dataset sleep diary contains, among things, column Id column sleep wake (called offset). sleep diaries event datasets can vary widely structure, must manually set arguments. Importantly, need specify Datetimes structured. case, values like 28-08-2023 23:20, give structure dmyHM. need import coherent table contains column Datetime besides column State starts point time. import_Statechanges() facilitates , can provide vector column names form continuous indicator given state - case Sleep. Now imported data, need combine sensibly, get next section.","code":"dataset.sleep <-    import_Statechanges(file.sleep, path,                        Datetime.format = \"dmyHM\",                       State.colnames = c(\"sleep\", \"offset\"),                       State.encoding = c(\"sleep\", \"wake\"),                       Id.colname = record_id,                       sep = \";\",                       dec = \",\",                       tz = tz) #>  #> Successfully read in 14 observations across 1 Ids from 1 Statechanges-file(s). #> Timezone set is Europe/Berlin. #> The system timezone is UTC. Please correct if necessary! #>  #> First Observation: 2023-08-28 23:20:00 #> Last Observation: 2023-09-04 07:25:00 #> Timespan: 6.3 days #>  #> Observation intervals:  #>    Id    interval.time             n pct   #>  1 205   34860s (~9.68 hours)      1 8%    #>  2 205   35520s (~9.87 hours)      1 8%    #>  3 205   35700s (~9.92 hours)      1 8%    #>  4 205   36000s (~10 hours)        1 8%    #>  5 205   36900s (~10.25 hours)     1 8%    #>  6 205   37020s (~10.28 hours)     1 8%    #>  7 205   37920s (~10.53 hours)     1 8%    #>  8 205   45780s (~12.72 hours)     1 8%    #>  9 205   48480s (~13.47 hours)     1 8%    #> 10 205   49200s (~13.67 hours)     1 8%    #> # ℹ 3 more rows  dataset.sleep |>    head() |>    gt()"},{"path":"https://tscnlab.github.io/LightLogR/articles/Day.html","id":"connecting-data","dir":"Articles","previous_headings":"","what":"Connecting Data","title":"The whole game","text":"Connecting data, case, means giving context participant’s luminous exposure data. number hurdles attached connecting time series data, data different sets rarely align perfectly. Often measurements least seconds, even use different measurement epochs. Also, sleep data, time stamps whenever change status. Also - crucial - might missing entries! LightLogR provides helpful functions however, deal topics without resorting rounding averaging data common multiple.","code":""},{"path":"https://tscnlab.github.io/LightLogR/articles/Day.html","id":"solar-potential","dir":"Articles","previous_headings":"Connecting Data","what":"Solar Potential","title":"The whole game","text":"Let us start environmental measurements unobstructed daylight. can seen natural potential luminous exposure thus serve reference participant´s luminous exposure. data2reference() function, create reference. function extraordinarily powerful can create reference tailored light logger data source wanted Reference column (case MEDI column, default), Datetime column, grouping structure (Id) light logger data set. data2reference() can even create reference subset data . example makes possible first (second, etc.) day data reference days. can apply one participant reference participants, even measurements different times. case necessary specify argument across.id = TRUE, want reference Id(“CW35”) applied across Id participant (“205”). sake example, also removed unnecessary data columns, makes code examples simpler. can already see table reference start measurements quite bit higher luminous exposure participant´s light logger. also see reference value applied three participant values. mirrors fact every three measurements taken participant device, one measurement epoch environmental sensor passes. visualize newly reached reference data, can easily extend gg_day() dashed red reference line. Keep mind visualization still exploratory, investing heavily styling.  , warning missing values added. simply due fact every data point x-axis corresponding y-axis-value. two datasets largely align, fringes, especially last day, non-overlap. perform calculations based light logger data reference, keep mind timesteps present give non NA results. basic, graph already shows valuable information potential light stimulus compared actual exposure. morning hours, participant never reached significant light dose, luminous exposure evening regularly par daytime levels, especially 29th. Let us see measurements compare recommendations luminous exposure.","code":"dataset.LL <-    dataset.LL |>      data2reference(Reference.data = dataset.env, across.id = TRUE)  dataset.LL <-    dataset.LL |>      select(Id, Datetime, MEDI, Reference)  dataset.LL |>    head() |>    gt() dataset.LL |>    gg_day(size = 0.25) +    geom_line(aes(y=Reference), lty = 2, col = \"red\") #> Warning: Removed 707 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://tscnlab.github.io/LightLogR/articles/Day.html","id":"recommended-light-levels","dir":"Articles","previous_headings":"Connecting Data","what":"Recommended Light levels","title":"The whole game","text":"Brown et al.(2022)1 provide guidance healthy, daytime dependent light stimuli, measured melanopic EDI: Throughout daytime, recommended minimum melanopic EDI 250 lux eye measured vertical plane approximately 1.2 m height (.e., vertical illuminance eye level seated). available, daylight used first instance meet levels. additional electric lighting required, polychromatic white light ideally spectrum , like natural daylight, enriched shorter wavelengths close peak melanopic action spectrum. evening, starting least 3 hours bedtime, recommended maximum melanopic EDI 10 lux measured eye vertical plane approximately 1.2 m height. help achieve , possible, white light spectrum depleted short wavelengths close peak melanopic action spectrum. sleep environment dark possible. recommended maximum ambient melanopic EDI 1 lux measured eye. case certain activities nighttime require vision, recommended maximum melanopic EDI 10 lux measured eye vertical plane approximately 1.2 m height. can see bedtime important factor determining timepoints three stages go effect. Luckily just happen sleep/wake data sleep diary hand. first step, convert timepoints state changes intervals participant awake asleep. sc2interval() function provides readily. case first entry sleep, can safely assume, day prior participant awake. take account starting.state = \"wake\" argument setting, implied participant awake midnight . first day data partial anyways, disregard . arguments sc2interval() refine interval creation. Probably important length.restriction, sets maximum length interval, default 24 hours. avoids implausibly long intervals one state highly likely caused implicit missing data misentries. Now can transform sleep/wake intervals intervals Brown recommendations. sleep_int2Brown() function facilitates . can see function fit 3 hour interval -every sleep wake phase, also recoded states. data can now applied light logger dataset. done interval2state() function2. already used function unknowingly, (alongside sc2interval()) hood data2reference(), making sure data reference set spread accordingly. Now column light logger dataset declares three state Brown et al. recommendation. another function, Brown2reference(), can one swoop add threshhold accompanied states check whether participant within recommendations . thing function needs name put recommended values - default go Reference, already used Solar exposition, put Reference.Brown. Brown2reference() added four columns, two shown table . third column contains text label type reference, sth. also added solar exposition fourth column contains difference actual mel EDI recommendations. Now let´s quick look result plot overview  Looking good far! next section, let us focus picking one day get styling. Based available data think 01/09 looks promising, variation day timeframes outside afternoon varied typical luminous exposure evening. can use filter_Date() function easily cut specific chunk data. also deactivate facetting function gg_day(), one day.","code":"dataset.sleep <-    dataset.sleep |>    sc2interval()  dataset.sleep |>    head() |>    gt() Brown.intervals <-    dataset.sleep |>    sleep_int2Brown()  Brown.intervals |>    head() |>    gt() dataset.LL <-    dataset.LL |>      interval2state(       State.interval.dataset = Brown.intervals, State.colname = State.Brown       )  dataset.LL |>    tail() |>    gt() dataset.LL <-    dataset.LL |>      Brown2reference(Brown.rec.colname = Reference.Brown)  dataset.LL |>    select(!Reference.Brown.label, !Reference.Brown.difference) |>    tail() |>    gt() dataset.LL |> #dataset   gg_day(size = 0.25) + #base plot   geom_line(aes(y=Reference), lty = 2, col = \"red\") + #solar reference   geom_line(aes(y=Reference.Brown), lty = 2, col = \"blue\") #Brown reference #> Warning: Removed 707 rows containing missing values or values outside the scale range #> (`geom_line()`). #> Warning: Removed 4153 rows containing missing values or values outside the scale range #> (`geom_line()`). dataset.LL.partial <-  dataset.LL |> #dataset   filter_Date(start = \"2023-09-01\", length = days(1)) #use only one day  solar.reference <- geom_line(aes(y=Reference), lty = 2, col = \"red\") #solar reference brown.reference <- geom_line(aes(y=Reference.Brown), lty = 2, col = \"blue\") #Brown reference  dataset.LL.partial  |>    gg_day(size = 0.25, facetting = FALSE, y.scale = symlog_trans()) + #base plot   solar.reference + brown.reference"},{"path":"https://tscnlab.github.io/LightLogR/articles/Day.html","id":"styling-data","dir":"Articles","previous_headings":"","what":"Styling Data","title":"The whole game","text":"Let us finish task exploring styling options graph. built dataset ended last section. use several functions processing steps, noted rarely specify arguments functions. due workflow LightLogR provides start finish. techniques section specific LightLogR, rather show can readily use data processed package work standard plotting function. Firstly, though, let us slightly tweak y-axis.","code":"scale.correction <- coord_cartesian(   xlim = c(0, 24.5*60*60), #make sure the x axis covers 24 hours (+a bit for the label)   expand = FALSE #set the axis limits exactly at ylim and xlim   )"},{"path":"https://tscnlab.github.io/LightLogR/articles/Day.html","id":"participants-luminous-exposure","dir":"Articles","previous_headings":"Styling Data","what":"Participants luminous exposure","title":"The whole game","text":"default, gg_day() uses point geom data display. can, however, play around geoms. geom_point geom_line geom_ribbon geom_boxplot geom_bin2d  standard behavior gg_day(). specify geom = \"point\" case, verbose communicate specify argument.  line geom shows changes luminous exposure bit better might better choice case.  geom_area fills area 0 given value. reason, however, slow unfortunately doesn´t work nicely purely logarithmic plots (10^0 = 1, start 13). can, however, disable geom gg_day() geom = \"blank\" instead add geom_ribbon can force-based zero ymin = 0. Setting geom = \"ribbon\" automatically behind scenes fast.  create boxplot representation, need specify geom also time interval want boxplot span. cut_Datetime() function LightLogR comes rescue. round datetimes desired interval, can specified group argument gg_day(). can nice representation, don´t think fits goal overall figure specific case.  geom family hex, bin2d, density_2d particularly well suited many, possibly overlaying observations. reduces complexity cutting x- y-axis bins counts many observations fall within bin. choosing 24 bins, see dominant values every hour day. jco_color = FALSE argument necessary disable default discrete color scheme gg_day(), continuous scale necessary counts densities. Finally, use aes_fill = stat(count) argument color bins according number observations bin4.","code":"dataset.LL.partial  |>    gg_day(     size = 0.25, geom = \"point\", facetting = FALSE) + #base plot   solar.reference +    brown.reference +    scale.correction dataset.LL.partial  |>    gg_day(     size = 0.25, facetting = FALSE, geom = \"line\") + #base plot   solar.reference +    brown.reference +    scale.correction dataset.LL.partial  |>    gg_day(facetting = FALSE, geom = \"ribbon\", alpha = 0.25, size = 0.25,          fill = \"#EFC000\", color = \"#EFC000\") + #base plot   solar.reference +    brown.reference +    scale.correction dataset.LL.partial  |>    cut_Datetime(unit = \"30 minutes\") |> #provide an interval for the boxplot   gg_day(size = 0.25, facetting = FALSE, geom = \"boxplot\", group = Datetime.rounded) + #base plot   solar.reference +    brown.reference +    scale.correction dataset.LL.partial  |>    gg_day(     size = 0.25, facetting = FALSE, geom = \"bin2d\",      jco_color = FALSE, bins = 24, aes_fill = stat(count)) + #base plot   solar.reference +    brown.reference +    scale.correction"},{"path":"https://tscnlab.github.io/LightLogR/articles/Day.html","id":"section","dir":"Articles","previous_headings":"","what":"The whole game","title":"The whole game","text":"Conclusion: line ribbon geom seem like good choice task. However, high resolution data (10 seconds) makes line noisy. Sometimes level detail good, figure give general representation luminous exposure, aggregate data somewhat. can use similar function boxplot, aggregate_Datetime() use aggregate data desired resolution. sensible defaults handle numeric (mean), logical character (represented) data, can adjusted. sake example, let´s wrap aggregate function additional code recalculate Brown_recommendations, default numeric aggregation fine measurement data, make sense Brown_recommendations column.","code":"aggregate_Datetime2 <- function(...) {   aggregate_Datetime(...) |> #aggregate the data   select(-Reference.Brown) |> #remove the rounded    Brown2reference(Brown.rec.colname = Reference.Brown) #recalculate the brown times     }"},{"path":"https://tscnlab.github.io/LightLogR/articles/Day.html","id":"data-aggregation","dir":"Articles","previous_headings":"Styling Data","what":"Data aggregation","title":"The whole game","text":"new aggregate function, let us taste variants: None 1 Minute 5 Minutes 30 Minutes 1 Hour","code":"dataset.LL.partial  |>    gg_day(facetting = FALSE, geom = \"ribbon\", alpha = 0.25, size = 0.25,          fill = \"#EFC000\", color = \"#EFC000\") + #base plot   solar.reference +     brown.reference +    scale.correction dataset.LL.partial |>    aggregate_Datetime2(unit = \"1 min\")  |>    gg_day(facetting = FALSE, geom = \"ribbon\", alpha = 0.25, size = 0.25,          fill = \"#EFC000\", color = \"#EFC000\") + #base plot   solar.reference +    brown.reference +    scale.correction dataset.LL.partial |>    aggregate_Datetime2(unit = \"5 mins\")  |>    gg_day(facetting = FALSE, geom = \"ribbon\", alpha = 0.25, size = 0.25,          fill = \"#EFC000\", color = \"#EFC000\") + #base plot   solar.reference +    brown.reference +    scale.correction dataset.LL.partial |>    aggregate_Datetime2(unit = \"30 mins\") |>    gg_day(facetting = FALSE, geom = \"ribbon\", alpha = 0.25, size = 0.25,          fill = \"#EFC000\", color = \"#EFC000\") + #base plot   solar.reference +    brown.reference +    scale.correction dataset.LL.partial |>    aggregate_Datetime2(unit = \"1 hour\")  |>    gg_day(facetting = FALSE, geom = \"ribbon\", alpha = 0.25, size = 0.25,          fill = \"#EFC000\", color = \"#EFC000\") + #base plot   solar.reference +    brown.reference +    scale.correction"},{"path":"https://tscnlab.github.io/LightLogR/articles/Day.html","id":"section-1","dir":"Articles","previous_headings":"","what":"The whole game","title":"The whole game","text":"Conclusion: 1 minute aggregate still pretty noisy, whereas 30 minutes 1 hour steps rough. 5 Minutes seem good balance.","code":"Plot <-  dataset.LL.partial |>    aggregate_Datetime2(unit = \"5 mins\")  |>    gg_day(facetting = FALSE, geom = \"ribbon\", alpha = 0.25, size = 0.25,          fill = \"#EFC000\", color = \"#EFC000\") + #base plot   brown.reference +    scale.correction"},{"path":"https://tscnlab.github.io/LightLogR/articles/Day.html","id":"solar-potential-1","dir":"Articles","previous_headings":"Styling Data","what":"Solar Potential","title":"The whole game","text":"Let us focus next solar potential harnessed participant. several choices represent . geom_line geom_ribbon second plot  base representation solar exposure. bad one . Let’s keep run know.  ribbon shows missed - night exceeded - potential due daylight.  plot requires bit preparation, focuses nicely unrealized daylight potential. reasons clarity, line color Brown recommendation changed blue red.","code":"Plot +    geom_line(aes(y=Reference), lty = 2, col = \"red\") #solar reference Plot +    geom_ribbon(aes(ymin = MEDI, ymax=Reference), alpha = 0.25, fill = \"#0073C2FF\") #solar reference #Note: This will become a function of its own in LightLogR at some point in the future  Plot_upper <-  dataset.LL.partial |>    aggregate_Datetime2(unit = \"5 mins\") |>    gg_day(facetting = FALSE, geom = \"ribbon\", alpha = 0.25, size = 0.4,          fill = \"#EFC000\", color = \"#EFC000\") + #base plot   geom_line(aes(y=Reference.Brown), lty = 2, col = \"red\") + #Brown reference   geom_line(aes(y=Reference), col = \"#0073C2FF\", size = 0.4) + #solar reference   labs(x = NULL) +  #remove the x-axis label   scale.correction  Plot_lower <-  dataset.LL.partial |>    aggregate_Datetime2(unit = \"5 mins\") |>    gg_day(facetting = FALSE, geom = \"blank\", y.axis.label = \"unrealized Potential\") + #base plot   geom_area(     aes(y = Reference - MEDI,          group = consecutive_id((Reference - MEDI) >= 0),          fill = (Reference - MEDI) >= 0,          col = (Reference - MEDI) >= 0),      alpha = 0.25, outline.type = \"upper\") +    guides(fill = \"none\", col = \"none\") +    geom_hline(aes(yintercept = 0), lty = 2) +      scale_fill_manual(values = c(\"#EFC000\", \"#0073C2\")) +      scale_color_manual(values = c(\"#EFC000\", \"#0073C2\")) +    scale.correction #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale. #> Scale for colour is already present. #> Adding another scale for colour, which will replace the existing scale.  Plot_upper / Plot_lower #set up the two plots"},{"path":"https://tscnlab.github.io/LightLogR/articles/Day.html","id":"section-2","dir":"Articles","previous_headings":"","what":"The whole game","title":"The whole game","text":"Conclusion: second plot option nice, focuses one aspect - missed unrealized potential. geom_ribbon variant still includes information, general, exactly want .","code":"Day.end <- as_datetime(\"2023-09-01 23:59:59\", tz = tz) Plot <-  dataset.LL.partial |>    aggregate_Datetime2(unit = \"5 mins\") |>    filter_Datetime(end = Day.end) |>    gg_day(facetting = FALSE, geom = \"blank\", y.axis.breaks = c(0, 10^(0:5), 250)) + #base plot     geom_ribbon(aes(ymin = MEDI, ymax=Reference),                alpha = 0.25, fill = \"#0073C2FF\",               outline.type = \"upper\", col = \"#0073C2FF\", size = 0.15) + #solar reference   geom_ribbon(aes(ymin = 0, ymax = MEDI), alpha = 0.30, fill = \"#EFC000\",                outline.type = \"upper\", col = \"#EFC000\", size = 0.4) + #ribbon geom   scale.correction"},{"path":"https://tscnlab.github.io/LightLogR/articles/Day.html","id":"brown-recommendations","dir":"Articles","previous_headings":"Styling Data","what":"Brown Recommendations","title":"The whole game","text":"Brown recommendations add layer complexity, specify threshold reached exceeded, depending time day. can tackle aspect several ways. case, y-axis reflect datime threshhold value 250 lx. already considered y.axis.breaks argument code chunk . geom_line geom_rect geom_point  variant representation used throught document. Since luminous exposure daylight levels distinct terms color, however, line stay black.   geom_area function can draw target areas values.  approach uses conditional coloration points, depending whether personal luminous exposure within recommended limits.","code":"Plot +    geom_line(aes(y=Reference.Brown), lty = 2, size = 0.4, col = \"grey15\") #Brown reference #This section will be integrated into a LightLogR function in the future Day.start <- as_datetime(\"2023-09-01 00:00:00\", tz = tz) Day.end <- as_datetime(\"2023-09-01 23:59:59\", tz = tz) Interval <- lubridate::interval(start = Day.start, end = Day.end, tzone = tz) Brown.times <-    Brown.intervals |>    filter(Interval |> int_overlaps(.env$Interval)) |>    mutate(ymin = case_match(State.Brown,                            \"night\"  ~ 0,                            \"day\" ~ 250,                            \"evening\" ~ 0),          ymax = case_match(State.Brown,                            \"night\"  ~ 1,                            \"day\" ~ Inf,                            \"evening\" ~ 10),          xmin = int_start(Interval),          xmax = int_end(Interval),          xmin = if_else(xmin < Day.start, Day.start, xmin)  |> hms::as_hms(),          xmax = if_else(xmax > Day.end, Day.end, xmax) |> hms::as_hms()          )  recommendations <-    geom_rect(     data = Brown.times,      aes(xmin= xmin, xmax = xmax, ymin = ymin, ymax = ymax),      inherit.aes = FALSE,     alpha = 0.15,     fill = \"grey35\")  Plot2 <- Plot Plot2$layers <- c(recommendations, Plot2$layers) Plot2 Plot2+geom_line(aes(y=Reference.Brown), lty = 2, size = 0.4, col = \"grey35\") Plot +    geom_point(aes(col = Reference.Brown.check), size = 0.5)+   geom_line(aes(y=Reference.Brown), lty = 2, size = 0.4, col = \"grey60\") + #Brown reference   scale_color_manual(values = c(\"grey50\", \"#EFC000\"))+   guides(color = \"none\") #> Scale for colour is already present. #> Adding another scale for colour, which will replace the existing scale."},{"path":"https://tscnlab.github.io/LightLogR/articles/Day.html","id":"section-3","dir":"Articles","previous_headings":"","what":"The whole game","title":"The whole game","text":"Conclusion: geom_point solution combines lot information designwise slim figure uses two colors (+grey) get many points across.","code":"Plot <-  Plot +    geom_point(aes(col = Reference.Brown.check), size = 0.5)+   geom_line(aes(y=Reference.Brown,                  # group = consecutive_id(State.Brown)                 ),              col = \"grey40\",             lty = 2, size = 0.4) + #Brown reference   scale_color_manual(values = c(\"grey50\", \"#EFC000\"))+   guides(color = \"none\")"},{"path":"https://tscnlab.github.io/LightLogR/articles/Day.html","id":"final-touches","dir":"Articles","previous_headings":"Styling Data","what":"Final Touches","title":"The whole game","text":"figure needs final touches can use , namely labels. Automatic guides labels work well use color palettes. , mostly specified coloring . Thus disabled automatic guides. Instead solve trough annotations.  concludes task. gone importing multiple source files final figure ready used publication. LightLogR facilitated importing processing steps also enabled us test various decisions, like choice geom time.aggregation.","code":"x <- 900  Brown.times <-    Brown.times |>    mutate(xmean = (xmax - xmin)/2 + xmin,          label.Brown = case_match(State.Brown,                                   \"night\" ~ \"sleep\",                                   \"evening\" ~ \"pre-bed\",                                   .default = State.Brown))  Plot +    # geom_vline(data = Brown.times[-1,],   #            aes(xintercept = xmin), lty = 2, col = \"grey40\", size = 0.4) + #adding vertical lines   geom_label(data = Brown.times[-4,],               aes(x = xmean, y = 0.3, label = label.Brown),               col = \"grey40\", alpha = 0.75) + #adding labels   annotate(\"rect\", fill = \"white\", xmin = 0, xmax = 7.5*60*60,             ymin = 2500, ymax = 60000)+   annotate(\"text\", x=x, y = 1.7, label = \"Brown et al. (2022)\",             hjust = 0, col = \"grey25\")+   annotate(\"text\", x=x, y = 40000, label = \"- Exposure within\",             hjust = 0, col = \"#EFC000\")+   annotate(\"text\", x=x, y = 19500, label = \"  recommended levels or\",             hjust = 0, col = \"black\")+   annotate(\"text\", x=x, y = 10000, label = \"  outside\",             hjust = 0, col = \"grey50\")+   annotate(\"text\", x=x, y = 4000, label = \"- Daylight Potential\",             hjust = 0, col = \"#0073C2DD\") #create folder images if necessary if (!dir.exists(\"images\")) dir.create(\"images\") #save image ggplot2::ggsave(\"images/Day.png\", width = 7, height = 4, dpi = 600)"},{"path":"https://tscnlab.github.io/LightLogR/articles/Import.html","id":"from-which-devices-can-i-import-data","dir":"Articles","previous_headings":"","what":"From which devices can I import data?","title":"Import & cleaning","text":"LightLogR aims provide standard import routines devices used research personal light exposure. Currently, following devices supported: Information devices can found reference import_Dataset().","code":"supported_devices() #>  [1] \"Actiwatch_Spectrum\"    \"Actiwatch_Spectrum_de\" \"ActLumus\"              #>  [4] \"ActTrust\"              \"Circadian_Eye\"         \"Clouclip\"              #>  [7] \"DeLux\"                 \"GENEActiv_GGIR\"        \"Kronowise\"             #> [10] \"LiDo\"                  \"LightWatcher\"          \"LIMO\"                  #> [13] \"LYS\"                   \"MotionWatch8\"          \"nanoLambda\"            #> [16] \"OcuWEAR\"               \"Speccy\"                \"SpectraWear\"           #> [19] \"VEET\""},{"path":"https://tscnlab.github.io/LightLogR/articles/Import.html","id":"what-if-my-device-is-not-listed","dir":"Articles","previous_headings":"From which devices can I import data?","what":"What if my device is not listed?","title":"Import & cleaning","text":"using device currently supported, please contact developers. always looking expand range supported devices. easiest trackable way get contact opening new issue Github repository. Please see CONTRIBUTING section different ways help details project handles .","code":""},{"path":"https://tscnlab.github.io/LightLogR/articles/Import.html","id":"what-if-my-device-is-listed-but-the-import-does-not-work-as-expected","dir":"Articles","previous_headings":"From which devices can I import data?","what":"What if my device is listed but the import does not work as expected?","title":"Import & cleaning","text":"regularly find files exported device model can differ structure. may due different settings, software hardware updates. encounter problems import, please get contact us, e.g. opening issue Github repository. Please see CONTRIBUTING section different ways help details project handles .","code":""},{"path":"https://tscnlab.github.io/LightLogR/articles/Import.html","id":"are-there-other-ways-to-import-data","dir":"Articles","previous_headings":"From which devices can I import data?","what":"Are there other ways to import data?","title":"Import & cleaning","text":"Yes. LightLogR simply requires data.frame column containing datetime formatted data. Even light data column strictly necessary, LightLogR optimized , restricted , light data. , Id column used functions distinguish different participants. make life easier using functions LightLogR, datetime column named Datetime, id column Id, , present, melanopic EDI light information MEDI. Lastly, can modify add import functions build upon LightLogRs import functionality. See last chapter article information .","code":""},{"path":"https://tscnlab.github.io/LightLogR/articles/Import.html","id":"importing-data","dir":"Articles","previous_headings":"","what":"Importing data","title":"Import & cleaning","text":"first step every analysis data import. work data collected part Master Thesis Insights real-world human light exposure: relating self-report eye-level light logging Carolina Guidolin (2023). data stored 17 text files data/ folder. can access data LightLogR GitHub repository. Next require time zone data collection. uncertain time zones valid, use OlsonNames() function. data collected “Europe/Berlin” time zone. Lastly, participant Ids stored file names. extract store column called Id. following code defines pattern regular expression, extract first three digits file name. Now can import data. Data collected ActLumus device Condor Instruments. right way specify import function.","code":"#this assumes that you downloaded the files into a folder called \"data\" in the working directory path <- \"data\" files <- list.files(path, full.names = TRUE) #show how many files are listes length(files) #> [1] 17 #first six time zones from OlsonNames() head(OlsonNames()) #> [1] \"Africa/Abidjan\"     \"Africa/Accra\"       \"Africa/Addis_Ababa\" #> [4] \"Africa/Algiers\"     \"Africa/Asmara\"      \"Africa/Asmera\"  #our time zone tz <- \"Europe/Berlin\" pattern <- \"^(\\\\d{3})\" data <- import$ActLumus(files, tz = tz, auto.id = pattern, print_n=33) #>  #> Successfully read in 1'034'650 observations across 17 Ids from 17 ActLumus-file(s). #> Timezone set is Europe/Berlin. #> The system timezone is UTC. Please correct if necessary! #> Observations in the following 2 file(s) and 2 Id(s) cross to or from daylight savings time (DST):  #> File: 221_actlumus_Log_1607_20231030121531432, Group:221 #> File: 222_actlumus_Log_1020_20231030140039534, Group:222 #> Please make sure that the timestamps in the source files correctly reflect these changes from DST<>ST.  #> To adjust datetimes after a jump, set `dst_adjustment = TRUE` or see `?dst_change_handler` for manual adjustment. #>  #> First Observation: 2023-08-14 10:55:21 #> Last Observation: 2023-10-30 15:00:32 #> Timespan: 77 days #>  #> Observation intervals:  #>    Id    interval.time              n pct   #>  1 201   10s                    60042 100%  #>  2 202   10s                    59957 100%  #>  3 204   10s                    61980 100%  #>  4 205   10s                    61015 100%  #>  5 206   10s                    60691 100%  #>  6 206   23s                        1 0%    #>  7 206   59575s (~16.55 hours)      1 0%    #>  8 208   10s                    59853 100%  #>  9 209   10s                    60084 100%  #> 10 210   10s                    60701 100%  #> 11 212   10s                    59478 100%  #> 12 213   10s                    59720 100%  #> 13 214   10s                    61836 100%  #> 14 214   16s                        1 0%    #> 15 214   1197207s (~1.98 weeks)     1 0%    #> 16 215   7s                         1 0%    #> 17 215   10s                    60707 100%  #> 18 216   10s                    61760 100%  #> 19 216   19s                        1 0%    #> 20 216   240718s (~2.79 days)       1 0%    #> 21 218   8s                         1 0%    #> 22 218   10s                    60929 100%  #> 23 218   11s                        1 0%    #> 24 219   9s                         1 0%    #> 25 219   10s                    61634 100%  #> 26 219   16s                        1 0%    #> 27 219   583386s (~6.75 days)       1 0%    #> 28 221   9s                         1 0%    #> 29 221   10s                    62340 100%  #> 30 221   19s                        1 0%    #> 31 221   3610s (~1 hours)           1 0%    #> 32 222   10s                    61890 100%  #> 33 222   3610s (~1 hours)           1 0%"},{"path":"https://tscnlab.github.io/LightLogR/articles/Import.html","id":"my-import-is-slow--why-is-that-and-can-i-speed-it-up","dir":"Articles","previous_headings":"Importing data","what":"My import is slow. Why is that and can I speed it up?","title":"Import & cleaning","text":"several possibilities, import slow. common reasons : data files simply large. short measurement intervals, many participants, long measurement periods, files single study can easily reach several gigabytes. takes time import ok. data files contain many gaps. import, LightLogR checks visualizes gaps data. Especially large datasets small intervals contain many gaps, can slow import process. device model importing non-consistent data structures. devices varying number rows actual data starts. means small portion every file read correct starting row found. can slow import process many files. experiencing slow imports, can try following: read part datasets, split dataset several pieces, gets loaded separately. can combine afterwards join_datasets(). many gaps data, can set auto.plot = FALSE import function. eliminate call gg_overview(), calculates visualizes gaps data.","code":""},{"path":"https://tscnlab.github.io/LightLogR/articles/Import.html","id":"finding-and-handling-gaps-and-irregular-data","dir":"Articles","previous_headings":"","what":"Finding and handling gaps and irregular data","title":"Import & cleaning","text":"can dive analysis part, need make sure clean dataset. import summary shows us two problems data: two files data crosses daylight saving time (DST) changes. ActLumus device adjust DST, need correct . Multiple Ids single datapoints beginning dataset gaps actual data collection starts. test measurements check equipment, must removed dataset. Let us first deal DST change. LightLogR -built function correct import. thus re-import data, make import silent clutter output. second problem requires filtering certain Ids. filter_Datetime_multiple() function ideal . can provide length (1 week), starting end data collection backwards. variable arguments provide variable arguments filter function, provided list form expressions quoted throughquote(). Fixed arguments, like length andlength_from_start\\ provided named arguments specified , Ids. Let’s look data gg_overview() function.  Looks much better now. Also, longer hint gaps lower right corner, can sure gaps removed. function has_irregulars() shows us, however, still irregularities data function gap_table() reveals . irregular data dataset can problematic, messes many functions require constant spacing observations. Also, can seriously slow computational performance. Let us first check irregular data happen, function gap_table(). important set include.implicit.gaps = FALSE, computationally costly means look take care irregularities Ids 215, 218, 221. Let us first visualize irregularities . can use gg_gaps() . use include.implicit.gaps = FALSE save computational cost, also group..days = TRUE, wich give us results day.  first instances seem fine, right start data appear shifted. first half day missing anyways, likely day using. also case participants, anyways, can show selecting sample extract gaps .  can remove partial days via remove_partial_data(). want make sure apply filter .date, otherwise outright remove participants, want simply remove single days. remove days can check days going removed. 34 days removed. 17 participants, equals first last day data collection, correctly identified partly available. data now clean can proceed analysis. dataset needed articles, save RDS file.","code":"data <-    import$ActLumus(files, tz = tz, auto.id = pattern, dst_adjustment = TRUE, silent = TRUE) data <-    data |>    filter_Datetime_multiple(     arguments = list(       list(only_Id = quote(Id == 216)),       list(only_Id = quote(Id == 219)),       list(only_Id = quote(Id == 214)),       list(only_Id = quote(Id == 206))     ),      length = \"1 week\", length_from_start = FALSE) data |> gg_overview() data |>    has_irregulars() #> [1] TRUE data |>    gap_table(include.implicit.gaps = FALSE) #> Warning: There are implicit gaps in the dataset that will not be part of the #> extracted summary, due to `include.implicit.gaps = FALSE`. #> No gaps found data |> gg_gaps(include.implicit.gaps = FALSE, group.by.days = TRUE, show.irregulars = TRUE) data |>    filter(Id %in% 208:210) |>    gg_gaps(MEDI, x.axis.format = \"%a\") #> Warning: Removed 8386 rows containing missing values or values outside the scale range #> (`geom_line()`). data |>    filter(Id %in% 208:210) |>    extract_gaps() #> # A tibble: 6 × 6 #> # Groups:   Id [3] #>   Id    gap.id epoch start               end                 #>   <fct>  <int> <dbl> <dttm>              <dttm>              #> 1 208        1    10 2023-09-04 00:00:04 2023-09-04 11:01:44 #> 2 208        2    10 2023-09-11 09:17:24 2023-09-12 00:00:04 #> 3 209        1    10 2023-09-03 23:59:57 2023-09-04 11:03:17 #> 4 209        2    10 2023-09-11 09:57:27 2023-09-11 23:59:57 #> 5 210        1    10 2023-09-04 00:00:00 2023-09-04 11:07:00 #> 6 210        2    10 2023-09-11 11:44:00 2023-09-12 00:00:00 #> # ℹ 1 more variable: duration <Duration> data |>    remove_partial_data(     handle.gaps = TRUE, MEDI, by.date = TRUE, threshold.missing = \"2 hours\",     show.result = TRUE     ) |>    filter(marked.for.removal) #> # A tibble: 34 × 9 #> # Groups:   Id, .date [34] #>    marked.for.removal Id    .date      duration              #>    <lgl>              <fct> <date>     <Duration>            #>  1 TRUE               201   2023-08-14 47080s (~13.08 hours) #>  2 TRUE               201   2023-08-21 34950s (~9.71 hours)  #>  3 TRUE               202   2023-08-14 46970s (~13.05 hours) #>  4 TRUE               202   2023-08-21 34210s (~9.5 hours)   #>  5 TRUE               204   2023-08-14 45030s (~12.51 hours) #>  6 TRUE               204   2023-08-21 56380s (~15.66 hours) #>  7 TRUE               205   2023-08-28 54730s (~15.2 hours)  #>  8 TRUE               205   2023-09-04 37030s (~10.29 hours) #>  9 TRUE               206   2023-08-28 51680s (~14.36 hours) #> 10 TRUE               206   2023-09-04 34720s (~9.64 hours)  #> # ℹ 24 more rows #> # ℹ 5 more variables: missing <Duration>, total <Duration>, missing_pct <dbl>, #> #   threshold <Duration>, interval <Duration>  data <-    data |>      remove_partial_data(       handle.gaps = TRUE, MEDI, by.date = TRUE, threshold.missing = \"2 hours\"       ) data |> has_gaps() #> [1] FALSE data |> has_irregulars() #> [1] FALSE # uncomment next lines to save the data # if (!dir.exists(\"cleaned_data\")) dir.create(\"cleaned_data\") # saveRDS(data, \"cleaned_data/ll_data.rds\")"},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/articles/Import.html","id":"other-import-arguments","dir":"Articles","previous_headings":"Importing data: Miscellaneous","what":"Other import arguments","title":"Import & cleaning","text":"potentially important arguments locale argument - useful special characters data (e.g. German ü ä) recognized default locale. Look readr::default_locale() information. ... argument passed whichever import function used data. devices, also used provide additional information, column_names Actiwatch devices, differ depending language setting device software. Whether device requires additional information can found import documentation (see import_Dataset()).","code":""},{"path":"https://tscnlab.github.io/LightLogR/articles/Import.html","id":"other-ways-to-call-import","dir":"Articles","previous_headings":"Importing data: Miscellaneous","what":"Other ways to call import","title":"Import & cleaning","text":"Instead using import function described (import$device()), can also use function import_Dataset() specify device character string first argument. might useful want import data programmatically different devices, e.g., purrr::map() function. supported_devices() accepted function. example: way, end list two dataframes, one ActLumus data one Speccy data.","code":"devices <- c(\"ActLumus\", \"Speccy\") files_AL <- c(\"path/to/ActLumus/file1.csv\", \"path/to/ActLumus/file2.csv\") files_Sy <- c(\"path/to/Speccy/file1.csv\", \"path/to/Speccy/file2.csv\") tz <- \"Europe/Berlin\"  data <- purrr::map2(devices, list(files_AL, files_Sy), import_Dataset, tz = tz)"},{"path":"https://tscnlab.github.io/LightLogR/articles/Import.html","id":"creating-your-own-import-function","dir":"Articles","previous_headings":"Importing data: Miscellaneous","what":"Creating your own import function","title":"Import & cleaning","text":"Note: section advanced users . familiar expressions R manipulate . LightLogR comes number custom import routines different devices, implemented main import function, covers general aspects also creates summary overview. like write custom import function, LightLogR covered. First, can see makes import functions tick looking included data set ll_import_expr(). list individual routines. Let’s look ActLumus routine can see, rather simple, just lines code. can write expression create import function . expression create data variable contains import script files. end expression, data variable contain imported dataset include correctly formatted Datetime column, complete correct timezone. create variation old routine, just adds short message: can now create new import function expression. function called import$ActLumus_new(). Let us now import file previous dataset, setting main summary plotting function silent","code":"ll_import_expr()$ActLumus #> { #>     data <- suppressMessages(readr::read_delim(filename, skip = 32,  #>         delim = \";\", n_max = n_max, col_types = paste0(\"c\", paste0(rep(\"d\",  #>             32), collapse = \"\")), id = \"file.name\", locale = locale,  #>         name_repair = \"universal\", ...)) #>     data <- data %>% dplyr::rename(Datetime = DATE.TIME, MEDI = MELANOPIC.EDI) %>%  #>         dplyr::mutate(Datetime = Datetime %>% lubridate::dmy_hms(tz = tz)) #> } new_import_expr <- ll_import_expr() new_import_expr$ActLumus_new <- new_import_expr$ActLumus new_import_expr$ActLumus_new[[4]] <-    rlang::expr({ cat(\"**Congratulation, you made a new import function**\\n\")   data   }) new_import_expr$ActLumus_new #> { #>     data <- suppressMessages(readr::read_delim(filename, skip = 32,  #>         delim = \";\", n_max = n_max, col_types = paste0(\"c\", paste0(rep(\"d\",  #>             32), collapse = \"\")), id = \"file.name\", locale = locale,  #>         name_repair = \"universal\", ...)) #>     data <- data %>% dplyr::rename(Datetime = DATE.TIME, MEDI = MELANOPIC.EDI) %>%  #>         dplyr::mutate(Datetime = Datetime %>% lubridate::dmy_hms(tz = tz)) #>     { #>         cat(\"**Congratulation, you made a new import function**\\n\") #>         data #>     } #> } import <- import_adjustment(new_import_expr) data <- import$ActLumus_new(files[1], tz = tz, auto.id = pattern,                           auto.plot = FALSE, silent = TRUE) #> **Congratulation, you made a new import function**"},{"path":"https://tscnlab.github.io/LightLogR/articles/Metrics.html","id":"importing-data","dir":"Articles","previous_headings":"","what":"Importing Data","title":"Metrics","text":"use data imported cleaned already article Import & Cleaning. can seen using gg_overview(), dataset contains 17 ids one weeks worth data , one three participants per week.","code":"#this assumes the data is in the cleaned_data folder in the working directory data <- readRDS(\"cleaned_data/ll_data.rds\") data |> gg_overview()"},{"path":"https://tscnlab.github.io/LightLogR/articles/Metrics.html","id":"metric-principles","dir":"Articles","previous_headings":"","what":"Metric principles","title":"Metrics","text":"lot metrics associated personal light exposure. can find function reference appropriate reference section. important distinctions metrics important understand: metrics require work best specific time frame, usually one day, others calculated arbitrary length time. example, function interdaily_stability() calculates metric multiple days, function like midpointCE() calculates midpoint cumulative light exposure within given time series - less useful multiple days, midpoint just time point days. E.g., two similar light exposure patterns across two days, midpoint cumulative light exposure across two days around midnight, particularly informative. Much sensible midpoint light exposure day. enable , data grouped within days (relevant time frames, like sleep/wake-phase). metrics submetrics within family actively chosen arguments function. example duration_above_threshold() , despite name also provides metrics duration threshold duration within threshold. Depending comparison argument, whether one two thresholds provided, function calculate different metrics. metric functions calculate multiple submetrics , like bright_dark_period(). stated , type function contains metrics accessible function argument, period case, allows specify whether brightest darkest periods day required. Independent , function calculate multiple submetrics , onset, midpoint, offset respective period, also mean light level period. cover practical considerations following aspects following sections. , every function documentation explicitly states whether different metrics accessible parameters, metrics calculated default. Note: metrics require complete regular data sensible output. metrics can handle missing data, generally advisable clean data calculating metrics. LightLogR helps identify gaps irregularities can also aggregate data larger intervals, can acceptable small gaps. cases larger gaps, dates participants might removed analysis.","code":""},{"path":"https://tscnlab.github.io/LightLogR/articles/Metrics.html","id":"to-log-or-not-to-log-transform","dir":"Articles","previous_headings":"","what":"To log or not to log (transform)","title":"Metrics","text":"Light exposure data (e.g., Illuminance, melanopic EDI) normally distributed (see #. nature, values often highly skewed, also overdispersed. Additionally, data tend show excess zero values (called zero-inflation). paper deal darkness: Modelling visualization zero-inflated personal light exposure data logarithmic scale Zauner et al. (2025) explores ways deal . simplicity, article just use untransformed melanopic EDI values teach basics metric functions work LightLogR. However, generally recommend use log_zero_inflated() whenever means calculated light exposure, simple way deal zero-values. See article Log transformation information . function log_zero_inflated() used log-transform data, exp_zero_inflated() used back-transform data.","code":""},{"path":"https://tscnlab.github.io/LightLogR/articles/Metrics.html","id":"metric-calculation-basics","dir":"Articles","previous_headings":"","what":"Metric calculation: basics","title":"Metrics","text":"metric functions default agnostic type data. require vectors numeric data (e.g., light data) commonly also datetimes. means functions can used outside LightLogR framework, applied correctly. Let us try simple example days worth light data one participant across two functions.","code":"data_Id201 <-    data |>      filter(Id == 201 & date(Datetime) == \"2023-08-15\")  data_Id201 |>    gg_day()"},{"path":"https://tscnlab.github.io/LightLogR/articles/Metrics.html","id":"time-above-threshold-tat","dir":"Articles","previous_headings":"Metric calculation: basics","what":"Time above threshold (TAT)","title":"Metrics","text":"first example metric calculate time threshold (TAT) threshold 250 lx mel EDI. TAT calculated function duration_above_threshold(). Specifying argument comparison = \"\" calculate time threshold. specifying two thresholds calculate time within thresholds.","code":"duration_above_threshold(   Light.vector = data_Id201$MEDI,   Time.vector = data_Id201$Datetime,   threshold = 250 ) #> [1] \"34500s (~9.58 hours)\" duration_above_threshold(   Light.vector = data_Id201$MEDI,   Time.vector = data_Id201$Datetime,   threshold = 250,   comparison = \"below\" ) #> [1] \"51900s (~14.42 hours)\" duration_above_threshold(   Light.vector = data_Id201$MEDI,   Time.vector = data_Id201$Datetime,   threshold = c(10,250) ) #> [1] \"15320s (~4.26 hours)\""},{"path":"https://tscnlab.github.io/LightLogR/articles/Metrics.html","id":"brightest-10-hours-of-the-day-l10","dir":"Articles","previous_headings":"Metric calculation: basics","what":"Brightest 10 hours of the day (L10)","title":"Metrics","text":"second example metric yields multiple submetrics . function bright_dark_period() calculates brightest darkest periods day. default, calculates brightest 10 hour period day. setting as_df = TRUE, function return data frame can pipe gt() better output","code":"bright_dark_period(   Light.vector = data_Id201$MEDI,   Time.vector = data_Id201$Datetime,   as.df = TRUE ) |>    gt() |> tab_header(\"M10\")"},{"path":"https://tscnlab.github.io/LightLogR/articles/Metrics.html","id":"looping","dir":"Articles","previous_headings":"Metric calculation: basics > Brightest 10 hours of the day (L10)","what":"Looping","title":"Metrics","text":"Calculating darkest period day tricky, likely traverses midnight. following code can see darkest 10-hour period day begins midnight ends 10 , coincidental. (Note commonly, darkest 5-hour period calculated. deviate make point.) also see makes little sense, visualize portion. blue color indicates darkest 10-hour period day.  solve , bright_dark_period() functions option loop day. plausible, can also visualized easily.","code":"M10_wrong <-  bright_dark_period(   Light.vector = data_Id201$MEDI,   Time.vector = data_Id201$Datetime,   as.df = TRUE,   period = \"darkest\",   timespan = \"10 hours\" )  M10_wrong |> gt() |> tab_header(\"M10 without looping\") data_Id201 |>    mutate(State = ifelse(     Datetime >= M10_wrong$darkest_10h_onset &        Datetime <= M10_wrong$darkest_10h_offset, \"M10\", NA   )) |>   gg_day() |>    gg_state(State, aes_fill = State) +   guides(fill = \"none\") M10 <-  bright_dark_period(   Light.vector = data_Id201$MEDI,   Time.vector = data_Id201$Datetime,   as.df = TRUE,   period = \"darkest\",   timespan = \"10 hours\",   loop = TRUE )  M10 |> gt() data_Id201 |>    mutate(State = ifelse(     Datetime >= M10$darkest_10h_onset |        Datetime <= M10$darkest_10h_offset, \"M10\", NA   )) |>   gg_day() |>    gg_state(State, aes_fill = State) +   guides(fill = \"none\")"},{"path":"https://tscnlab.github.io/LightLogR/articles/Metrics.html","id":"metric-calculation-advanced","dir":"Articles","previous_headings":"","what":"Metric calculation: advanced","title":"Metrics","text":"often , metrics calculated many participants prolonged periods time. case, singular calculation shown inefficient. dplyr family dplyr::summarize() dplyr::reframe() make much easier. sure data prepared way metric functions can applied correctly. responsibility user, many functions provide output, long input vectors correct type length. case already prepared data correctly Import & Cleaning article. data already grouped Id, gaps irregular data","code":""},{"path":"https://tscnlab.github.io/LightLogR/articles/Metrics.html","id":"summarize","dir":"Articles","previous_headings":"Metric calculation: advanced","what":"Summarize","title":"Metrics","text":"dplyr::summarize() function used calculate metrics group data. following example, calculate Interdaily Stability () participants data set, giving us variability 24h light exposure patterns across full 6 days data compared average, ranging 0 (Gaussian noise) 1 (Perfect stability). brevity, first 6 Ids shown.","code":"data |>    summarize(     interdaily_stability(       Light.vector = MEDI,       Datetime.vector = Datetime,       as.df = TRUE     )   ) |>    head() |>    gt()"},{"path":"https://tscnlab.github.io/LightLogR/articles/Metrics.html","id":"grouping","dir":"Articles","previous_headings":"Metric calculation: advanced","what":"Grouping","title":"Metrics","text":"default, data imported LightLogR grouped Id, represents individual participants. using dplyr family functions, grouping essential, specifies subgroups data metrics calculated. following example, calculate TAT 250 lx MEDI participants data set. show first 6 participants, becomes readily apparent time threshold 6 days might informative parametrization metric. Instead, can calculate TAT 250 lx MEDI participant day data. informative, allows us see metric changes time. final output first two Ids.","code":"data |>    summarize(     duration_above_threshold(       Light.vector = MEDI,       Time.vector = Datetime,       threshold = 250,       as.df = TRUE     )   ) |>    head() |>    gt() #create a new column in the data set with the weekday data$wDay <- wday(data$Datetime, label = TRUE, week_start = 1)  #group the data and calculate the metrics TAT_250 <-  data |>    group_by(wDay, .add = TRUE) |>    summarize(     duration_above_threshold(       Light.vector = MEDI,       Time.vector = Datetime,       threshold = 250,       as.df = TRUE     ), .groups = \"drop_last\"   )  TAT_250 |>    head(12) |>    gt()"},{"path":"https://tscnlab.github.io/LightLogR/articles/Metrics.html","id":"photoperiod","dir":"Articles","previous_headings":"Metric calculation: advanced > Grouping","what":"Photoperiod","title":"Metrics","text":"Another useful grouping factor photoperiod, differentiate day day night. LightLogR contains family functions easily deal photoperiod. minimal example. , can summarize data : easily gives us metrics based daily photoperiod. Metric calculation can utilize photoperiod information ways, . information dealing photoperiods can found article Photoperiod.","code":"#specifying coordinates (latitude/longitude) coordinates <- c(48.521637, 9.057645)  #adding photoperiod information data <-    data |>    add_photoperiod(coordinates)  #calculating the metric mean_Exposure <-  data |>    group_by(photoperiod.state, .add = TRUE) |>    summarize(     mean_MEDI = mean(MEDI), .groups = \"drop_last\"   )  #showing the first three participants mean_Exposure |>    head(6) |>    gt() |>    fmt_number(mean_MEDI) mean_Exposure |>    group_by(photoperiod.state) |>    summarize_numeric(prefix = \"\"   ) |>    gt() |>    fmt_number(mean_MEDI)"},{"path":"https://tscnlab.github.io/LightLogR/articles/Metrics.html","id":"metric-statistics","dir":"Articles","previous_headings":"Metric calculation: advanced","what":"Metric statistics","title":"Metrics","text":"dataframe TAT_250, can easily calculate statistics participant. can done manually, e.g., another call dplyr::summarize(), semi-automatic, e.g., packages like gtsummary. following example, calculate mean standard deviation TAT 250 lx MEDI participant, formatted HH:MM styling function.","code":"#styling formula for time style_time <- function(x, format = \"%H:%M\"){   x |>      as.numeric() |>       hms::as_hms() |>      as.POSIXlt() |>      format(format) }  #Table output TAT_250 |>    tbl_summary(by = Id, include = -wDay,                statistic = list(duration_above_250 ~ \"{mean} ({sd})\"),                digits = list(duration_above_250 ~ style_time),               label = list(duration_above_250 = \"Time above 250 lx mel EDI\")               )"},{"path":"https://tscnlab.github.io/LightLogR/articles/Metrics.html","id":"mean_daily","dir":"Articles","previous_headings":"Metric calculation: advanced > Metric statistics","what":"mean_daily()","title":"Metrics","text":"function mean_daily() helper summarize daily data . takes summary results either contain date weekday column calculates mean metric weekdays, weekends, , mean day (based (5 x weekdays + 2 x weekends) / 7). variant mean_daily() called mean_daily_metric(), convenience function combine calculation single-return-value, duration-based metric mean daily calculation. can use calculate duration_above_250(lx) scratch function () limited options change metric_type. case, change function longest continuous period threshold. Basically, metric functions return numeric column can used.","code":"#mean daily calculation TAT_250_daily <- mean_daily(   TAT_250,   Weekend.type = wDay   )  TAT_250_daily |>    head(6) |>    gt() data |>    mean_daily_metric(     Variable = MEDI,     threshold = 250   ) |>    head() |>    gt() data |>    mean_daily_metric(     Variable = MEDI,     metric_type = period_above_threshold,     threshold = 250   ) |>    head() |>    gt()"},{"path":"https://tscnlab.github.io/LightLogR/articles/Metrics.html","id":"summarize_numericsummarise_numeric","dir":"Articles","previous_headings":"Metric calculation: advanced > Metric statistics","what":"summarize_numeric()/summarise_numeric()","title":"Metrics","text":"can even summarize data summarize_numeric(), takes dataset calculates average numeric columns, well number episodes group. makes sense within participants, just average Weekday, Weekend, Mean daily. regroup data, however, can gain usefull insights. can see participants slightly time 250 lx weekdays, compared weekends (03:45 vs. 02:58, respectively)","code":"TAT_250_daily |>    group_by(wDay) |>    summarize_numeric(   ) |>    gt() |>    fmt_duration(mean_average_duration_above_250,                 input_units = \"seconds\", duration_style = \"colon-sep\")"},{"path":"https://tscnlab.github.io/LightLogR/articles/Metrics.html","id":"metric-calculation-batch","dir":"Articles","previous_headings":"","what":"Metric calculation: batch","title":"Metrics","text":"final section, add metrics analysis, including ones multiple sub-metrics. , imagine want know metrics change first half experiment (August/September) second half (October/November). operation yields data frame six metrics across 102 participant days (6 days 17 participants). grouping Month add additional groups, participant day already solely \"Aug/Sep\" \"Oct/Nov\" group.","code":"data <- data |>    mutate(     Month = case_when(month(Datetime) %in% 8:9 ~ \"Aug/Sep\",                       month(Datetime) %in% 10:11 ~ \"Oct/Nov\")   )  metrics <-    data |>    group_by(Month, Id, wDay) |>    summarize(     timing_above_threshold(MEDI, Datetime, threshold = 250, as.df = TRUE),     duration_above_threshold(MEDI, Datetime, threshold = 250, as.df = TRUE),     average_medi =        MEDI |> log_zero_inflated() |>  mean() |> exp_zero_inflated(), #calculate zero inflated log transformed mean     dose(MEDI, Datetime, as.df = TRUE),     .groups = \"drop_last\"     )  #first 6 rows metrics |>    head() |>    gt()"},{"path":"https://tscnlab.github.io/LightLogR/articles/Metrics.html","id":"summarize-metrics","dir":"Articles","previous_headings":"Metric calculation: batch","what":"Summarize metrics","title":"Metrics","text":"can summarize data different ways. Within LightLogR, can use mean_daily() summarize_numeric() functions. default automatically transform datetime columns (type POSIXct) time columns (type hms), much sensible cases calculate averages number episodes shows us 11 values Aug/Sep, 6 Oct/Nov - except Weekends, 7. one participant crosses Sep/Oct. Checking participants data shows last day October, Sunday - thus part weekend. can wrangle data differently, get averages across days shows us 11 participants Aug/Sep timeframe 7 Oct/Nov timeframe. line summary , showed us one participant crossed timeframes. course, filtering data inbetween step ensure minimum amount data points category makes sense, left brevity.","code":"#calculating weekday, weekend, and mean daily summaries for each group metrics |>     #calculate weekday, weekend, and mean daily summaries for each group:   mean_daily(wDay, prefix = \"\", filter.empty = TRUE) |> #remove empty rows   group_by(Month, wDay) |>  #regroup so that we can summarize across Participants   summarize_numeric(prefix = \"\") |>    gt() |>    fmt_number(c(average_medi, dose)) data |>    filter(Id == 214) |>    pull(Datetime) |>    date() |>    unique() #> [1] \"2023-09-26\" \"2023-09-27\" \"2023-09-28\" \"2023-09-29\" \"2023-09-30\" #> [6] \"2023-10-01\" #calculating weekday daily summaries for each group metrics |>    summarize_numeric(prefix = \"\") |> #summarize across participants   summarize_numeric(prefix = \"\") |> #summarize by month   gt() |>    fmt_number(c(average_medi, dose))"},{"path":"https://tscnlab.github.io/LightLogR/articles/Metrics.html","id":"using-gtsummary","dir":"Articles","previous_headings":"Metric calculation: batch","what":"Using gtsummary","title":"Metrics","text":"section repeats summary, using popular gtsummary package. need work metrics LightLogR. sure look documentation function understand parameters outputs reference section get overview available metrics.","code":"metrics <-    metrics |>    group_by(Month) |>    select(-Id, -wDay)  #Table output metrics |>    tbl_summary(by = Month,               statistic = list(all_continuous() ~ \"{mean} (±{sd})\"),               digits = list(                 c(                   mean_timing_above_250, first_timing_above_250,                    last_timing_above_250, duration_above_250                   ) ~ style_time),               label = list(                 mean_timing_above_250 =                    \"mean timing above 250 lx mel EDI (HH:MM)\",                 first_timing_above_250 =                    \"first time above 250 lx mel EDI (HH:MM)\",                 last_timing_above_250 =                    \"last time above 250 lx mel EDI (HH:MM)\",                 duration_above_250 = \"duration above 250 lx mel EDI (HH:MM)\",                 average_medi = \"average mel EDI (lx)\",                 dose = \"light exposure (lx·h)\"                 )               )"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"importing-data","dir":"Articles","previous_headings":"","what":"Importing Data","title":"Visualizations","text":"use data imported cleaned already article Import & Cleaning.","code":"#this assumes the data is in the cleaned_data folder in the working directory data <- readRDS(\"cleaned_data/ll_data.rds\")"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"gg_overview","dir":"Articles","previous_headings":"","what":"gg_overview()","title":"Visualizations","text":"gg_overview() provides glance data available Id. Let’s call dataset.  can seen dataset contains 17 ids one weeks worth data , one three participants per week. gg_overview() default test whether gaps data show grey bars, well message lower right corner. Let us force behavior dataset removing two days.  Calculating gaps data can computationally expensive large datasets small epochs. just require overview data without concerned gaps, can provide empty tibble::tibble() gap.data argument. skip gap calculation speed graph generation.  Hint: gg_overview() automatically called import functions LightLogR, unless argument auto.plot = FALSE set. import slow, can also help speeding process.","code":"data |> gg_overview() data |>   filter(     !(date(Datetime) %in% c(\"2023-08-16\", \"2023-08-17\"))     ) |>    gg_overview() data |>   filter(     !(date(Datetime) %in% c(\"2023-08-16\", \"2023-08-17\"))     ) |>    gg_overview(gap.data = tibble())"},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"basics","dir":"Articles","previous_headings":"gg_day()","what":"Basics","title":"Visualizations","text":"gg_day() compares days within dataset. default use date. Let’s call subset data. distinguish different Ids, can set aes_col argument Id.","code":"data |>    filter(Id %in% c(205, 206)) |>    gg_day(aes_col = Id, size = 0.5)"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"facetting","dir":"Articles","previous_headings":"gg_day()","what":"Facetting","title":"Visualizations","text":"Note day represented facet, named date. can give Id facet using ggplot2::facet_wrap() function. Day.data column produced gg_day() contains structure daily facets. used facet_wrap() ensure facets shown correctly. also reduce breaks x-axis avoid overlap 00:00.","code":"data |>    filter(Id %in% c(205, 206)) |>    gg_day(aes_col = Id, size = 0.5,           x.axis.breaks = hms::hms(hours = c(0, 6, 12, 18))) +    guides(color = \"none\") +   facet_grid(rows = vars(Day.data), cols = vars(Id), switch = \"y\")"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"date-grouping","dir":"Articles","previous_headings":"gg_day()","what":"Date-grouping","title":"Visualizations","text":"Showing days date default behavior gg_day(). can also grouped formatting base::strptime(). Using format.day = \"%\" function call group output weekday. Putting many Participants facet makes plot unreadable, demonstrates gg_day() can configured combine observations different dates. provide different color scale compared default one, default 10 colors compared 17 need .","code":"data |>    gg_day(aes_col = Id, size = 0.5, format.day = \"%A\") +    scale_color_viridis_d() #> Scale for colour is already present. #> Adding another scale for colour, which will replace the existing scale."},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"customizing-geoms-and-miscellanea","dir":"Articles","previous_headings":"gg_day()","what":"Customizing geoms and miscellanea","title":"Visualizations","text":"gg_day() uses geom_point() default. can changed providing different geom function. use geom_line() connect points. make readable. Let us first recreate simpler version dataset filtering aggregating  Now can use different geom.  Also ribbon possible.","code":"data_subset <-    data |>    filter(Id %in% c(205, 206)) |> #choosing 2 ids   aggregate_Datetime(unit = \"15 mins\") |> #aggregating to 15 min intervals   filter_Datetime(length = \"3 days\", full.day = TRUE) #restricting their length to 3 days  data_subset |>    gg_day(aes_col = Id) data_subset |>   gg_day(aes_col = Id, geom = \"line\") data_subset |>     gg_day(aes_col = Id, aes_fill = Id, geom = \"ribbon\", alpha = 0.5)"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"gg_days","dir":"Articles","previous_headings":"","what":"gg_days()","title":"Visualizations","text":"companion function gg_day(). Instead using individual days, create timeline days across Ids.  default, gg_days() always plot full days. Let us strip one participant data three days.  can see plots misaligned facets. can correct providing exact number days x.axis.limits argument. Datetime_limits() helper function LightLogR documentation reveals arguments.  gg_days() customization options gg_day(). customize plot ribbon, different naming breaks datetime axis.","code":"data_subset2 <-  data |>    filter(Id %in% c(205, 216, 219)) |> #choosing 3 ids   aggregate_Datetime(unit = \"15 mins\") #aggregating to 15 min intervals  data_subset2 |>   gg_days() data_subset3 <-  data_subset2 |>    filter(!(Id == 205 &               date(Datetime) %in% c(\"2023-08-29\", \"2023-08-30\", \"2023-08-31\")))  data_subset3 |>   gg_days() data_subset3 |>    gg_days(     x.axis.limits =        \\(x) Datetime_limits(x, length = ddays(5), midnight.rollover = TRUE)     ) data_subset3 |>    gg_days(     geom = \"ribbon\", aes_col = Id, aes_fill = Id, alpha = 0.5, jco_color = TRUE,     x.axis.limits =        \\(x) Datetime_limits(x, length = ddays(5), midnight.rollover = TRUE),     x.axis.breaks =        \\(x) Datetime_breaks(x, by = \"6 hours\", shift = 0),     x.axis.format = \"%H\",     ) +   guides(color = \"none\", fill = \"none\")"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"gg_heatmap","dir":"Articles","previous_headings":"","what":"gg_heatmap()","title":"Visualizations","text":"gg_heatmap() simple handy feature get overview large time periods across groups. (unknown reason, tends produce warning uneven horizontal intervals, can safely ignored)  function ton individualization, options:   Importantly, handy doubleplot feature, either showing next, day repeated  Finally, can use heatmaps produce Actigram-like plot.","code":"data |> gg_heatmap() data |>    filter(Id %in% c(204, 216, 218)) |> #choosing 3 ids   gg_heatmap(fill.limits = c(0,NA)) #sets the upper limit to the max value# data |>    filter(Id %in% c(204, 216, 218)) |> #choosing 3 ids   gg_heatmap(unit = \"5 mins\") #changes the binning data |>    filter(Id %in% c(204, 216, 218))|>    gg_heatmap(doubleplot = \"next\", fill.limits = c(0, NA)) data |>    filter(Id %in% c(204, 216, 218))|>    gg_heatmap(Variable.colname = MEDI >= 50,               doubleplot = \"next\",               fill.limits = c(0, NA),               fill.remove = TRUE, fill.title = \">50lx MEDI\") +    scale_fill_manual(values = c(\"TRUE\" = \"black\", \"FALSE\" = \"#00000000\"))"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"gg_doubleplot","dir":"Articles","previous_headings":"","what":"gg_doubleplot()","title":"Visualizations","text":"generalized implementation doubleplots realized gg_doubleplot(): repeats days within plot, either horizontally vertically. Doubleplots generally useful visualize patterns center around midnight (horizontally) deviate 24-hour rhythms (vertically).","code":""},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"preparation","dir":"Articles","previous_headings":"gg_doubleplot()","what":"Preparation","title":"Visualizations","text":"use subset data used gg_day() : two Ids, aggregated 15-minute intervals, restricted three days. first day partly present Ids, use gap_handler() function fill implicitly missing data NA. ignore step, doubleplot incorrect, connect last point first day (around midnight) first point second day (somewhen noon), incorrect also looks bad.","code":"data_subset <-    data_subset |>    gap_handler(full.days = TRUE)"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"horizontal-doubleplot","dir":"Articles","previous_headings":"gg_doubleplot()","what":"Horizontal doubleplot","title":"Visualizations","text":"horizontal doubleplot activated default, one day present within provided groups, can set explicitly type = \"repeat\".  plot line thus day, plotted twice.","code":"data_subset |>     gg_doubleplot(aes_fill = Id, jco_color = TRUE, type = \"repeat\") #identical: # data_subset |>  #  group_by(Date = date(Datetime), .add = TRUE) |> #  gg_doubleplot(aes_fill = Id, jco_color = TRUE)"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"vertical-doubleplot","dir":"Articles","previous_headings":"gg_doubleplot()","what":"Vertical doubleplot","title":"Visualizations","text":"vertical doubleplot activated default group one day. can set explicitly type = \"next\".  Note second day row first day next row. allows visualize non-24-hour rhythms, Entrainment lost due pathologies experimental conditions. Note x-axis labels change automatically depending whether doubleplot type \"next\" \"repeat\". cases (horizontally vertically) easy condense plots single line per day, ungrouping data structure (makes sense datetimes identical):","code":"data_subset |>    gg_doubleplot(aes_fill = Id, jco_color = TRUE) #identical: # data_subset |>  #  gg_doubleplot(aes_fill = Id, jco_color = TRUE, type = \"next\") data_subset |>    ungroup() |>    gg_doubleplot(aes_fill = Id, jco_color = TRUE)"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"aggregated-doubleplot","dir":"Articles","previous_headings":"gg_doubleplot()","what":"Aggregated doubleplot","title":"Visualizations","text":"Independent gg_doubleplot(), great concert aggregate_Date(), allows aggregate groups data single day . way, one can easily calculate average day participant group participants perform doubleplot (default type = \"next\"). Let us first group data whether participants first last two months experiment. Now can aggregate data single day per group make doubleplot . aggregate_Date() condense large dataset 10-second intervals single day two groups 15 minute interval. day assigned default median measurement day group.  can improve plot. First, overwrite default behavior setting specific (arbitrary) date groups. ungrouping data afterwards, can plot two groups single row, making two times easily comparable. Setting facetting = FALSE gets rid strip label, otherwise show (arbitrary) date.  clearly see now, daytime light exposure starts later ends earlier, lower daytime values overall. Conversely, nighttime light exposure increased second half experiment (Oct/Nov). using gg_doubleplot() feature, nighttime light pattern clearly visible even accross midnight.","code":"data_two_groups <- data |>    mutate(     Month = case_when(month(Datetime) %in% 8:9 ~ \"Aug/Sep\",                       month(Datetime) %in% 10:11 ~ \"Oct/Nov\")   ) |>    group_by(Month) data_two_groups |>    aggregate_Date(unit = \"15 mins\") |>    gg_doubleplot(aes_fill = Month, jco_color = TRUE) +   guides(fill = \"none\") data_two_groups |>    aggregate_Date(unit = \"15 mins\",                   date.handler = \\(x) as_date(\"2023-09-15\")                  ) |>    ungroup() |>    gg_doubleplot(aes_fill = Month, jco_color = TRUE, facetting = FALSE)"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"photoperiod","dir":"Articles","previous_headings":"","what":"Photoperiod","title":"Visualizations","text":"LightLogR contains family functions calculate work photoperiods. includes visualization, easy adding gg_photoperiod() choice gg_day(), gg_days(), gg_doubleplot(). minimal example:  information dealing photoperiods can found article Photoperiod.","code":"#specifying coordinates (latitude/longitude) coordinates <- c(48.521637, 9.057645)  sample.data.environment |>    gg_days() |>    gg_photoperiod(coordinates)"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"gg_state","dir":"Articles","previous_headings":"","what":"gg_state()","title":"Visualizations","text":"gg_state() another great add plotting function works similarly gg_photoperiod() called top existing plot. Let us start filtering larger dataset participant.","code":""},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"preparation-1","dir":"Articles","previous_headings":"gg_state()","what":"Preparation","title":"Visualizations","text":"Next importing sleep data participant (Id = 205), included LightLogR: Next, add sleep/wake data dataset. , also add Brown et al. 2022 recommendations healthy light, can extracted sleep/wake data.","code":"#filter the dataset data_205 <-   data |> filter(Id == \"205\") |>    aggregate_Datetime(unit = \"5 mins\", type = \"floor\") #the the path to the sleep data path <- system.file(\"extdata\",                package = \"LightLogR\") file.sleep <- \"205_sleepdiary_all_20230904.csv\" #import sleep/wake data dataset.sleep <-    import_Statechanges(file.sleep, path,                        Datetime.format = \"dmyHM\",                       State.colnames = c(\"sleep\", \"offset\"),                       State.encoding = c(\"sleep\", \"wake\"),                       Id.colname = record_id,                       sep = \";\",                       dec = \",\",                       tz = \"Europe/Berlin\") #>  #> Successfully read in 14 observations across 1 Ids from 1 Statechanges-file(s). #> Timezone set is Europe/Berlin. #> The system timezone is UTC. Please correct if necessary! #>  #> First Observation: 2023-08-28 23:20:00 #> Last Observation: 2023-09-04 07:25:00 #> Timespan: 6.3 days #>  #> Observation intervals:  #>    Id    interval.time             n pct   #>  1 205   34860s (~9.68 hours)      1 8%    #>  2 205   35520s (~9.87 hours)      1 8%    #>  3 205   35700s (~9.92 hours)      1 8%    #>  4 205   36000s (~10 hours)        1 8%    #>  5 205   36900s (~10.25 hours)     1 8%    #>  6 205   37020s (~10.28 hours)     1 8%    #>  7 205   37920s (~10.53 hours)     1 8%    #>  8 205   45780s (~12.72 hours)     1 8%    #>  9 205   48480s (~13.47 hours)     1 8%    #> 10 205   49200s (~13.67 hours)     1 8%    #> # ℹ 3 more rows data_205 <-   data_205 |>   interval2state(dataset.sleep |> sc2interval()) |> #add sleep/wake-data   interval2state(     dataset.sleep |> sc2interval() |> sleep_int2Brown(),      State.colname = State.Brown) #add Brown et al. 2022 states"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"with-gg_days","dir":"Articles","previous_headings":"gg_state()","what":"With gg_days()","title":"Visualizations","text":"Adding sleep-wake information base plot.  can also highlight sleep phases, either setting wake instances NA, , converting logical column. Notice conditional fill longer necessary.","code":"data_205 |> gg_days() |> gg_state(State, aes_fill = State) data_205 |>    mutate(State = ifelse(State == \"sleep\", TRUE, FALSE)) |>    gg_days() |>    gg_state(State)"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"with-gg_day","dir":"Articles","previous_headings":"gg_state()","what":"With gg_day()","title":"Visualizations","text":"gg_state() automatically detects whether called gg_day() gg_days(), just works box.  can even go step beyond, show times participant complied recommendations. employ helper function Brown2reference() creates additional columns, including one tests whether light exposure level within required range (Reference.check). select column gg_state(), can color State.Brown , get selection recommendation actually met.","code":"data_205 |>    gg_day(geom = \"line\") |>    gg_state(State.Brown, aes_fill = State.Brown) +   labs(fill = \"Brown states\") data_205 |>    Brown2reference() |>   group_by(State.Brown, .add = TRUE) |>    gg_day(geom = \"line\") |>    gg_state(Reference.check, aes_fill = State.Brown) +   labs(fill = \"Brown states\")"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"with-gg_doubleplot","dir":"Articles","previous_headings":"gg_state()","what":"With gg_doubleplot()","title":"Visualizations","text":"gg_state() mostly work fine gg_doubleplot() gate","code":"data_205 |>    mutate(State = ifelse(State == \"sleep\", TRUE, FALSE)) |>    gg_doubleplot() |>    gg_state(State)"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"combination-with-other-add-on-functionality","dir":"Articles","previous_headings":"gg_state()","what":"Combination with other add-on functionality","title":"Visualizations","text":"State plotting can combined add-plotting functions, like states, photoperiods, even gaps. However can quickly become confusing overlapping states, like sleep nighttime:  cases might useful color ribbon according state photoperiod.","code":"data_205 |>    mutate(State = ifelse(State == \"sleep\", TRUE, FALSE)) |>    gg_doubleplot() |>    gg_state(State, aes_fil = State, aes_col =State, alpha = 0.1) |>    gg_photoperiod(c(48.5,9)) +   labs(colour =\"Sleep\", fill = \"Sleep\")"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"emphasis-ond-photoperiod-with-sleepwake","dir":"Articles","previous_headings":"gg_state() > Combination with other add-on functionality","what":"Emphasis ond photoperiod with sleep/wake","title":"Visualizations","text":"","code":"data_205 |>    mutate(State = ifelse(State == \"sleep\", TRUE, FALSE)) |>    add_photoperiod(c(48.5,9)) |>    gg_doubleplot(aes_fill = photoperiod.state, group = consecutive_id(photoperiod.state)) |>    gg_state(State) +   labs(fill = \"Photoperiod\")"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"emphasis-on-sleepwake-with-photoperiod","dir":"Articles","previous_headings":"gg_state() > Combination with other add-on functionality","what":"Emphasis on sleep/wake with photoperiod","title":"Visualizations","text":"","code":"data_205 |>    gg_doubleplot(aes_fill = State, group = consecutive_id(State)) |>    gg_photoperiod(c(48.5,9)) +   labs(fill = \"Sleep\")"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"gg_gaps","dir":"Articles","previous_headings":"","what":"gg_gaps()","title":"Visualizations","text":"gg_gaps() visualizes gaps optionally also irregular data. easy use, can computationally expensive, lots irregular data /gaps. Calling good data produce plot can create dataset explicit implicit gaps irregular data, zero values replaced NA, observations 1000 lx missing, last day slightly delayed sequence. default, gg_gaps() shows missing values. Setting show.irregulars = TRUE also adds irregular data plot","code":"data |> gg_gaps() #> No gaps nor irregular values were found. Plot creation skipped bad_dataset <- data_205 |>    mutate(Datetime = if_else(date(Datetime) == max(date(Datetime)),                              Datetime, Datetime + 1), #creates irregular data for the last day           MEDI = na_if(MEDI, 0) #creates explicit gaps           ) |>   filter(MEDI <1000) #creates implicit gaps  bad_dataset |> gg_gaps(MEDI) #> Warning: Removed 113 rows containing missing values or values outside the scale range #> (`geom_line()`). bad_dataset |> gg_gaps(MEDI, show.irregulars = TRUE) #> Warning: Removed 113 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"interactivity","dir":"Articles","previous_headings":"","what":"Interactivity","title":"Visualizations","text":"gg_day() gg_days() inbuilt option displayed interactively. great exploring data. plotly package used . interactive argument set FALSE default. Setting TRUE create interactive plot.","code":"data_subset |>     gg_day(aes_col = Id, geom = \"line\",          interactive = TRUE          )"},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"non-light-properties","dir":"Articles","previous_headings":"Miscellaneous","what":"Non-Light properties","title":"Visualizations","text":"LightLogR designed work light data, can also used types data. Simply define y.axis argument plotting functions. following example, plot activity data data dataset. comparison, light data added background lower alpha value.","code":"data_subset2 |>   gg_days(y.axis = PIM, y.axis.label = \"Activity (PIM)\") +   geom_line(aes(y=MEDI), color = \"red\", alpha = 0.2)"},{"path":"https://tscnlab.github.io/LightLogR/articles/Visualizations.html","id":"scales","dir":"Articles","previous_headings":"Miscellaneous","what":"Scales","title":"Visualizations","text":"default, LightLogR uses -called symlog scale visualizations. scale combination linear logarithmic scale, useful light data, allows visualize low high values plot, including 0 negative values. light data regularly zero, exact values 0 1 lux usually relevant devices measuring 10^5 lx, scale useful compared linear logarithmic scaling. way symlog works threshold absolute values kept linear, beyond transformed logarithmically. default threshold 1, good choice light data. However, can changed setting threshold argument plotting functions. See full documentation symlog scale symlog_trans(). example show transformation particularly useful differences cross zero. use single-day doubleplot data .  can clearly see difference light exposure crossing 0 several times. symlog scale values discarded, outside traditional range logarithmic scale. values 1 lux interest, parameters transformation can adjusted.","code":"#dataset from above data <-    data_two_groups |>      aggregate_Date(unit = \"15 mins\",                     date.handler = \\(x) as_date(\"2023-09-15\")                    ) |>      ungroup()  #original doubleplot from above original_db <-    data |>      gg_doubleplot(aes_fill = Month, jco_color = TRUE, facetting = FALSE) +     guides(fill = \"none\")  #difference doubleplot, showing the average difference between the to phases difference_db <-    data |>      select(Datetime, MEDI, Month) |>      pivot_wider(names_from = Month, values_from = MEDI) |>      gg_doubleplot(y.axis = `Oct/Nov`-`Aug/Sep`, facetting = FALSE,                   y.axis.label = \"difference (lx, MEDI)\")  #plotting original_db / difference_db data |>    select(Datetime, MEDI, Month) |>    pivot_wider(names_from = Month, values_from = MEDI) |>    gg_doubleplot(y.axis = `Oct/Nov`-`Aug/Sep`, facetting = FALSE,                 y.axis.label = \"difference (lx, MEDI)\",                 y.scale = symlog_trans(thr = 0.001),                 y.axis.breaks = c(-10^(-2:5), 0, 10^(5:-2))                 )"},{"path":"https://tscnlab.github.io/LightLogR/articles/log.html","id":"importing-data","dir":"Articles","previous_headings":"","what":"Importing Data","title":"Log transformation","text":"use data imported cleaned already article Import & Cleaning. can seen using gg_overview(), dataset contains 17 ids one weeks worth data , one three participants per week.","code":"#this assumes the data is in the cleaned_data folder in the working directory data <- readRDS(\"cleaned_data/ll_data.rds\") data |> gg_overview()"},{"path":"https://tscnlab.github.io/LightLogR/articles/log.html","id":"to-log-or-not-to-log-transform","dir":"Articles","previous_headings":"","what":"To log or not to log (transform)","title":"Log transformation","text":"Light exposure data (e.g., Illuminance, melanopic EDI) normally distributed (see #. nature, values often highly skewed, also overdispersed. Additionally, data tend show excess zero values (called zero-inflation). paper deal darkness: Modelling visualization zero-inflated personal light exposure data logarithmic scale Zauner et al. (2025) explores ways deal . visualization, symlog scale excellent (see symlog_trans()), basis LightLogR visualizations. statistical modelling, Tweedie distribution good choice, can handle zero-inflation overdispersion. one simply wants average across portions dataset? case, mean good choice. Even median affected zero-inflation. Log-transforming data removes zero values, common occurance, thus also removes valuable information dataset. Zauner et al. summize adding small, negligable value variable prior log-transformation good way deal issue, also modelling. LightLogR two functions facilitate : log_zero_inflated() exp_zero_inflated() use default offset 0.1 logarithmic base 10, can adjusted. function log_zero_inflated() used log-transform data, exp_zero_inflated() used back-transform data. functions used following way: values represent dataset? Let’s overlay histogram  can readily seen median log_zero_inflated mean lead similar results, still different almost factor 2. mean doesn’t represent anything well, log-transformed mean represents “non-zero” part distribution quite well, expected. look like look daytime values, expected fewer zero-lux values?  cases fewer zero-values, log-transformed mean log_zero_inflated mean similar, still 50% higher untransformed mel EDI level.","code":"#no transformation data$MEDI |> mean() #> [1] 425.6553 data$MEDI |> median() #> [1] 9.39  #log-transformation data$MEDI |> log() |> Filter(\\(x) !is.infinite(x), x = _) |> mean() |> exp() #> [1] 46.61243  #log_zero_inflated data$MEDI |> log_zero_inflated() |> mean() |> exp_zero_inflated() #> [1] 5.603959 #creating a histogram function MEDI_histogram <- function(data) {  #creating a dataset with the location parameters locations <- tibble(   mean = data$MEDI |> mean(),   median = data$MEDI |> median(),   log_mean = data$MEDI |> log() |> Filter(\\(x) !is.infinite(x), x = _) |> mean() |> exp(),   log_zero_inflated_mean = data$MEDI |> log_zero_inflated() |> mean() |> exp_zero_inflated() ) |> pivot_longer(cols = everything())    #creating the histogram data |>    ggplot(aes(x = MEDI, y = after_stat(ncount))) +    geom_histogram(binwidth = 0.2) +    scale_x_continuous(trans = \"symlog\",                       breaks = c(0, 10^(0:5)),                       labels= expression(0,10^0,10^1, 10^2, 10^3, 10^4, 10^5)                      ) +   geom_vline(data = locations, aes(xintercept = value, color = name), linetype = \"dashed\") +   geom_label(data = locations, aes(x = value, y = c(0.4, 0.3, 0.35, 0.25), label = name, color = name),               size = 3) +   ggsci::scale_color_jco()+   guides(color = \"none\") +   labs(x = \"Melanopic illuminance (lx, mel EDI)\", y = \"Scaled counts (max = 1)\") +   theme_minimal() } MEDI_histogram(data) #looking only at daytime values of light exposure day_data <-  data |>    add_photoperiod(c(48.5, 9)) |>    filter(photoperiod.state == \"day\")  MEDI_histogram(day_data)"},{"path":"https://tscnlab.github.io/LightLogR/articles/log.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Log transformation","text":"cases many zero values, log_zero_inflated mean arguably better representation location parameter data, median. log_zero_inflated mean also good choice modelling, affected zero values. difference log transformed data becomes pronounced number zero values increases. generally recommend either use median log_zero_inflated mean summaries light exposure data.","code":""},{"path":"https://tscnlab.github.io/LightLogR/articles/photoperiod.html","id":"importing-data","dir":"Articles","previous_headings":"","what":"Importing Data","title":"Photoperiod","text":"use data imported cleaned already article Import & Cleaning. first three lines data can seen using gg_overview(), dataset contains 17 ids one weeks worth data , one three participants per week.","code":"#this assumes the data is in the `cleaned_data` folder in the working directory data <- readRDS(\"cleaned_data/ll_data.rds\") #to save computational time, we will only use a few columns from the data data <- data |> select(Id, Datetime, MEDI) data |> ungroup() |>  head(3) |> gt_tab() data |> gg_overview()"},{"path":"https://tscnlab.github.io/LightLogR/articles/photoperiod.html","id":"adding-photoperiod-information","dir":"Articles","previous_headings":"","what":"Adding photoperiod information","title":"Photoperiod","text":"Adding photoperiod information dataset easy, requires four pieces information: dates photoperiod information added? timezone photoperiod information provided? location photoperiod information added? photoperiod defined? first two aspects (usually) already defined dataset imported LightLogR. contains information relevant days, Datetime column contains necessary timezone information. latter two aspects need provided user.","code":""},{"path":"https://tscnlab.github.io/LightLogR/articles/photoperiod.html","id":"geolocation","dir":"Articles","previous_headings":"Adding photoperiod information","what":"Geolocation","title":"Photoperiod","text":"geographical location defined set coordinates form latitude longitude. sample data collected Tübingen, Germany, located 48.52°N, 9.06°E. coordinates need stored numeric vector length 2. order latitude longitude essential.","code":"coordinates <- c(48.521637, 9.057645)"},{"path":"https://tscnlab.github.io/LightLogR/articles/photoperiod.html","id":"what-is-photoperiod","dir":"Articles","previous_headings":"Adding photoperiod information","what":"What is photoperiod?","title":"Photoperiod","text":", photoperiod covers time sun given threshold elevation (rather depression), relative horizon. elevation/depression decided user. LightLogR uses default depression angle 6 degrees, yielding Civil dawn/dusk, depression angles can set, depending research hand. depression value 0 degrees sunrise/sunset, 12 degrees Nautical dawn/dusk, 18 degrees Astronomical dawn/dusk. find Civil dawn/dusk relates best steep rise environmental illuminance levels, set default.","code":""},{"path":"https://tscnlab.github.io/LightLogR/articles/photoperiod.html","id":"calculating-photoperiod","dir":"Articles","previous_headings":"Adding photoperiod information","what":"Calculating photoperiod","title":"Photoperiod","text":"LightLogR provides several ways calculate dawn dusk information. Likely useful function add_photoperiod(), directly expands dataset necessary information. way LightLogR provides information singular number, rather set values relevant photoperiod. dawn dusk columns provide start end times photoperiod, respectively. photoperiod length photoperiod, defined dawn dusk times. Finally, photoperiod.state defines whether current observation (Datetime) within (day) outside (night) relevant photoperiod. Adding information might necessary cases, however. relevant photoperiods required, need part whole dataset, extract_photoperiod() right choice. functions works way add_photoperiod(), returns dataframe relevant days: Finally, photoperiods connected specific dataset might required. case, photoperiod() useful basic helper function. draw upon dataset, dates timezone must supplied separately. provides good opportunity change solar depression angle, showcasing differences photoperiod compare different settings, purrr::map() friend Comparing different solar depression values summer solstice","code":"data |>    add_photoperiod(coordinates) |>    #from here on out is just formatting   head(3) |>    gt_tab(caption = \"Photoperiod Information for the first three observations\") |>    fmt_duration(\"photoperiod\") |>    fmt_datetime(c(\"dawn\", \"dusk\")) |>    tab_style(style = cell_text(color = \"red\"),              locations = list(cells_body(dawn:photoperiod.state),                              cells_column_labels(dawn:photoperiod.state))   ) data |>    extract_photoperiod(coordinates) |>    #from here on out is just formatting   head(3) |>    gt_tab(caption = \"Photoperiod Information for the first three days\") |>    fmt_duration(\"photoperiod\") |>    fmt_number(c(lat, lon)) |>    fmt_datetime(c(\"dawn\", \"dusk\")) dates <- c(\"2025-06-21\", \"2025-12-21\") timezone <- \"Europe/Berlin\"  photoperiod(coordinates, dates, timezone) |>    #from here on out is just formatting   gt_tab(caption = \"Photoperiod information for winter and summer solstice\") |>    fmt_datetime(c(\"dawn\", \"dusk\")) |>    fmt_number(c(lat, lon)) |>    fmt_duration(\"photoperiod\") photoperiod(coordinates, dates, timezone, solarDep = 0) |>    #from here on out is just formatting   gt_tab(caption = \"Photoperiod information for sunrise/sunset\") |>    fmt_datetime(c(\"dawn\", \"dusk\")) |>    fmt_number(c(lat, lon)) |>    fmt_duration(\"photoperiod\") |>    tab_style(style = cell_text(color = \"red\"),             locations = list(cells_body(solar.angle),                              cells_column_labels(solar.angle))   ) solarDep <- c(0, 6, 12, 18)  solarDep |>    map(\\(solarDep) photoperiod(coordinates, dates[1], timezone, solarDep)) |>    list_rbind() |>    arrange(date) |>    select(solar.angle, dawn, dusk, photoperiod) |>    gt(caption = \"Comparing different solar depression values for summer solstice\") |>    fmt_datetime(c(\"dawn\", \"dusk\")) |>    fmt_duration(\"photoperiod\") |>    tab_style(style = cell_text(color = \"red\"),             locations = list(cells_body(solar.angle),                              cells_column_labels(solar.angle))   )"},{"path":"https://tscnlab.github.io/LightLogR/articles/photoperiod.html","id":"visualizing-photoperiod","dir":"Articles","previous_headings":"","what":"Visualizing photoperiod","title":"Photoperiod","text":"LightLogR provides simple interface add photoperiod information plots created gg_day(), gg_days(), gg_doubleplot(). can either draw previously added photoperiod information, create fly. dataset quite extensive, use portion five days three participants. easy filter_Date() function:","code":"data_partial <-    data |>    filter_Date(start = \"2023-08-15\", length = \"5 days\")  data_partial |> gg_overview()"},{"path":"https://tscnlab.github.io/LightLogR/articles/photoperiod.html","id":"integration-with-gg_day","dir":"Articles","previous_headings":"Visualizing photoperiod","what":"Integration with gg_day()","title":"Photoperiod","text":"","code":"data_partial |>    gg_day(aes_col = Id, geom = \"line\") |>    gg_photoperiod(coordinates) #this is identical to: # data_partial |>  #   add_photoperiod(coordinates) |>  #   gg_day(aes_col = Id, geom = \"line\") |>  #   gg_photoperiod()"},{"path":"https://tscnlab.github.io/LightLogR/articles/photoperiod.html","id":"integration-with-gg_days","dir":"Articles","previous_headings":"Visualizing photoperiod","what":"Integration with gg_days()","title":"Photoperiod","text":"photoperiod information added prior plotting, can also used main geom:","code":"data_partial |>    gg_days() |>    gg_photoperiod(coordinates) #this is identical to: # data_partial |>  #   add_photoperiod(coordinates) |>  #   gg_days() |>  #   gg_photoperiod() data_partial |>    add_photoperiod(coordinates) |>    gg_days(     aes_col = photoperiod.state,      group = consecutive_id(photoperiod.state),     jco_color = TRUE) +   theme(legend.position = \"bottom\") +   labs(col = \"State of the photoperiod\")"},{"path":"https://tscnlab.github.io/LightLogR/articles/photoperiod.html","id":"integration-with-gg_doubleplot","dir":"Articles","previous_headings":"Visualizing photoperiod","what":"Integration with gg_doubleplot()","title":"Photoperiod","text":"Integration gg_doubleplot() similar plotting functions. However, gg_doubleplot() uses trickery hood cases repeats day twice (case one day per group present, type = \"repeat\" set), strongly suggest photoperiod information added prior plotting. , photoperiod repeated day actually draw consecutive calender date. minor difference minutes, easily avoided.","code":"data_partial |>    filter_Date(length = \"1 day\") |>    add_photoperiod(coordinates) |>   gg_doubleplot() |>    gg_photoperiod() #NOT the same as: # data_partial |>  #   filter_Date(length = \"1 day\") |>  #   gg_doubleplot() |>  #   gg_photoperiod(coordinates)"},{"path":"https://tscnlab.github.io/LightLogR/articles/photoperiod.html","id":"combination-with-aggregate_date","dir":"Articles","previous_headings":"Visualizing photoperiod","what":"Combination with aggregate_Date()","title":"Photoperiod","text":"Adding photoperiod data dataset means can manipulated way column dataset. aggregate_Date() great way condense multiple days data collection single day. example, use full dataset start . suggest photoperiods added aggregate_Date() applied, aggregation datetimes can error prone. E.g., mean dusk 6:00:00 1 Feb, 6:01:00 2 Feb 18:00:30 1 Feb. certainly correct numeric standpoint (datetimes stored seconds reference), make much sense dusk dawn values shifted sense. applying photoperiod information aggregation, can sure based aggregated datetimes.","code":"data |>    filter(Id %in% c(201, 212, 216, 222)) |>    aggregate_Date(unit = \"5 mins\") |>   add_photoperiod(coordinates) |>   gg_doubleplot() |>    gg_photoperiod(alpha = 0.9)"},{"path":"https://tscnlab.github.io/LightLogR/articles/photoperiod.html","id":"differences-in-solar-depression-angle","dir":"Articles","previous_headings":"Visualizing photoperiod","what":"Differences in solar depression angle","title":"Photoperiod","text":"can show difference solar depression angle makes visualizing different variants. use sample.data.environment comes LightLogR. contains ambient environmental illuminance values:  use Environment data Sat 09/02/23 showcase .  influence solar depression angle can also displayed single plot:","code":"sample.data.environment |>    gg_days() |>    gg_photoperiod(coordinates) #preparing a dataset with multiple solar depression angles: multiple_solarDep <-   solarDep |>   rlang::set_names() |>   map(\\(solarDep) {     sample.data.environment |>       filter(Id == \"Environment\") |>       filter_Date(start = \"2023-09-02\", length = \"1 day\") |>       add_photoperiod(coordinates, solarDep = solarDep)   }) |>   list_rbind(names_to = \"solarDep\") |>   mutate(solarDep = paste0(solarDep, \"°\"),          solarDep = factor(solarDep, levels = c(\"0°\", \"6°\", \"12°\", \"18°\"))) |>   group_by(solarDep)  #actual plotting: multiple_solarDep |>    gg_doubleplot(facetting = FALSE) |>    gg_photoperiod(alpha = 0.8) +   facet_wrap(~solarDep, ncol = 1) +   labs(title = \"Differences in photoperiod\\ndepending on solar depression angle\") #plotting in one facet: multiple_solarDep |>    gg_doubleplot(facetting = FALSE) |>    gg_photoperiod(alpha = 0.25) +   labs(title = \"Differences in photoperiod\\ndepending on solar depression angle\")"},{"path":"https://tscnlab.github.io/LightLogR/articles/photoperiod.html","id":"calculating-metrics","dir":"Articles","previous_headings":"","what":"Calculating metrics","title":"Photoperiod","text":"Metrics calculation photoperiod data quite straightforward, photoperiod can used direct grouping aspect, intermediary. cases sensible add photoperiod information data:","code":"data <-    data |>    add_photoperiod(coordinates)"},{"path":"https://tscnlab.github.io/LightLogR/articles/photoperiod.html","id":"photoperiod-as-a-grouping-aspect","dir":"Articles","previous_headings":"Calculating metrics","what":"Photoperiod as a grouping aspect","title":"Photoperiod","text":"can group photoperiod (within participants) calculate metrics daytime nighttime sections. calculate simple mean value summarize results help gtsummary package. results singular value per participant (N=17 total) photoperiod. interested weekly values, can group week.  one group day (calender day), one disadvantage night portion day split two. midnight dawn part bin dusk midnight, grouping day. differs common understanding, night day 1 goes dusk till dawn - depending research question, one might required. LightLogR useful number_states() function case. allows types counting independent 24 hour day. Let us apply function dataset. function creates new column divides dataset individual days nights, can used grouping. function similarly useful “sleep/wake” column present data, allows calculation metrics based singular sleep/wake episodes, indifferent date.  approach benefit works regardless data collection started. always bin first, second, forth daytime periods participants together, nighttime.","code":"data |>    group_by(photoperiod.state, .add = TRUE) |>  # setting .add = TRUE ensures prior grouping is kept   summarize(mean_MEDI = mean(MEDI), .groups = \"drop\") |>    tbl_summary(by=photoperiod.state,                include = \"mean_MEDI\",                label = mean_MEDI ~ \"mean mel EDI (lx)\") per_week <-  data |>    group_by(Id, week = week(Datetime), photoperiod.state) |>   summarize(mean_MEDI = mean(MEDI), .groups = \"drop\")  #uncomment next lines for a tabular view # per_week |>  #   pivot_wider(names_from = week, values_from = mean_MEDI, names_prefix = \"week \") |>  #   tbl_summary(by=photoperiod.state,  #               include = -Id,  #               type =  #                 paste(\"week\", 33:44) ~ \"continuous\",  #               missing = \"no\" #               ) |>  #   modify_header(label = \"**mean mel EDI (lx)**\")  per_week |>    ggplot(aes(x=factor(week), y = mean_MEDI)) +   geom_boxplot(aes(fill = photoperiod.state)) +   scale_y_log10() +   theme_minimal() +   labs(x = \"week\", y = \"mean mel EDI (lx)\", fill = \"Photoperiod\") +   theme(legend.position = \"bottom\")+   scale_fill_manual(values = c(\"#FDFBD3\", \"#003153AA\")) data <-   data |>   number_states(photoperiod.state)  data |> pull(photoperiod.state.count) |> unique() |> head() #> [1] \"night 1\" \"day 1\"   \"night 2\" \"day 2\"   \"night 3\" \"day 3\" per_day <-  data |>    group_by(Id, photoperiod.state, photoperiod.state.count) |>    summarize(mean_MEDI = mean(MEDI), .groups = \"drop\") |>    select(-photoperiod.state) |>    separate_wider_delim(photoperiod.state.count, \" \", names = c(\"photoperiod.state\", \"count\"))  per_day |>    pivot_wider(names_from = count, values_from = mean_MEDI, names_prefix = \"day \") |>    tbl_summary(by=photoperiod.state,                include = -Id,               missing = \"no\"               ) |>    modify_header(label = \"**mean mel EDI (lx)**\") per_day  |>    ggplot(aes(x=count, y = mean_MEDI)) +   geom_boxplot(aes(fill = photoperiod.state)) +   scale_y_log10() +   theme_minimal() +   labs(x = \"day\", y = \"mean mel EDI (lx)\", fill = \"Photoperiod\") +   theme(legend.position = \"bottom\") +   scale_fill_manual(values = c(\"#FDFBD3\", \"#003153AA\")) #> Warning in scale_y_log10(): log-10 transformation introduced #> infinite values. #> Warning: Removed 7 rows containing non-finite outside the scale range #> (`stat_boxplot()`)."},{"path":"https://tscnlab.github.io/LightLogR/articles/photoperiod.html","id":"photoperiod-as-an-intermediary","dir":"Articles","previous_headings":"Calculating metrics","what":"Photoperiod as an intermediary","title":"Photoperiod","text":"Sometimes photoperiod whole interest, rather used point reference calculate metric. One example requested LightLogR feature issue #39. , intensity daytime light exposure defined mean illuminance first morning light exposure 50 lux time civil dusk). Similarly, mean intensity evening light exposure defined mean illuminance civil dusk last light exposure 50 lux. tools LightLogR provides, easy. example intensity daytime light exposure, evening light exposure calculated alongside . datasets start middle first day, end middle last day, remove days analysis: start calculating timing first morning light exposure 50 lux per participant day timing_above_threshold() function. step provided us first timing light 50 lux, , incidentally, also last timing light 50 lux, need intensity evening light. next step, add information dataset. provides us expanded dataset containing light exposure time series (Datetime), information Dusk First timing 50 lux. checking whether observation within first timing light dusk, prepare data final step. , also calculated check evening light. last step calculate mean melanopic EDI state, per participant day. can see every day evening light intensity value. due way calculation set - participant light exposure 50 lux dusk, accompanying value. Also note value seeing participant 202 2023-08-15 8 lux, 50 lux. , due way calculation set . calculate last time participant 50 lux dusk. can well 50 lux dusk last time, yielding lower average melanopic EDI value. final step, aggregate information across participants. can see 102 participant days daytime light condition, 75 participant days evening light condition.","code":"data <-    data |>    mutate(Day = date(Datetime)) |>   filter(Day > min(Day), Day < max(Day)) timing_light_exposure <-   data |>   group_by(Id, Day) |>   summarize(       timing_above_threshold(         MEDI, Datetime, \"above\", 50, na.rm = TRUE, as.df = TRUE         ),     .groups = \"drop\"   )  timing_light_exposure |>    head(4) |>    gt_tab() |>    tab_style(style = cell_text(color = \"red\"),              locations = list(cells_body(4),                              cells_column_labels(4))   ) data <-   data |>   left_join(timing_light_exposure, by = join_by(Id, Day))  data |>    head(4) |>    select(Id, MEDI, Datetime, dusk, first_timing_above_50) |>    ungroup() |>    gt_tab() |>    fmt_datetime(dusk) |>    cols_label(first_timing_above_50 = \"First timing above 50 lux\",              dusk = \"Dusk\") |>    tab_style(style = cell_text(color = \"red\"),              locations = list(cells_body(3:5),                              cells_column_labels(3:5))   ) data <-   data |>    mutate(light.type =             case_when(              between(Datetime, first_timing_above_50, dusk) ~ \"daytime\",              between(Datetime, dusk, last_timing_above_50) ~ \"evening\",              .default = NA)   ) metric <-   data |>   group_by(Id, Day, light.type) |>   summarize(mean_MEDI = mean(MEDI), .groups = \"drop\") |>   drop_na()  metric |>    head(9) |>     gt_tab() |>    fmt_number(mean_MEDI) |>    tab_style(style = cell_fill(color = \"#FDFBD3\"),             locations = cells_body(rows = light.type == \"daytime\")   ) |>    tab_style(style = list(cell_fill(color = \"#003153AA\"),                          cell_text(color = \"white\")),             locations = cells_body(rows = light.type == \"evening\")   ) |>    cols_label(light.type = \"Type\", mean_MEDI = \"mean MEDI (lux)\") metric |>    tbl_summary(by = light.type,                include = mean_MEDI,                label = mean_MEDI ~ \"mean mel EDI (lx)\"               )"},{"path":"https://tscnlab.github.io/LightLogR/articles/photoperiod.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Photoperiod","text":"suite photoperiod functions provides powerful addition toolkit LightLogR, visualizations, metric calculations, simply part analysis process. aspects photoperiods feel missing LightLogR, help us improve submit issue Github.","code":""},{"path":"https://tscnlab.github.io/LightLogR/articles/spectrum.html","id":"importing-data","dir":"Articles","previous_headings":"","what":"Importing Data","title":"Light Spectrum","text":"use data imported cleaned already article Import & Cleaning. can seen using gg_overview(), dataset contains 17 ids one weeks worth data , one three participants per week.","code":"#this assumes the data is in the cleaned_data folder in the working directory data <- readRDS(\"cleaned_data/ll_data.rds\") data |> gg_overview()"},{"path":"https://tscnlab.github.io/LightLogR/articles/spectrum.html","id":"spectral-power-distributions","dir":"Articles","previous_headings":"Importing Data","what":"Spectral power distributions","title":"Light Spectrum","text":"devices output spectral power distribution, SPD, directly. time writing, nanoLambda device, OcuWEAR known provide data directly, least export option. section can skipped device outputs SPDs directly. devices provide information directly, set channels can used reconstruct SPD. time writing, ActLumus VEET devices belong group. form spectral reconstruction needed obtain SPD devices. LightLogR provides one function derive SPDs sensor channels using calibration matrix. **matrices provided LightLogR, acquired manufacturer device, metrology institutions tasked device characterization, users calibration efforts*. going use simple dataset Actlumus device. First load calibration matrix. LightLogR dummy matrix ActLumus device, way substitute real calibration matrix. dummy matrix used testing purposes, used real analysis without checking back manufacturer. relevant column names F1 F8, CLEAR, IR.Light. Calibration matrix Next, apply spectral_reconstruction() function dataset. function takes sensor channels calibration matrix input, returns tibble wavelength irradiance values. function vectorized, can applied multiple rows . Important note: spectral_reconstruction() takes normalized sensor counts inputs. ActLumus device provides values sensor channels, devices may . E.g., VEET device provides raw counts gain value. values normalized first. See documentation normalize_counts() derive normalized counts based raw counts, gain values, gain table. user check documentation device find columns contain normalized sensor counts. start demonstrating function works single observation. SPD rather short, calibration matrix provides 9 wavelength rows. spectral_reconstruction() output many wavelengths, rows calibration matrix. Now add Spectrum whole dataset. function provides two ways . “long” form creates list column, “wide” form adds new columns dataset. “long” form useful plotting spectral integration metrics, “wide” form useful easy “access” individual wavelength values. require long form tutorial list column contains corresponding spectrum. can plot spectra one day example.  plot shows spectra one day, color representing mel EDI. Consequently, irradiance spectrum, higher mel EDI. plot informative, spectra similar, demonstrates derived spectra look plausible.","code":"#Path to data in LightLogR path <- system.file(\"extdata\",                package = \"LightLogR\")  #Load the calibration matrix calib_mtx <-    read_csv(paste(path, \"ActLumus_dummy_calibration_matrix.csv\", sep = \"/\")) #> New names: #> Rows: 9 Columns: 11 #> ── Column specification #> ──────────────────────────────────────────────────────── Delimiter: \",\" dbl #> (11): ...1, W1 (F1), W2 (F2), W3 (F3), W4 (F4), W5 (F5), W6 (F6), W7 (F7... #> ℹ Use `spec()` to retrieve the full column specification for this data. ℹ #> Specify the column types or set `show_col_types = FALSE` to quiet this message. #> • `` -> `...1`  #rename the columns, so that the column names are in line with the actlumus data calib_mtx <-  calib_mtx |>    rename_with( #collect the sensor channel names, which are inside of brackets     ~ str_extract(., pattern = \"(?<=\\\\()[^()]+(?=\\\\))\"), .cols = -`...1`) |>      rename(wavelength = `...1`, #change the first column to wavelength            IR.LIGHT = IR) #rename the IR channel to its name in the dataset  #show a table of the matrix calib_mtx |>    gt(caption = \"Calibration matrix\") |>    fmt_number(columns = -wavelength) #convert the matrix to an actual matrix calib_mtx <-   calib_mtx |> column_to_rownames(\"wavelength\") |> as.matrix() data_aggregated <-  data|>    aggregate_Datetime(unit = \"15 mins\") #aggregate the data to 15 min intervals so as to reduce the amount of data    #collect a single row single_obs <-  data |> ungroup() |>  slice(10^5) |> select(F1:F8, CLEAR, IR.LIGHT)  #apply the function to the single observation spectral_reconstruction(   sensor_channels = single_obs,   calibration_matrix = calib_mtx ) |> gt() # demonstrating the wide form data_aggregated <-  data_aggregated |>    dplyr::mutate(     Spectrum =        spectral_reconstruction(         #important to use dplyr::pick, as it expects a named vector or a          #dataframe (the latter of which pick provides)         dplyr::pick(F1:F8, CLEAR, IR.LIGHT),          calib_mtx,          format = \"wide\"        )   )  #show the first 3 observations data_aggregated |>    select(Id, Datetime, Spectrum) |>    ungroup() |>    slice(2000:(2002)) |>    unnest(Spectrum) |>    gt() |>    fmt_scientific(decimals = 3) # long form data_aggregated <-  data_aggregated|>   mutate(        Spectrum =           spectral_reconstruction(            #important to use dplyr::pick, as it expects a named vector or a             #dataframe (the latter of which pick provides)            pick(F1:F8, CLEAR, IR.LIGHT),             calib_mtx,             format = \"long\" #long is also the default            )        )  #show the first 3 observations data_aggregated |>    ungroup() |>    select(Id, Datetime, Spectrum) |>    head(3) #> # A tibble: 3 × 3 #>   Id    Datetime            Spectrum         #>   <fct> <dttm>              <list>           #> 1 201   2023-08-15 00:00:00 <tibble [9 × 2]> #> 2 201   2023-08-15 00:15:00 <tibble [9 × 2]> #> 3 201   2023-08-15 00:30:00 <tibble [9 × 2]> data_1_day <-  data_aggregated |>    filter_Date(length = \"1 day\") |>    filter(Id == \"201\") |>    add_Time_col()  data_1_day |>    unnest(Spectrum) |> #unnest the list column   ggplot(aes(x=wavelength, y = irradiance, group = Datetime)) +    geom_path(aes(col = MEDI)) +   theme_minimal() +   labs(col = \"mel EDI (lx)\") +    scale_color_viridis_c(trans = \"symlog\", breaks = c(0, 10^(0:5)),                          labels= expression(0,10^0,10^1, 10^2, 10^3, 10^4, 10^5))"},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/articles/spectrum.html","id":"integration","dir":"Articles","previous_headings":"Calculating metrics","what":"Integration","title":"Light Spectrum","text":"spectrum, can calculate various metrics . can done manually, LightLogR provides handy function: spectral_integration(). function allows integrate portions spectrum. E.g., short long wavelength range spectrum interest, can easily calculated . just total irradiance interest, whole spectrum can provided without parameters. setting wavelength_range, function integrate specified range. spectra contained list column, purrr::map_dbl() used obtain single result per observation. results look like? “per participant” summary, see total irradiance, well portions falling short long wavelength ranges respectively. also see, long wavelength range always higher compared short one, expressed ratio.","code":"data_aggregated <-  data_aggregated |>    mutate(     Total_irradiance = Spectrum |> map_dbl(spectral_integration),     short_wl = Spectrum |> map_dbl(spectral_integration,                            wavelength.range = c(300, 500)),     long_wl = Spectrum |> map_dbl(spectral_integration,                            wavelength.range = c(600, 800)),     short_long_ratio = short_wl / long_wl   ) #summarize spectral data per participant data_aggregated |>    select(Id, Total_irradiance, short_wl, long_wl, short_long_ratio) |>    summarize_numeric() |>    head() |>    gt() |>    fmt_number()"},{"path":"https://tscnlab.github.io/LightLogR/articles/spectrum.html","id":"weighted-integration","dir":"Articles","previous_headings":"Calculating metrics","what":"Weighted integration","title":"Light Spectrum","text":"spectral_integration() also allows calculate weigthed integrations. Examples weigthed integrations illuminance (weighed photopic action spectrum), melanopic EDI (weighed melanopic action spectrum), also alphaopic metrics. spectrum can provided function via action.spectrum argument (see documentation info). also number inbuilt spectra: photopic: photopic action spectrum melanopic: melanopic action spectrum rhodopic: rhodopic action spectrum l_cone_opic: L-cone action spectrum m_cone_opic: M-cone action spectrum s_cone_opic: S-cone action spectrum basis integration can found dataset alphaopic.action.spectra.  final step, calculate illuminance melanopic EDI Spectra compare derived values ActLumus direct export. function return value lx mel EDI depending action spectrum provided.   strong deviations wearable data reconstructed spectrum, especially lower regions melanopic EDI? three likely reasons : calibration matrix used reconstruction used recording data Another method conversion used internal routines check implausible values (negative values). Indeed, ActLumus devices calibration matrices photopic alphaopic quantity, can explain differences seen. LightLogRs goal reproduce every manufacturers internal routines, rather provide standardized pipelines analysis. Wearable devices laboratory-grade measurement devices, treated . Thus, users can work derived spectra, care.","code":"#show the action spectra alphaopic.action.spectra |>    pivot_longer(cols = -wavelength) |>    drop_na() |>    ggplot(aes(x = wavelength, y = value)) +    geom_line(aes(col = name)) +   theme_minimal() +   labs(col = \"Action spectrum\") +   scale_color_manual(values = c(\"limegreen\",\"darkred\", \"#1D63DC\", \"gold1\",                                 \"grey60\", \"darkviolet\")) data_aggregated <-  data_aggregated |>    mutate(     illuminance = Spectrum |> map_dbl(spectral_integration,                                       action.spectrum = \"photopic\",                                       general.weight = \"auto\"),     melEDI = Spectrum |> map_dbl(spectral_integration,                            action.spectrum = \"melanopic\",                           general.weight = \"auto\")     )  data_aggregated |>    select(Id, Datetime, LIGHT, MEDI, illuminance, melEDI) |>    add_Time_col() |>    ggplot(aes(x=MEDI, y = melEDI)) +   geom_point(aes(col = abs(1- MEDI/melEDI))) +    geom_abline(slope = 1, intercept = 0, col = \"red\", linetype = 2) +    theme_minimal() +   scale_color_viridis_c(trans = \"symlog\",                          limits = c(0, 5),                         breaks = c(0, 0.5, 1, 5, 10),                         labels = scales::label_percent())+   scale_x_continuous(trans = \"symlog\",                                            breaks = c(-1, 0, 10^(0:5)),                       labels= expression(-1, 0, 1,10, 10^2, 10^3, 10^4, 10^5)                      ) +   scale_y_continuous(trans = \"symlog\",                                            breaks = c(-100, -10, -1, 0, 10^(0:5)),                       labels= expression(-10^2, -10, -1, 0,1,10, 10^2, 10^3, 10^4, 10^5)                      ) data_aggregated |>    select(Id, Datetime, LIGHT, MEDI, illuminance, melEDI) |>    add_Time_col() |>    ggplot(aes(x=LIGHT, y = illuminance)) +   geom_point(aes(col = abs(1- LIGHT/illuminance))) +    geom_abline(slope = 1, intercept = 0, col = \"red\", linetype = 2) +    theme_minimal() +   scale_color_viridis_c(trans = \"symlog\",                          limits = c(0, 5),                         breaks = c(0, 0.5, 1, 5, 10),                         labels = scales::label_percent())+   scale_x_continuous(trans = \"symlog\",                                            breaks = c(-1, 0, 10^(0:5)),                       labels= expression(-1, 0, 1,10, 10^2, 10^3, 10^4, 10^5)                      ) +   scale_y_continuous(trans = \"symlog\",                                            breaks = c(-100, -10, -1, 0, 10^(0:5)),                       labels= expression(-10^2, -10, -1, 0,1,10, 10^2, 10^3, 10^4, 10^5)                      )"},{"path":"https://tscnlab.github.io/LightLogR/articles/states.html","id":"importing-data","dir":"Articles","previous_headings":"","what":"Importing Data","title":"Durations, States and Clusters","text":"use data imported cleaned already article Import & Cleaning. can seen using gg_overview(), dataset contains 17 ids one weeks worth data , one three participants per week.","code":"#this assumes the data is in the cleaned_data folder in the working directory data <- readRDS(\"cleaned_data/ll_data.rds\") data |> gg_overview()"},{"path":"https://tscnlab.github.io/LightLogR/articles/states.html","id":"creating-states","dir":"Articles","previous_headings":"","what":"Creating states","title":"Durations, States and Clusters","text":"Whether existing states part data much depends devices employed data. wear non-wear indicators (usually wrist-worn devices) sleep/wake state. time, however, states added created data. simple example binned continuous variables light exposure. melanopic EDI, typical look episodes ≤1lx (recommended sleep environment), ≤10lx( recommended evening), ≥250lx (recommended daytime). many states can created established data analysis pipelines, dive . Rather, focus use variables, created. start adding example dataset. Brown_cut() exactly adds new column state dataset. can choose cutoff values, labels, state name, use defaults . also filter dataset include two participants 1 minute intervals, make plots manageable. One first questions analyst might adding states dataset : long state last? states appear?. important question, can used assess quality data, also assess validity created states. example, participant spends 90% time state, might indication state well defined. simple quantification states, durations() can used. return tibble duration group. default, divide participant (default group), can easily adjusted. also provide variable, function can check much data missing (.e., NA) much present. , alongside summary statistics useful assess quality data. good start, might require additional information - example mean melanopic EDI state, actigraphy TAT (time threshold) . can add summary extract_metric(). function requires extract original dataset input. answers first question, states appear? visual representation, can use gg_state(), add-gg_day() gg_days(). Brown_cut() created factor variable NA factor level, makes sense convert NA levels real NA values. can done forcats::fct_na_level_to_value().  numeric representation can achieved extract_states(). far granular representation compared result derived durations(). , every episode state one row, start, end, duration, epoch. , can add metrics summary extract_metric(). universal function summarize_numeric(), can condense data . number rows identical extract durations(), gain insights number episodes long active. Note extracted metrics different durations(). reason metrics calculated episode, averaged. means average durations() deviates average averages . important keep mind interpreting results. can get overall mean regrouping state, calculates averages across participants.","code":"dataset <-  data |>    filter(Id %in% c(\"201\", \"202\")) |>    aggregate_Datetime(unit = \"1 min\") |>        Brown_cut()  dataset |>  ungroup() |>    count(state) |>    gt() #without grouping dataset |>    durations() #> # A tibble: 2 × 2 #> # Groups:   Id [2] #>   Id    duration          #>   <fct> <Duration>        #> 1 201   518460s (~6 days) #> 2 202   518460s (~6 days)  #providing a variable and show additional stats dataset |>    durations(MEDI, show.missing = TRUE, show.interval = TRUE) #> # A tibble: 2 × 5 #> # Groups:   Id [2] #>   Id    duration          missing    total             interval         #>   <fct> <Duration>        <Duration> <Duration>        <Duration>       #> 1 201   518460s (~6 days) 0s         518460s (~6 days) 60s (~1 minutes) #> 2 202   518460s (~6 days) 0s         518460s (~6 days) 60s (~1 minutes)  #extend grouping extract <-  dataset |>    group_by(state, .add = TRUE) |>    durations(MEDI) |>    ungroup(state)  extract |> gt() #add metrics extract |>     extract_metric(     dataset,     identifying.colname = state,      MEDI = mean(MEDI),     TAT = mean(TAT)   ) |>    gt() |>    fmt_number(c(MEDI, TAT)) #helper for colors color <-   ggplot2::scale_fill_manual(     values=c(`≤1lx` = \"#868686FF\", `≤10lx` = \"#EFC000FF\", `≥250lx` = \"#0073C2FF\")     )  #plotting states dataset |>    mutate(state = fct_na_level_to_value(state)) |>    filter_Date(length = \"3 days\") |>    gg_days() |>    gg_state(state, aes_fill = state) +   color #extract states extract <-  dataset |>    extract_states(     state   )  extract |> head(3) |> gt() extract <-  extract |>    extract_metric(     dataset,     identifying.colname = state.count,      MEDI = mean(MEDI),     TAT = mean(TAT)   )  extract |>    head(3) |>    gt() |>    fmt_number(c(MEDI, TAT)) extract |>    summarize_numeric(remove = c(\"epoch\")) |>    gt() |>    fmt_number(c(mean_MEDI, mean_TAT)) |>    fmt_datetime(2:3) |>    fmt_duration(contains(\"duration\"), input_units = \"seconds\") extract |>    summarize_numeric(remove = c(\"epoch\", \"start\", \"end\")) |>    group_by(state) |>    summarize_numeric(prefix = \"\") |>    gt() |>    fmt_number(c(mean_MEDI, mean_TAT)) |>    fmt_datetime(2:3) |>    fmt_duration(contains(\"duration\"), input_units = \"seconds\")"},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/articles/states.html","id":"principles","dir":"Articles","previous_headings":"Adding states","what":"Principles","title":"Durations, States and Clusters","text":"Adding states dataset common task data analysis. generally, column extract can added dataset add_states() - one simply needs specify start end columns . Let’s assume interested looking brightest 10 hour period day. require summary, want work state context dataset. start grouping data day, reveals problem, last datapoint group falls exactly midnight, thus single datapoint group. midnight cases often problematic - case six full days data, overhang. best remove single datapoint groups, easy remove_partial_data(). function throw message irregular/singular groups, remove . Now can calculate metric provides us table brightest 10 hours day, want add dataset. can done add_states(). added column M10 dataset, logical variable indicating whether datapoint part brightest 10 hours. can now use variable analysis, example plot data.","code":"dataset |>    # group_by(Id, Date = date(Datetime)) |>    durations() |>    head(7) #> # A tibble: 2 × 2 #> # Groups:   Id [2] #>   Id    duration          #>   <fct> <Duration>        #> 1 201   518460s (~6 days) #> 2 202   518460s (~6 days) #removing partial data dataset <-    dataset |>    group_by(Id, Date = date(Datetime)) |>    remove_partial_data() #> This dataset has irregular or singular data. Singular data will automatically be removed. If you are uncertain about irregular data, you can check them with `gap_finder`, `gap_table`, and `gg_gaps`. #calculate the brightest 10 hours M10 <-   dataset |>    group_by(Id, Date = date(Datetime)) |>    summarize(     bright_dark_period(               Light.vector = MEDI,               Time.vector = Datetime,               as.df = TRUE,               period = \"brightest\",               timespan = \"10 hours\"               ),     .groups = \"drop_last\"   )  M10 |> head() |> gt() |> fmt_number() #adding the brightest 10 hours to the dataset dataset <-   dataset |>    add_states(     M10 |> mutate(M10 = TRUE),     start.colname = brightest_10h_onset,     end.colname = brightest_10h_offset,      leave.out = c(\"brightest_10h_midpoint\", \"brightest_10h_mean\")   ) dataset |>   ungroup(Date) |>    gg_days() |>    gg_state(M10, fill = \"yellow2\")"},{"path":"https://tscnlab.github.io/LightLogR/articles/states.html","id":"example-sleepwake-data","dir":"Articles","previous_headings":"Adding states","what":"Example sleep/wake data","title":"Durations, States and Clusters","text":"special form external state data coming , e.g., diaries. often case sleep/wake data. example, add sleep/wake data dataset.","code":""},{"path":"https://tscnlab.github.io/LightLogR/articles/states.html","id":"preparation","dir":"Articles","previous_headings":"Adding states > Example sleep/wake data","what":"Preparation","title":"Durations, States and Clusters","text":"Next importing sleep data participant Id = 205, included LightLogR: data gets added dataset interval2state() function sc2interval() function. inbetween step two functions give us option also add Brown et al. 2022 recommendations healthy light, can extracted sleep/wake data.","code":"#filter the dataset data_205 <-   data |> filter(Id == \"205\") #the the path to the sleep data path <- system.file(\"extdata\",                package = \"LightLogR\") file.sleep <- \"205_sleepdiary_all_20230904.csv\" #import sleep/wake data dataset.sleep <-    import_Statechanges(file.sleep, path,                        Datetime.format = \"dmyHM\",                       State.colnames = c(\"sleep\", \"offset\"),                       State.encoding = c(\"sleep\", \"wake\"),                       Id.colname = record_id,                       sep = \";\",                       dec = \",\",                       tz = \"Europe/Berlin\") #>  #> Successfully read in 14 observations across 1 Ids from 1 Statechanges-file(s). #> Timezone set is Europe/Berlin. #> The system timezone is UTC. Please correct if necessary! #>  #> First Observation: 2023-08-28 23:20:00 #> Last Observation: 2023-09-04 07:25:00 #> Timespan: 6.3 days #>  #> Observation intervals:  #>    Id    interval.time             n pct   #>  1 205   34860s (~9.68 hours)      1 8%    #>  2 205   35520s (~9.87 hours)      1 8%    #>  3 205   35700s (~9.92 hours)      1 8%    #>  4 205   36000s (~10 hours)        1 8%    #>  5 205   36900s (~10.25 hours)     1 8%    #>  6 205   37020s (~10.28 hours)     1 8%    #>  7 205   37920s (~10.53 hours)     1 8%    #>  8 205   45780s (~12.72 hours)     1 8%    #>  9 205   48480s (~13.47 hours)     1 8%    #> 10 205   49200s (~13.67 hours)     1 8%    #> # ℹ 3 more rows data_205 <-   data_205 |>   interval2state(dataset.sleep |> sc2interval()) |> #add sleep/wake-data   interval2state(     dataset.sleep |> sc2interval() |> sleep_int2Brown(),      State.colname = State.Brown) #add Brown et al. 2022 states"},{"path":"https://tscnlab.github.io/LightLogR/articles/states.html","id":"sleepwake","dir":"Articles","previous_headings":"Adding states > Example sleep/wake data","what":"Sleep/Wake","title":"Durations, States and Clusters","text":"Adding sleep-wake information base plot.  want know duration sleep-wake states? can number states function number_states(). long singular missing instances (like sleep instance middle), yield good result.","code":"data_205 |>    aggregate_Datetime(unit = \"5 mins\") |>    gg_days() |>    gg_state(State, aes_fill = State) data_205 |>    number_states(State, use.original.state = FALSE) |>    mutate(     State.count = paste0(\"SW-cycle \", State.count)   ) |>   group_by(State.count) |>    extract_states(State.count) |>    select(-state.count) |>    ungroup() |>    gt() |>    tab_header(\"Sleep/Wake cycles\")"},{"path":"https://tscnlab.github.io/LightLogR/articles/states.html","id":"brown-recommendations","dir":"Articles","previous_headings":"Adding states > Example sleep/wake data","what":"Brown recommendations","title":"Durations, States and Clusters","text":"can even go step beyond, show times participant complied recommendations. employ helper function Brown2reference() creates additional columns, including one tests whether light exposure level within required range (Reference.check). select column gg_state(), can color State.Brown , get selection recommendation actually met.  can check well recommendations followed using durations().","code":"data_205 |>    gg_day(geom = \"line\") |>    gg_state(State.Brown, aes_fill = State.Brown) +   labs(fill = \"Brown states\") data_205 |>    Brown2reference() |>   group_by(State.Brown, .add = TRUE) |>   gg_day(geom = \"line\") |>    gg_state(Reference.check, aes_fill = State.Brown) +   labs(fill = \"Following\\nrecommendations\\nduring the\") data_205 |>    Brown2reference() |>    group_by(State.Brown, .add = TRUE) |>   durations(Reference.check, show.missing = TRUE, FALSE.as.NA = TRUE) |>    mutate(     compliance = (duration/total) |> scales::percent()   ) |>    ungroup() |>    gt()"},{"path":"https://tscnlab.github.io/LightLogR/articles/states.html","id":"photoperiods","dir":"Articles","previous_headings":"Adding states > Example sleep/wake data","what":"Photoperiods","title":"Durations, States and Clusters","text":"Photoperiods powerful way give context light exposure data. Photoperiods require coordinates data collected. whole article photoperiods, can found .","code":"#visualize photoperiods data_205 |>    aggregate_Datetime(unit = \"15 mins\", type = \"floor\") |>    add_photoperiod(c(48.5, 9)) |>    gg_days() |>    gg_photoperiod() #summarize photoperiods data_205 |>    add_photoperiod(c(48.5, 9)) |>    group_by(photoperiod.state, Date = date(Datetime)) |>   durations() |>    ungroup(Date) |>    slice(1:3) |>    gt()"},{"path":"https://tscnlab.github.io/LightLogR/articles/states.html","id":"clusters","dir":"Articles","previous_headings":"","what":"Clusters","title":"Durations, States and Clusters","text":"Clusters, defined , states can interruptions still considered one episode. example make clear. Let us say interest periods 250 lx melanopic EDI. participant 205, look sth. like :  shows , average, participant 105 seconds 250 lx per episode, around 940 episodes across week total. want know often participant spent 30 minutes 250 lx? clusters come . can use extract_clusters() find periods. six days measurement, participant spent 12 episodes 30 minutes 250 lx, average duration 45 minutes. good example clusters can used summarize data meaningful way. Another trick clusters , ability allow interruptions. Let’s say looking periods 30 minutes , allowing interruptions 3 minutes. change results? leads expected rise number episodes (12 19), increase average duration (45 minutes 100 minutes). important note, interruption duration cumulative. theory, one bright/dark/bright/dark/… 2 minutes , count towards cluster episode. can also add clusters dataset, can useful analysis. done add_clusters(), works similar add_states(). difference need provide cluster properties. state can now used way state. example, can plot data gg_state().  concludes article states, clusters, durations. seen create states, add dataset, extract useful information . also seen work clusters visualize .","code":"data_205 <-  data_205 |>    mutate(     above_250 = MEDI >= 250)  data_205 |>    gg_days() |>    gg_state(above_250, fill = \"skyblue4\") +   labs(title = \"Episodes above 250 lx\") data_205 |>    extract_states(above_250) |>    summarize_numeric() |>    gt()|> tab_header(\"Episodes above 250 lx\") data_205 |>    extract_clusters(     above_250,     cluster.duration = \"30 mins\"   ) |>    summarize_numeric() |>    gt() |> tab_header(\"Clusters of 30 minutes or more above 250 lx\") data_205 |>    extract_clusters(     above_250,     cluster.duration = \"30 mins\",      interruption.duration = \"3 mins\"   ) |>    summarize_numeric() |>    gt()|>    tab_header(\"Clusters of 30 minutes or more above 250 lx\",                     subtitle = \"with interruptions of up to 3 minutes\") data_205 <-    data_205 |>    add_clusters(     above_250,     cluster.duration = \"30 mins\",     interruption.duration = \"3 mins\",      cluster.colname = above_250_cluster   ) data_205 |>    filter_Date(length = \"4 days\") |>    aggregate_Datetime(unit = \"3 mins\", type = \"floor\") |>   gg_days() |>    gg_state(above_250_cluster, fill = \"skyblue4\") +   labs(title = \"Clusters above 250 lx\")"},{"path":"https://tscnlab.github.io/LightLogR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Johannes Zauner. Author, maintainer. Manuel Spitschan. Author. Steffen Hartmeyer. Author. European Partnership Metrology. Funder.           project (22NRM05 MeLiDos) received funding European Partnership Metrology, co-financed European Union's Horizon Europe Research Innovation Programme, EURAMET, Participating States. Views opinions expressed authors necessarily reflect European Union EURAMET. Translational Sensory Circadian Neuroscience Unit (MPS/TUM/TUMCREATE). Copyright holder.           www.tscnlab.org","code":""},{"path":"https://tscnlab.github.io/LightLogR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Zauner, J., Hartmeyer, S., & Spitschan, M. (2025). LightLogR: Reproducible analysis personal light exposure data. Journal Open Source Software, 10(107), 7601. https://doi.org/10.21105/joss.07601. RRID:SCR_025408","code":"@Article{,   title = {LightLogR: Reproducible analysis of personal light exposure data},   author = {Johannes Zauner and Steffen Hartmeyer and Manuel Spitschan},   journal = {Journal of Open Source Software},   year = {2025},   volume = {10},   number = {107},   pages = {7601},   doi = {10.21105/joss.07601},   url = {https://doi.org/10.21105/joss.07601}, }"},{"path":"https://tscnlab.github.io/LightLogR/index.html","id":"lightlogr-","dir":"","previous_headings":"","what":"Process Data from Wearable Light Loggers and Optical Radiation Dosimeters","title":"Process Data from Wearable Light Loggers and Optical Radiation Dosimeters","text":"Personalized luminous exposure data progressively gaining importance various sectors, including research, occupational affairs, fitness tracking. Data collected proliferating selection wearable loggers dosimeters, varying size, shape, functionality, output format. Despite maybe numerous use cases, field lacks unified framework collecting, validating, analyzing accumulated data. issue increases time expertise necessary handle data also compromises FAIRness (Findability, Accessibility, Interoperability, Reusability) results, especially meta-analyses. Light logger data can powerfully convey insights personal light exposure LightLogR package development part MeLiDos project address issues. package aims provide tools : Import common measurement devices (see list Supported devices) Cleaning processing light logging data Visualization light exposure data, exploratory publication ready Calculation common analysis parameters (see list Metrics) come: Import, creation, verification crucial metadata Semi-automated analysis visualization (command-line GUI-based) Integration data unified database cross-study analyses","code":""},{"path":"https://tscnlab.github.io/LightLogR/index.html","id":"please-note-that-lightlogr-is-work-in-progress-if-you-are-interested-in-the-project-and-want-to-know-more-you-can-subscribe-to-the-lightlogr-mailing-list-if-you-find-a-bug-or-would-like-to-see-new-or-improved-features-please-open-an-issue-on-the-github-repository","dir":"","previous_headings":"","what":"Please note that LightLogR is work in progress! If you are interested in the project and want to know more, you can subscribe to the LightLogR mailing list. If you find a bug or would like to see new or improved features, please open an issue on the GitHub repository.","title":"Process Data from Wearable Light Loggers and Optical Radiation Dosimeters","text":"look Example section get started, dive Articles get depth information work package generate images one , import data, visualization, metric calculation.","code":""},{"path":"https://tscnlab.github.io/LightLogR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Process Data from Wearable Light Loggers and Optical Radiation Dosimeters","text":"can install LightLogR CRAN : can install latest development version LightLogR GitHub :","code":"install.packages(\"LightLogR\") # install.packages(\"devtools\") devtools::install_github(\"tscnlab/LightLogR\")"},{"path":"https://tscnlab.github.io/LightLogR/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Process Data from Wearable Light Loggers and Optical Radiation Dosimeters","text":"quick starter use LightLogR.","code":"library(LightLogR) #the following packages are needed for the examples as shown below. library(flextable) library(dplyr) library(ggplot2)"},{"path":"https://tscnlab.github.io/LightLogR/index.html","id":"import","dir":"","previous_headings":"Example","what":"Import","title":"Process Data from Wearable Light Loggers and Optical Radiation Dosimeters","text":"can import light logger dataset ease. import functions give quick, helpful feedback dataset.  complex data, useful gg_overview() function get immediate grasp data. automatically called import (set auto.plot = FALSE suppress ), really shines datasets multiple participants. also indicates data missing, based measurement epochs found data. Example gg_overview() large data collection effort many months note: example image requires large dataset, included package. available, however, article Import & cleaning.","code":"filename <-    system.file(\"extdata/205_actlumus_Log_1020_20230904101707532.txt.zip\",                package = \"LightLogR\") dataset <- import$ActLumus(filename, \"Europe/Berlin\", manual.id = \"P1\") #>  #> Successfully read in 61'016 observations across 1 Ids from 1 ActLumus-file(s). #> Timezone set is Europe/Berlin. #>  #> First Observation: 2023-08-28 08:47:54 #> Last Observation: 2023-09-04 10:17:04 #> Timespan: 7.1 days #>  #> Observation intervals:  #>   Id    interval.time     n pct   #> 1 P1    10s           61015 100% #example code, on how to use gg_overview(): dataset %>% gg_overview()"},{"path":"https://tscnlab.github.io/LightLogR/index.html","id":"visualize","dir":"","previous_headings":"Example","what":"Visualize","title":"Process Data from Wearable Light Loggers and Optical Radiation Dosimeters","text":"imported, LightLogR many convenient visualization options.  wide range options gg_days() function customize output. look reference page (?gg_days) see options. can also override defaults, e.g., different color, facetting, theme options. Helper functions can prepare data (e.g. aggregate coarser intervals), add plot (e.g., add conditions, nighttime)","code":"dataset %>% gg_days() dataset |>    #change the interval from 10 seconds to 15 minutes:   aggregate_Datetime(\"15 min\") |>    #create groups of 3-hour intervals:   cut_Datetime(\"3 hours\") |>    #plot creation, with a boxplot:   gg_days(geom = \"boxplot\", group = Datetime.rounded) |>    #adding nighttime indicators:   gg_photoperiod(c(47.9,9)) +    # the output is a standard ggplot, and can be manipulated that way   geom_line(col = \"red\", linewidth = 0.25) +    labs(title = \"Personal light exposure across a week\",         subtitle = \"Boxplot in 3-hour bins\")"},{"path":"https://tscnlab.github.io/LightLogR/index.html","id":"more-than-one-dataset","dir":"","previous_headings":"Example","what":"More than one dataset","title":"Process Data from Wearable Light Loggers and Optical Radiation Dosimeters","text":"built-dataset sample.data.environment shows combined dataset light logger data second set data - case unobstructed outdoor light measurements. Combined datasets can easily visualized gg_day(). col parameter used Id column dataset allows color separation. gg_day() show plots always facetted day, whereas gg_days() shows timeline days group. functions opinionated terms scaling linebreaks show whole days, can adjusted. many ways enhance plots - , e.g., look periods least 1 hour 250 lx, can add visualize periods easily  visualizations try - article Visualizations dives -depths.","code":"sample.data.environment %>%    gg_day(     start.date = \"2023-09-01\",     aes_col = Id,     geom = \"line\") +    theme(legend.position = \"bottom\") #> Only Dates will be used from start.date and end.date input. If you also want to set Datetimes or Times, consider using the `filter_Datetime()` function instead. sample.data.environment %>%    #search for these conditions:   add_clusters(MEDI > 250, cluster.duration = \"30 min\") |>    #base plot + add the condition   gg_days() |>    gg_state(state, fill = \"red\") +    #standard ggplot:   geom_hline(yintercept = 250, col = \"red\", linetype = \"dashed\") +    labs(title = \"Periods > 250 lx mel EDI for more than 30 minutes\") sample.data.environment |> gg_heatmap(doubleplot = \"next\")"},{"path":"https://tscnlab.github.io/LightLogR/index.html","id":"metrics","dir":"","previous_headings":"Example","what":"Metrics","title":"Process Data from Wearable Light Loggers and Optical Radiation Dosimeters","text":"many Metrics used literature condensing personalized light exposure time series singular values. LightLogR rather comprehensive number metrics consistent, easy--use interface. types metrics can derived less formally durations(), extract_state() extract_cluster() function. second row indicates status true. identical : interested often threshold crossed, long? see roughly one thousand instances across week 250 lx reached, lasted two minutes average. many long periods , say 30 minutes? might short interruption, consider irrelevant, ignoring interruptions 1 minute. area clusters. see 17 instances across week, lasting, average, bit hour (sitting aroung 14:00 - 15:00). Directly relating total duration 1.29 days time 250 lx misleading, however. , interruptions present. prominent interruptions? Thus find 4% long exposure periods made interruptions, just shy 50 minutes 20 hours.","code":"sample.data.environment |> # two groups: participant and environment   filter_Date(length = \"2 days\") |> #filter to three days each for better overview   group_by(Day = lubridate::date(Datetime), .add = TRUE) |>  #add grouping per day   summarize(     #time above 250 lx mel EDI:     duration_above_threshold(MEDI, Datetime, threshold = 250, as.df = TRUE),     #intradaily variability (IV):     intradaily_variability(MEDI, Datetime, as.df = TRUE),     #... as many more metrics as are desired     .groups = \"drop\"   ) #> # A tibble: 4 × 4 #>   Id          Day        duration_above_250    intradaily_variability #>   <fct>       <date>     <Duration>                             <dbl> #> 1 Environment 2023-08-29 48240s (~13.4 hours)                   0.248 #> 2 Environment 2023-08-30 49350s (~13.71 hours)                  0.168 #> 3 Participant 2023-08-29 5810s (~1.61 hours)                    1.23  #> 4 Participant 2023-08-30 9960s (~2.77 hours)                    0.821 dataset |>    gap_handler(full.days = TRUE) |> #extend the viewed time until midnight of the first and last day   durations(MEDI, show.missing = TRUE) #> # A tibble: 1 × 4 #> # Groups:   Id [1] #>   Id    duration              missing               total                 #>   <fct> <Duration>            <Duration>            <Duration>            #> 1 P1    610160s (~1.01 weeks) 81040s (~22.51 hours) 691200s (~1.14 weeks)  dataset |>    group_by(TAT250 = MEDI >= 250, .add = TRUE) |> #creating a grouping column that checks for values above 250lx   durations(MEDI) #> # A tibble: 2 × 3 #> # Groups:   Id, TAT250 [2] #>   Id    TAT250 duration             #>   <fct> <lgl>  <Duration>           #> 1 P1    FALSE  498530s (~5.77 days) #> 2 P1    TRUE   111630s (~1.29 days) dataset |>    summarize(     duration_above_threshold(MEDI, Datetime, threshold = 250, as.df = TRUE),     .groups = \"drop\"   ) #> # A tibble: 1 × 2 #>   Id    duration_above_250   #>   <fct> <Duration>           #> 1 P1    111630s (~1.29 days) dataset |>    extract_states(TAT250, MEDI >= 250) |> #extract a list of states   summarize_numeric() |> #summarize the numeric values   select(Id, TAT250, mean_duration, episodes, total_duration) #collect a subset #> # A tibble: 2 × 5 #> # Groups:   Id [1] #>   Id    TAT250 mean_duration        episodes total_duration       #>   <fct> <lgl>  <Duration>              <int> <Duration>           #> 1 P1    FALSE  482s (~8.03 minutes)     1034 498530s (~5.77 days) #> 2 P1    TRUE   108s (~1.8 minutes)      1034 111630s (~1.29 days) dataset |>    extract_clusters(MEDI >= 250, #base condition                    cluster.duration = \"30 mins\", #search for at least 30 minute instances                    interruption.duration = \"1 min\", #allow 1 minute interrupts                    add.label = TRUE) |> #add a description of the conditions   group_by(label) |> #group by the label so it does not get removed next   summarize_numeric() |> #summarize the output   select(-mean_epoch) #collect a subset #> # A tibble: 1 × 6 #>   label   mean_start mean_end mean_duration       total_duration        episodes #>   <chr>   <time>     <time>   <Duration>          <Duration>               <int> #> 1 MEDI>=… 13:50:47   15:02:14 4288s (~1.19 hours) 72890s (~20.25 hours)       17 dataset |>    extract_clusters(MEDI >= 250, #base condition                    cluster.duration = \"30 mins\", #search for at least 30 minute instances                    interruption.duration = \"1 min\", #allow 1 minute interrupts                    add.label = TRUE) |>   #extract the metric:   extract_metric(dataset, rel_interrupt = sum(MEDI < 250)/n()) |>    summarize_numeric(prefix = \"\") |> #summarize the output   select(episodes, total_duration, rel_interrupt) |>   #collect a subset   mutate(interrupt_duration = (total_duration*rel_interrupt) |> round(), #calculate interrupt          rel_interrupt = rel_interrupt |> scales::percent_format(1)()) #> # A tibble: 1 × 4 #>   episodes total_duration        rel_interrupt interrupt_duration     #>      <int> <Duration>            <chr>         <Duration>             #> 1       17 72890s (~20.25 hours) 4%            2918s (~48.63 minutes)"},{"path":"https://tscnlab.github.io/LightLogR/index.html","id":"gaps-and-cleaning","dir":"","previous_headings":"Example","what":"Gaps and cleaning","title":"Process Data from Wearable Light Loggers and Optical Radiation Dosimeters","text":"LightLogR provides range functions get insight light logger data. importantly, can search eliminate implicit gaps. import, already get sense intervals, can always show count_difftime(). can eliminate gap_handler() function. function automatically fill gaps NA values. function impute interpolate data. dominant interval dataset now 15 seconds anymore (intermediate datapoints added), need specify epoch gap_finder(). want force data regular, can use aggregate_Datetime() function. aggregate data specified epoch. sensible defaults aggregate numeric, categorical, logical data. can also specify aggregation functions. also convenient functions extract (extract_gaps()), summarize (gap_table()) visualize (gg_gaps()) gaps.  Finally, remove_partial_data() easily gets rid groups days provide enough data.","code":"sample.data.irregular |> has_irregulars() #> [1] TRUE sample.data.irregular |> has_gaps() #> [1] TRUE sample.data.irregular %>% count_difftime() #> # A tibble: 4 × 4 #> # Groups:   Id [1] #>   Id    difftime       n group.indices #>   <chr> <Duration> <int>         <int> #> 1 P1    15s        10015             1 #> 2 P1    16s         1367             1 #> 3 P1    17s           23             1 #> 4 P1    18s           16             1 sample.data.irregular |> gap_handler() |> has_gaps(epoch = \"15 secs\") #> [1] FALSE sample.data.irregular |>     aggregate_Datetime(unit = \"20 sec\") |>    has_gaps() #> [1] FALSE dataset |> gg_gaps() #> Warning: Removed 8104 rows containing missing values or values outside the scale range #> (`geom_line()`). dataset |>    remove_partial_data(MEDI, #variable for which to check missingness                       threshold.missing = \"2 hours\", #remove when more than 2 hours are missing                       by.date = TRUE, #check the condition per day, not the whole participant                       handle.gaps = TRUE) |>  #go beyond the available data to midnight of the first and last day   gg_days()"},{"path":"https://tscnlab.github.io/LightLogR/index.html","id":"supported-devices","dir":"","previous_headings":"","what":"Supported devices","title":"Process Data from Wearable Light Loggers and Optical Radiation Dosimeters","text":"present, devices support LightLogR: Actiwatch_Spectrum Actiwatch_Spectrum_de ActLumus ActTrust Circadian_Eye Clouclip DeLux GENEActiv_GGIR Kronowise LiDo LightWatcher LIMO LYS MotionWatch8 nanoLambda OcuWEAR Speccy SpectraWear VEET Information devices can found reference import_Dataset(). want know import data devices, look article Import & Cleaning. using device currently supported, please contact developers. always looking expand range supported devices. easiest trackable way get contact opening new issue Github repository. Please also provide sample file data, can test import function.","code":""},{"path":"https://tscnlab.github.io/LightLogR/index.html","id":"metrics-1","dir":"","previous_headings":"","what":"Metrics","title":"Process Data from Wearable Light Loggers and Optical Radiation Dosimeters","text":"LightLogR supports wide range metrics across different metric families. can find full documentation metrics functions reference section. also overview article use Metrics. like use metric don’t find represented LightLogR, please contact developers. easiest trackable way get contact opening new issue Github repository.","code":""},{"path":"https://tscnlab.github.io/LightLogR/index.html","id":"about-the-creation-and-funding-of-lightlogr","dir":"","previous_headings":"","what":"About the creation and funding of LightLogR","title":"Process Data from Wearable Light Loggers and Optical Radiation Dosimeters","text":"LightLogR developed Translational Sensory & Circadian Neuroscience lab, joint group Technical University Munich Max Planck Institute Biological Neuroscience Unit (MPS/TUM/TUMCREATE)*, joint group based Technical University Munich, TUMCREATE, Max Planck Institute Biological Cybernetics. MeLiDos joint, EURAMET-funded project involving sixteen partners across Europe, aimed developing metrology standard workflow wearable light logger data optical radiation dosimeters. primary contributions towards fostering FAIR data include development common file format, robust metadata descriptors, accompanying open-source software ecosystem.  project (22NRM05 MeLiDos) received funding European Partnership Metrology, co-financed European Union’s Horizon Europe Research Innovation Programme Participating States. Views opinions expressed however author(s) necessarily reflect European Union EURAMET. Neither European Union granting authority can held responsible .","code":""},{"path":"https://tscnlab.github.io/LightLogR/index.html","id":"i-want-to-contribute","dir":"","previous_headings":"","what":"I Want To Contribute","title":"Process Data from Wearable Light Loggers and Optical Radiation Dosimeters","text":"types contributions encouraged valued. See CONTRIBUTING section different ways help details project handles . project everyone participating governed LightLogR Code Conduct.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown2reference.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Brown et al. (2022) reference illuminance to a dataset — Brown2reference","title":"Add Brown et al. (2022) reference illuminance to a dataset — Brown2reference","text":"Adds several columns light logger dataset. requires column contains Brown states, e.g. \"daytime\", \"evening\", \"night\". function add column recommended illuminance, column checks illuminance dataset within recommended illuminance levels, column gives label reference.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown2reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Brown et al. (2022) reference illuminance to a dataset — Brown2reference","text":"","code":"Brown2reference(   dataset,   MEDI.colname = MEDI,   Brown.state.colname = State.Brown,   Brown.rec.colname = Reference,   Reference.label = \"Brown et al. (2022)\",   overwrite = FALSE,   ... )"},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown2reference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Brown et al. (2022) reference illuminance to a dataset — Brown2reference","text":"dataset dataframe contains column Brown states MEDI.colname name column contains MEDI values used checks Brown reference illuminance. Must part dataset. Brown.state.colname name column contains Brown states. Must part dataset. Brown.rec.colname name column contain recommended illuminance. Must part dataset, otherwise throw error. Reference.label label used reference. Expects character scalar. overwrite TRUE (defaults FALSE), function overwrite Brown.rec.colname column already exists. ... Additional arguments passed Brown_rec() Brown_check(). relevant correct names daytime states thresholds used within states. See documentation functions information.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown2reference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Brown et al. (2022) reference illuminance to a dataset — Brown2reference","text":"dataframe basis dataset contains added columns.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown2reference.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add Brown et al. (2022) reference illuminance to a dataset — Brown2reference","text":"lower level, function uses Brown_rec() Brown_check() create required information.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown2reference.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Add Brown et al. (2022) reference illuminance to a dataset — Brown2reference","text":"https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001571","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown2reference.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Brown et al. (2022) reference illuminance to a dataset — Brown2reference","text":"","code":"#add Brown reference illuminance to some sample data testdata <- tibble::tibble(MEDI = c(100, 10, 1, 300),                   State.Brown = c(\"day\", \"evening\", \"night\", \"day\")) Brown2reference(testdata) #> # A tibble: 4 × 6 #>    MEDI State.Brown Reference Reference.check Reference.difference #>   <dbl> <chr>           <dbl> <lgl>                          <dbl> #> 1   100 day               250 FALSE                           -150 #> 2    10 evening            10 TRUE                               0 #> 3     1 night               1 TRUE                               0 #> 4   300 day               250 TRUE                              50 #> # ℹ 1 more variable: Reference.label <chr>"},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether a value is within the recommended illuminance/MEDI levels by Brown et al. (2022) — Brown_check","title":"Check whether a value is within the recommended illuminance/MEDI levels by Brown et al. (2022) — Brown_check","text":"lower level function. checks given value threshold states given Brown et al. (2022). function vectorized. day threshold lower limit, evening night threshold upper limit.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether a value is within the recommended illuminance/MEDI levels by Brown et al. (2022) — Brown_check","text":"","code":"Brown_check(   value,   state,   Brown.day = \"day\",   Brown.evening = \"evening\",   Brown.night = \"night\",   Brown.day.th = 250,   Brown.evening.th = 10,   Brown.night.th = 1 )"},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether a value is within the recommended illuminance/MEDI levels by Brown et al. (2022) — Brown_check","text":"value Illuminance value check recommendation. needs numeric, can vector. state state Brown et al. (2022). Needs character vector length value. Brown.day, Brown.evening, Brown.night names states Brown et al. (2022). default values (\"day\", \"evening\", \"night\"), can changed names state different. Needs character scalar. Brown.day.th, Brown.evening.th, Brown.night.th thresholds states Brown et al. (2022). default values (250, 10, 1), can changed thresholds different. Needs numeric scalar.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether a value is within the recommended illuminance/MEDI levels by Brown et al. (2022) — Brown_check","text":"logical vector length value indicates whether value within recommended illuminance levels.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_check.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Check whether a value is within the recommended illuminance/MEDI levels by Brown et al. (2022) — Brown_check","text":"https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001571","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_check.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check whether a value is within the recommended illuminance/MEDI levels by Brown et al. (2022) — Brown_check","text":"","code":"states <- c(\"day\", \"evening\", \"night\", \"day\") values <- c(100, 10, 1, 300) Brown_check(values, states) #> [1] FALSE  TRUE  TRUE  TRUE Brown_check(values, states, Brown.day.th = 100) #> [1] TRUE TRUE TRUE TRUE"},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_cut.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a state column that cuts light levels into sections by Brown et al. (2022) — Brown_cut","title":"Create a state column that cuts light levels into sections by Brown et al. (2022) — Brown_cut","text":"convenience wrapper arount cut() dplyr::mutate(). creates state column dividing light column recommended levels Brown et al. (2022). Cuts can adjusted extended vector_cuts vector_labels","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_cut.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a state column that cuts light levels into sections by Brown et al. (2022) — Brown_cut","text":"","code":"Brown_cut(   dataset,   MEDI.colname = MEDI,   New.state.colname = state,   vector_cuts = c(-Inf, 1, 10, 250, Inf),   vector_labels = \"default\",   overwrite = TRUE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_cut.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a state column that cuts light levels into sections by Brown et al. (2022) — Brown_cut","text":"dataset light exposure dataframe MEDI.colname colname containing melanopic EDI values (, alternatively, Illuminance). Defaults MEDI. Expects symbol. New.state.colname Name new column contain cut data. Expects symbol. vector_cuts Numeric vector breaks cuts. vector_labels Vector labels cuts. Must one entry shorter vector_cuts. \"default\" produce nice labels default setting vector_cuts (throw error otherwise). overwrite Logical. New.state.colname overwrite preexisting column dataset","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_cut.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a state column that cuts light levels into sections by Brown et al. (2022) — Brown_cut","text":"input dataset additional (overwritten) column containing cut light vector","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_cut.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create a state column that cuts light levels into sections by Brown et al. (2022) — Brown_cut","text":"https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001571","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_cut.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a state column that cuts light levels into sections by Brown et al. (2022) — Brown_cut","text":"","code":"sample.data.environment |> Brown_cut(vector_labels = c(\"0-1lx\", \"1-10lx\", \"10-250lx\", \"250lx-Inf\")) |> dplyr::count(state) #> # A tibble: 8 × 3 #> # Groups:   Id [2] #>   Id          state         n #>   <fct>       <fct>     <int> #> 1 Environment 0-1lx      6768 #> 2 Environment 1-10lx      247 #> 3 Environment 10-250lx    523 #> 4 Environment 250lx-Inf  9742 #> 5 Participant 0-1lx     20315 #> 6 Participant 1-10lx     5781 #> 7 Participant 10-250lx  15892 #> 8 Participant 250lx-Inf  9852"},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_rec.html","id":null,"dir":"Reference","previous_headings":"","what":"Set the recommended illuminance/MEDI levels by Brown et al. (2022) — Brown_rec","title":"Set the recommended illuminance/MEDI levels by Brown et al. (2022) — Brown_rec","text":"lower level function. sets recommended illuminance/MEDI levels Brown et al. (2022) given state. function vectorized.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_rec.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set the recommended illuminance/MEDI levels by Brown et al. (2022) — Brown_rec","text":"","code":"Brown_rec(   state,   Brown.day = \"day\",   Brown.evening = \"evening\",   Brown.night = \"night\",   Brown.day.th = 250,   Brown.evening.th = 10,   Brown.night.th = 1 )"},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_rec.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set the recommended illuminance/MEDI levels by Brown et al. (2022) — Brown_rec","text":"state state Brown et al. (2022). Needs character vector. Brown.day, Brown.evening, Brown.night names states Brown et al. (2022). default values (\"day\", \"evening\", \"night\"), can changed names state different. Needs character scalar. Brown.day.th, Brown.evening.th, Brown.night.th thresholds states Brown et al. (2022). default values (250, 10, 1), can changed thresholds different. Needs numeric scalar.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_rec.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set the recommended illuminance/MEDI levels by Brown et al. (2022) — Brown_rec","text":"dataframe length state contains recommended illuminance/MEDI levels.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_rec.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Set the recommended illuminance/MEDI levels by Brown et al. (2022) — Brown_rec","text":"https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001571","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/Brown_rec.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set the recommended illuminance/MEDI levels by Brown et al. (2022) — Brown_rec","text":"","code":"states <- c(\"day\", \"evening\", \"night\") Brown_rec(states) #> [1] 250  10   1 Brown_rec(states, Brown.day.th = 100) #> [1] 100  10   1"},{"path":"https://tscnlab.github.io/LightLogR/reference/Datetime2Time.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Datetime columns to Time columns — Datetime2Time","title":"Convert Datetime columns to Time columns — Datetime2Time","text":"Convert Datetime columns Time columns","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Datetime2Time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Datetime columns to Time columns — Datetime2Time","text":"","code":"Datetime2Time(   dataset,   cols = dplyr::where(lubridate::is.POSIXct),   silent = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/Datetime2Time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Datetime columns to Time columns — Datetime2Time","text":"dataset data.frame POSIXct columns. cols column names convert. Expects symbol. default convert POSIXct columns. uncertain whether columns exist dataset, use dplyr::any_of(). silent Logical whether message shall shown input output identical. Defaults FALSE (.e., message shown).","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Datetime2Time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Datetime columns to Time columns — Datetime2Time","text":"input dataset converted POSIXct columns time (hms) columns. default settings, POSIXct column exists, input output identical.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Datetime2Time.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Datetime columns to Time columns — Datetime2Time","text":"","code":"sample.data.environment |> Datetime2Time() #> # A tibble: 69,120 × 3 #> # Groups:   Id [2] #>    Id          Datetime  MEDI #>    <fct>       <time>   <dbl> #>  1 Participant 00'04\"       0 #>  2 Participant 00'14\"       0 #>  3 Participant 00'24\"       0 #>  4 Participant 00'34\"       0 #>  5 Participant 00'44\"       0 #>  6 Participant 00'54\"       0 #>  7 Participant 01'04\"       0 #>  8 Participant 01'14\"       0 #>  9 Participant 01'24\"       0 #> 10 Participant 01'34\"       0 #> # ℹ 69,110 more rows #more than one POSIX col sample.data.environment |>   dplyr::mutate(Datetime2 = lubridate::POSIXct(1)) |>   Datetime2Time() #> # A tibble: 69,120 × 4 #> # Groups:   Id [2] #>    Id          Datetime  MEDI Datetime2 #>    <fct>       <time>   <dbl> <time>    #>  1 Participant 00'04\"       0 00'00\"    #>  2 Participant 00'14\"       0 00'00\"    #>  3 Participant 00'24\"       0 00'00\"    #>  4 Participant 00'34\"       0 00'00\"    #>  5 Participant 00'44\"       0 00'00\"    #>  6 Participant 00'54\"       0 00'00\"    #>  7 Participant 01'04\"       0 00'00\"    #>  8 Participant 01'14\"       0 00'00\"    #>  9 Participant 01'24\"       0 00'00\"    #> 10 Participant 01'34\"       0 00'00\"    #> # ℹ 69,110 more rows #only converting one of them sample.data.environment |>   dplyr::mutate(Datetime2 = lubridate::POSIXct(1)) |>   Datetime2Time(Datetime) #> # A tibble: 69,120 × 4 #> # Groups:   Id [2] #>    Id          Datetime  MEDI Datetime2           #>    <fct>       <time>   <dbl> <dttm>              #>  1 Participant 00'04\"       0 1970-01-01 00:00:00 #>  2 Participant 00'14\"       0 1970-01-01 00:00:00 #>  3 Participant 00'24\"       0 1970-01-01 00:00:00 #>  4 Participant 00'34\"       0 1970-01-01 00:00:00 #>  5 Participant 00'44\"       0 1970-01-01 00:00:00 #>  6 Participant 00'54\"       0 1970-01-01 00:00:00 #>  7 Participant 01'04\"       0 1970-01-01 00:00:00 #>  8 Participant 01'14\"       0 1970-01-01 00:00:00 #>  9 Participant 01'24\"       0 1970-01-01 00:00:00 #> 10 Participant 01'34\"       0 1970-01-01 00:00:00 #> # ℹ 69,110 more rows #if uncertain whether column exists sample.data.environment |>   Datetime2Time(dplyr::any_of(\"Datetime3\")) #> No columns were affected #> # A tibble: 69,120 × 3 #> # Groups:   Id [2] #>    Id          Datetime             MEDI #>    <fct>       <dttm>              <dbl> #>  1 Participant 2023-08-29 00:00:04     0 #>  2 Participant 2023-08-29 00:00:14     0 #>  3 Participant 2023-08-29 00:00:24     0 #>  4 Participant 2023-08-29 00:00:34     0 #>  5 Participant 2023-08-29 00:00:44     0 #>  6 Participant 2023-08-29 00:00:54     0 #>  7 Participant 2023-08-29 00:01:04     0 #>  8 Participant 2023-08-29 00:01:14     0 #>  9 Participant 2023-08-29 00:01:24     0 #> 10 Participant 2023-08-29 00:01:34     0 #> # ℹ 69,110 more rows"},{"path":"https://tscnlab.github.io/LightLogR/reference/Datetime_breaks.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a (shifted) sequence of Datetimes for axis breaks — Datetime_breaks","title":"Create a (shifted) sequence of Datetimes for axis breaks — Datetime_breaks","text":"Take vector Datetimes create sequence Datetimes given shift interval. helper function create breaks plotting, e.g. gg_days(), best used conjunction Datetime_limits(). function thin wrapper around seq().","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Datetime_breaks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a (shifted) sequence of Datetimes for axis breaks — Datetime_breaks","text":"","code":"Datetime_breaks(x, shift = lubridate::duration(12, \"hours\"), by = \"1 day\")"},{"path":"https://tscnlab.github.io/LightLogR/reference/Datetime_breaks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a (shifted) sequence of Datetimes for axis breaks — Datetime_breaks","text":"x vector Datetimes shift numeric giving number  duration object, e.g. lubridate::duration(12, \"hours\") character scalar giving unit interval base::seq()","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Datetime_breaks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a (shifted) sequence of Datetimes for axis breaks — Datetime_breaks","text":"vector Datetimes","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Datetime_breaks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a (shifted) sequence of Datetimes for axis breaks — Datetime_breaks","text":"","code":"dataset <- c(\"2023-08-15\", \"2023-08-20\") Datetime_breaks(dataset) #> [1] \"2023-08-15 12:00:00 UTC\" \"2023-08-16 12:00:00 UTC\" #> [3] \"2023-08-17 12:00:00 UTC\" \"2023-08-18 12:00:00 UTC\" #> [5] \"2023-08-19 12:00:00 UTC\" Datetime_breaks(dataset, shift = 0) #> [1] \"2023-08-15 UTC\" \"2023-08-16 UTC\" \"2023-08-17 UTC\" \"2023-08-18 UTC\" #> [5] \"2023-08-19 UTC\" \"2023-08-20 UTC\" Datetime_breaks(dataset, by = \"12 hours\") #>  [1] \"2023-08-15 12:00:00 UTC\" \"2023-08-16 00:00:00 UTC\" #>  [3] \"2023-08-16 12:00:00 UTC\" \"2023-08-17 00:00:00 UTC\" #>  [5] \"2023-08-17 12:00:00 UTC\" \"2023-08-18 00:00:00 UTC\" #>  [7] \"2023-08-18 12:00:00 UTC\" \"2023-08-19 00:00:00 UTC\" #>  [9] \"2023-08-19 12:00:00 UTC\" \"2023-08-20 00:00:00 UTC\""},{"path":"https://tscnlab.github.io/LightLogR/reference/Datetime_limits.html","id":null,"dir":"Reference","previous_headings":"","what":"Find or set sensible limits for Datetime axis — Datetime_limits","title":"Find or set sensible limits for Datetime axis — Datetime_limits","text":"Take vector Datetimes return start first end last day data. start length can adjusted durations, like lubridate::ddays(). used gg_days() function return sensible x-axis. function thin wrapper around lubridate::floor_date() lubridate::ceiling_date().","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Datetime_limits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find or set sensible limits for Datetime axis — Datetime_limits","text":"","code":"Datetime_limits(   x,   start = NULL,   length = NULL,   unit = \"1 day\",   midnight.rollover = FALSE,   ... )"},{"path":"https://tscnlab.github.io/LightLogR/reference/Datetime_limits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find or set sensible limits for Datetime axis — Datetime_limits","text":"x vector Datetimes start optional duration object, e.g. lubridate::ddays(1) shifts start Datetime vector amount. length optional duration object, e.g. lubridate::ddays(7) shifts end Datetime vector amount (adjusted) start. Depending data, might subtract one day desired length get correct axis-scaling start midnight. unit character scalar giving unit rounding lubridate::floor_date() lubridate::ceiling_date() midnight.rollover logical scalar indicating whether rollover cases exact matches rounded values input values. Helpful cases fall exactly rounded values others don`t. ... arguments passed lubridate::floor_date() lubridate::ceiling_date()","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Datetime_limits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find or set sensible limits for Datetime axis — Datetime_limits","text":"2 item vector Datetimes (adjusted) start end input vector.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/Datetime_limits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find or set sensible limits for Datetime axis — Datetime_limits","text":"","code":"dataset <- c(\"2023-08-15\", \"2023-08-20\") breaks <- Datetime_breaks(dataset) Datetime_limits(breaks) #> [1] \"2023-08-15 UTC\" \"2023-08-20 UTC\" Datetime_limits(breaks, start = lubridate::ddays(1)) #> [1] \"2023-08-16 UTC\" \"2023-08-20 UTC\" Datetime_limits(breaks, length = lubridate::ddays(2)) #> [1] \"2023-08-15 UTC\" \"2023-08-18 UTC\""},{"path":"https://tscnlab.github.io/LightLogR/reference/LightLogR-package.html","id":null,"dir":"Reference","previous_headings":"","what":"LightLogR: Process Data from Wearable Light Loggers and Optical Radiation Dosimeters — LightLogR-package","title":"LightLogR: Process Data from Wearable Light Loggers and Optical Radiation Dosimeters — LightLogR-package","text":"Import, processing, validation, visualization personal light exposure measurement data wearable devices. package implements features import data metadata files, conversion common file formats, validation light logging data, verification crucial metadata, calculation common parameters, semi-automated analysis visualization.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/LightLogR-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"LightLogR: Process Data from Wearable Light Loggers and Optical Radiation Dosimeters — LightLogR-package","text":"Maintainer: Johannes Zauner johannes.zauner@tum.de (ORCID) Authors: Manuel Spitschan manuel.spitschan@tum.de (ORCID) Steffen Hartmeyer steffen.hartmeyer@epfl.ch (ORCID) contributors: MeLiDos [funder] EURAMET (European Association National Metrology Institutes. Website: www.euramet.org. Grant Number: 22NRM05 MeLiDos. Grant Statement: project (22NRM05 MeLiDos) received funding European Partnership Metrology, co-financed European Union’s Horizon Europe Research Innovation Programme Participating States.) [funder] European Union (Co-funded European Union. Views opinions expressed however author(s) necessarily reflect European Union EURAMET. Neither European Union granting authority can held responsible .) [funder] TSCN-Lab (www.tscnlab.org) [copyright holder]","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/add_Date_col.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Date column in the dataset — add_Date_col","title":"Create a Date column in the dataset — add_Date_col","text":"Create Date column dataset","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/add_Date_col.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Date column in the dataset — add_Date_col","text":"","code":"add_Date_col(   dataset,   Date.colname = Date,   group.by = FALSE,   as.wday = FALSE,   Datetime.colname = Datetime )"},{"path":"https://tscnlab.github.io/LightLogR/reference/add_Date_col.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Date column in the dataset — add_Date_col","text":"dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variable Datetime.colname. Date.colname Name newly created column. Expects symbol. default(Date) works well functions LightLogR. overwrite existing columns identical name. group.Logical whether output (additionally) grouped new column .wday Logical whether added column calculate day week instead date. TRUE create factor weekday abbreviations, week starts Mon. Datetime.colname column name contains datetime. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. Needs part dataset. Must type POSIXct.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/add_Date_col.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Date column in the dataset — add_Date_col","text":"data.frame object identical dataset added column Date data","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/add_Date_col.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Date column in the dataset — add_Date_col","text":"","code":"sample.data.environment %>% add_Date_col() #> # A tibble: 69,120 × 4 #> # Groups:   Id [2] #>    Id          Datetime             MEDI Date       #>    <fct>       <dttm>              <dbl> <date>     #>  1 Participant 2023-08-29 00:00:04     0 2023-08-29 #>  2 Participant 2023-08-29 00:00:14     0 2023-08-29 #>  3 Participant 2023-08-29 00:00:24     0 2023-08-29 #>  4 Participant 2023-08-29 00:00:34     0 2023-08-29 #>  5 Participant 2023-08-29 00:00:44     0 2023-08-29 #>  6 Participant 2023-08-29 00:00:54     0 2023-08-29 #>  7 Participant 2023-08-29 00:01:04     0 2023-08-29 #>  8 Participant 2023-08-29 00:01:14     0 2023-08-29 #>  9 Participant 2023-08-29 00:01:24     0 2023-08-29 #> 10 Participant 2023-08-29 00:01:34     0 2023-08-29 #> # ℹ 69,110 more rows #days of the week sample.data.environment %>%    add_Date_col(as.wday = TRUE, group.by = TRUE) |>    summarize_numeric(remove = c(\"Datetime\")) #> # A tibble: 12 × 4 #> # Groups:   Id [2] #>    Id          Date  mean_MEDI episodes #>    <fct>       <ord>     <dbl>    <int> #>  1 Environment Tue      6362.      2880 #>  2 Environment Wed     13966.      2880 #>  3 Environment Thu     17513.      2880 #>  4 Environment Fri     17180.      2880 #>  5 Environment Sat     23869.      2880 #>  6 Environment Sun     18086.      2880 #>  7 Participant Tue        91.5     8640 #>  8 Participant Wed        93.8     8640 #>  9 Participant Thu       188.      8640 #> 10 Participant Fri       748.      8640 #> 11 Participant Sat      1641.      8640 #> 12 Participant Sun      1712.      8640"},{"path":"https://tscnlab.github.io/LightLogR/reference/add_Time_col.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Time-of-Day column in the dataset — add_Time_col","title":"Create a Time-of-Day column in the dataset — add_Time_col","text":"Create Time--Day column dataset","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/add_Time_col.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Time-of-Day column in the dataset — add_Time_col","text":"","code":"add_Time_col(   dataset,   Datetime.colname = Datetime,   Time.colname = Time,   output.dataset = TRUE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/add_Time_col.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Time-of-Day column in the dataset — add_Time_col","text":"dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variable Datetime.colname. Datetime.colname column name contains datetime. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. Needs part dataset. Must type POSIXct. Time.colname Name newly created column. Expects symbol. default(Time) works well functions LightLogR. overwrite existing columns identical name. output.dataset output data.frame (Default TRUE) vector hms (FALSE) times? Expects logical scalar.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/add_Time_col.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Time-of-Day column in the dataset — add_Time_col","text":"data.frame object identical dataset added column Time--Day data, vector Time--Day-data","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/add_Time_col.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Time-of-Day column in the dataset — add_Time_col","text":"","code":"sample.data.environment %>% add_Time_col() #> # A tibble: 69,120 × 4 #> # Groups:   Id [2] #>    Id          Datetime             MEDI Time   #>    <fct>       <dttm>              <dbl> <time> #>  1 Participant 2023-08-29 00:00:04     0 00'04\" #>  2 Participant 2023-08-29 00:00:14     0 00'14\" #>  3 Participant 2023-08-29 00:00:24     0 00'24\" #>  4 Participant 2023-08-29 00:00:34     0 00'34\" #>  5 Participant 2023-08-29 00:00:44     0 00'44\" #>  6 Participant 2023-08-29 00:00:54     0 00'54\" #>  7 Participant 2023-08-29 00:01:04     0 01'04\" #>  8 Participant 2023-08-29 00:01:14     0 01'14\" #>  9 Participant 2023-08-29 00:01:24     0 01'24\" #> 10 Participant 2023-08-29 00:01:34     0 01'34\" #> # ℹ 69,110 more rows"},{"path":"https://tscnlab.github.io/LightLogR/reference/add_states.html","id":null,"dir":"Reference","previous_headings":"","what":"Add states to a dataset based on groups and start/end times — add_states","title":"Add states to a dataset based on groups and start/end times — add_states","text":"add_states() brings states time series dataset. uses States.dataset add states dataset. States.dataset must least contain variables dataset grouping, well start end time. Beware datasets operate different time zones consider set force.tz = TRUE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/add_states.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add states to a dataset based on groups and start/end times — add_states","text":"","code":"add_states(   dataset,   States.dataset,   Datetime.colname = Datetime,   start.colname = start,   end.colname = end,   force.tz = FALSE,   leave.out = c(\"duration\", \"epoch\") )"},{"path":"https://tscnlab.github.io/LightLogR/reference/add_states.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add states to a dataset based on groups and start/end times — add_states","text":"dataset light logger dataset. Needs dataframe. States.dataset light logger dataset. Needs dataframe. dataset must contain variables dataset grouping, well start end time. column, leave.added dataset. Datetime.colname column contains datetime. Needs POSIXct part dataset. start.colname, end.colname columns contain start end time. Need POSIXct part States.dataset. force.tz TRUE, start end times States.dataset forced time zone dataset using lubridate::force_tz(). FALSE (default), start end times States.dataset used . leave.character vector columns carried dataset","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/add_states.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add states to a dataset based on groups and start/end times — add_states","text":"modified dataset states added. states added new columns dataset. columns named columns States.dataset, except start end times, removed.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/add_states.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add states to a dataset based on groups and start/end times — add_states","text":"Beware columns dataset States.dataset name (grouping variables). underlying function, dplyr::left_join() mark columns dataset suffix .x, States.dataset suffix .y.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/add_states.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add states to a dataset based on groups and start/end times — add_states","text":"","code":"states <- sample.data.environment |>   filter_Date(length = \"1 day\") |>    extract_states(Daylight, MEDI > 1000)  states |> head(2) #> # A tibble: 2 × 7 #> # Groups:   Id, Daylight [1] #>   Id          Daylight state.count epoch start               end                 #>   <fct>       <lgl>    <chr>       <dbl> <dttm>              <dttm>              #> 1 Environment FALSE    FALSE 1        30 2023-08-28 23:59:53 2023-08-29 06:57:53 #> 2 Environment FALSE    FALSE 2        30 2023-08-29 19:45:23 2023-08-29 23:59:53 #> # ℹ 1 more variable: duration <Duration>  #add states to a dataset and plot them - as we only looked for states on the # first day (see above), only the first day will show up in the plot sample.data.environment |>   filter_Date(length = \"2 day\") |>   add_states(states) |>   gg_days() |>   gg_state(Daylight)"},{"path":"https://tscnlab.github.io/LightLogR/reference/aggregate_Date.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate dates to a single day — aggregate_Date","title":"Aggregate dates to a single day — aggregate_Date","text":"Condenses dataset aggregating data single day per group, resolution choice unit. aggregate_Date() opinionated sense sets default handlers data type numeric, character, logical, factor. can overwritten user. Columns fall one categories need handled individually user (... argument) removed aggregation. unit specified data simply aggregated common interval (dominant.epoch) every group. aggregate_Date() especially useful summary plots show average day.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/aggregate_Date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate dates to a single day — aggregate_Date","text":"","code":"aggregate_Date(   dataset,   Datetime.colname = Datetime,   unit = \"none\",   type = c(\"round\", \"floor\", \"ceiling\"),   date.handler = stats::median,   numeric.handler = mean,   character.handler = function(x) names(which.max(table(x, useNA = \"ifany\"))),   logical.handler = function(x) mean(x) >= 0.5,   factor.handler = function(x) factor(names(which.max(table(x, useNA = \"ifany\")))),   datetime.handler = stats::median,   duration.handler = function(x) lubridate::duration(mean(x)),   time.handler = function(x) hms::as_hms(mean(x)),   ... )"},{"path":"https://tscnlab.github.io/LightLogR/reference/aggregate_Date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate dates to a single day — aggregate_Date","text":"dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variable Datetime.colname. Datetime.colname column name contains datetime. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. Needs part dataset. Must type POSIXct. unit Unit binning. See lubridate::round_date() examples. default \"none\", aggregate data , recommended regular data, condensation across different days performed time. Another option \"dominant.epoch\", means everything aggregated common interval. especially useful slightly irregular data, can computationally expensive. type One \"round\"(default), \"ceiling\" \"floor\". Setting chooses relevant function lubridate. date.handler function calculates aggregated day group. default, set median. numeric.handler, character.handler, logical.handler, factor.handler, datetime.handler, duration.handler, time.handler functions handle respective data types. default handlers calculate mean median numeric, POSIXct, duration, hms, mode character, factor logical types. ... arguments given dplyr::summarize() handle columns fall one categories .","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/aggregate_Date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate dates to a single day — aggregate_Date","text":"tibble aggregated Datetime data, maximum one day per group. handler arguments capture column types, number columns input dataset.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/aggregate_Date.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Aggregate dates to a single day — aggregate_Date","text":"Summary values type POSIXct calculated median, mean can nonsensical times (e.g., mean Day1 18:00 Day2 18:00, Day2 6:00, can desired result, focus time, rather datetime, recommended values converted times via hms::as_hms() applying function (mean 18:00 18:00 still 18:00, 6:00). Using median default handler ensures sensible datetime. aggregate_Date() splits Datetime column Date.data Time column. create subgroups Time present group aggregate group single day, remove sub grouping. Use ... create summary statistics group, e.g. maximum minimum values time point group. Performing aggregate_Datetime() unit aggregate_Date() unit \"none\" equivalent just using aggregate_Date() unit directly (provided arguments set functions). Disentangling two functions can useful split computational cost small instances unit large datasets. can also useful apply different handlers aggregating data desired unit time, aggregation single day, handlers well ... used twice unit set \"none\".","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/aggregate_Date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregate dates to a single day — aggregate_Date","text":"","code":"library(ggplot2) #gg_days without aggregation sample.data.environment %>%  gg_days()   #with daily aggregation sample.data.environment %>%  aggregate_Date() %>%  gg_days()   #with daily aggregation and a different time aggregation sample.data.environment %>%  aggregate_Date(unit = \"15 mins\", type = \"floor\") %>%  gg_days()   #adding further summary statistics about the range of MEDI  sample.data.environment %>%  aggregate_Date(unit = \"15 mins\", type = \"floor\",                 MEDI_max = max(MEDI),                 MEDI_min = min(MEDI)) %>%  gg_days() +  geom_ribbon(aes(ymin = MEDI_min, ymax = MEDI_max), alpha = 0.5)"},{"path":"https://tscnlab.github.io/LightLogR/reference/aggregate_Datetime.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate Datetime data — aggregate_Datetime","title":"Aggregate Datetime data — aggregate_Datetime","text":"Condenses dataset aggregating data given (shorter) interval unit. aggregate_Datetime() opinionated sense sets default handlers data type numeric, character, logical, factor, duration, time, datetime. can overwritten user. Columns fall one categories need handled individually user (... argument) removed aggregation. unit specified data simply aggregated common interval (dominant.epoch), often aggregation rounding.)","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/aggregate_Datetime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate Datetime data — aggregate_Datetime","text":"","code":"aggregate_Datetime(   dataset,   unit = \"dominant.epoch\",   Datetime.colname = Datetime,   type = c(\"round\", \"floor\", \"ceiling\"),   numeric.handler = mean,   character.handler = function(x) names(which.max(table(x, useNA = \"ifany\"))),   logical.handler = function(x) mean(x) >= 0.5,   factor.handler = function(x) factor(names(which.max(table(x, useNA = \"ifany\")))),   datetime.handler = mean,   duration.handler = function(x) lubridate::duration(mean(x)),   time.handler = function(x) hms::as_hms(mean(x)),   ... )"},{"path":"https://tscnlab.github.io/LightLogR/reference/aggregate_Datetime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate Datetime data — aggregate_Datetime","text":"dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variable Datetime.colname. unit Unit binning. See lubridate::round_date() examples. default \"dominant.epoch\", means everything aggregated common interval. especially useful slightly irregular data, can computationally expensive. \"none\" aggregate data . Datetime.colname column name contains datetime. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. Needs part dataset. Must type POSIXct. type One \"round\"(default), \"ceiling\" \"floor\". Setting chooses relevant function lubridate. numeric.handler, character.handler, logical.handler, factor.handler, datetime.handler, duration.handler, time.handler functions handle respective data types. default handlers calculate mean median numeric, POSIXct, duration, hms, mode character, factor logical types. ... arguments given dplyr::summarize() handle columns fall one categories .","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/aggregate_Datetime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate Datetime data — aggregate_Datetime","text":"tibble aggregated Datetime data. Usually number rows smaller input dataset. handler arguments capture column types, number columns input dataset.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/aggregate_Datetime.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Aggregate Datetime data — aggregate_Datetime","text":"Summary values type POSIXct calculated mean, can nonsensical times (e.g., mean Day1 18:00 Day2 18:00, Day2 6:00, can desired result, focus time, rather datetime, recommended values converted times via hms::as_hms() applying function (mean 18:00 18:00 still 18:00, 6:00).","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/aggregate_Datetime.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregate Datetime data — aggregate_Datetime","text":"","code":"#dominant epoch without aggregation sample.data.environment %>%  dominant_epoch() #> # A tibble: 2 × 3 #>   Id          dominant.epoch group.indices #>   <fct>       <Duration>             <int> #> 1 Environment 30s                        1 #> 2 Participant 10s                        2  #dominant epoch with 5 minute aggregation sample.data.environment %>%  aggregate_Datetime(unit = \"5 mins\") %>%  dominant_epoch() #> # A tibble: 2 × 3 #>   Id          dominant.epoch    group.indices #>   <fct>       <Duration>                <int> #> 1 Environment 300s (~5 minutes)             1 #> 2 Participant 300s (~5 minutes)             2  #dominant epoch with 1 day aggregation sample.data.environment %>%  aggregate_Datetime(unit = \"1 day\") %>%  dominant_epoch() #> # A tibble: 2 × 3 #>   Id          dominant.epoch   group.indices #>   <fct>       <Duration>               <int> #> 1 Environment 86400s (~1 days)             1 #> 2 Participant 86400s (~1 days)             2"},{"path":"https://tscnlab.github.io/LightLogR/reference/alphaopic.action.spectra.html","id":null,"dir":"Reference","previous_headings":"","what":"Alphaopic (+ photopic) action spectra — alphaopic.action.spectra","title":"Alphaopic (+ photopic) action spectra — alphaopic.action.spectra","text":"dataframe alphaopic action spectra plus photopic action spectrum. alphaopic action spectra according CIE S 026/E:2018 standard. alphaopic action spectra 32-year-old standard observer. photopic action spectrum 2° standard observer.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/alphaopic.action.spectra.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Alphaopic (+ photopic) action spectra — alphaopic.action.spectra","text":"","code":"alphaopic.action.spectra"},{"path":"https://tscnlab.github.io/LightLogR/reference/alphaopic.action.spectra.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Alphaopic (+ photopic) action spectra — alphaopic.action.spectra","text":"alphaopic.action.spectra datafram 471 rows 7 columns: wavelength integer wavelength, 360 830 nm. Unit nm melanopic numeric melanopic action spectrum l_cone_opic numeric L-cone opic action spectrum m_cone_opic numeric M-cone opic action spectrum s_cone_opic numeric S-cone opic action spectrum rhodopic numeric rhodopic action spectrum photopic numeric photopic action spectrum","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/alphaopic.action.spectra.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Alphaopic (+ photopic) action spectra — alphaopic.action.spectra","text":"https://www.cie.co./publications/cie-system-metrology-optical-radiation-iprgc-influenced-responses-light-0 https://cie.co./datatable/cie-spectral-luminous-efficiency-photopic-vision <https://files.cie.co./CIE S 026 alpha-opic Toolbox.xlsx>","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/alphaopic.action.spectra.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Alphaopic (+ photopic) action spectra — alphaopic.action.spectra","text":"CIE (2019). ISO/CIE 11664-1:2019(E). Colorimetry — Part 1: CIE standard colorimetric observers. Vienna, CIE CIE (2018). CIE S 026/E:2018. CIE system metrology optical radiation ipRGC-influenced responses light. Vienna, CIE","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/barroso_lighting_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Circadian lighting metrics from Barroso et al. (2014) — barroso_lighting_metrics","title":"Circadian lighting metrics from Barroso et al. (2014) — barroso_lighting_metrics","text":"function calculates metrics proposed Barroso et al. (2014) light-dosimetry context research non-visual effects light. following metrics calculated:","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/barroso_lighting_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Circadian lighting metrics from Barroso et al. (2014) — barroso_lighting_metrics","text":"","code":"barroso_lighting_metrics(   Light.vector,   Time.vector,   epoch = \"dominant.epoch\",   loop = FALSE,   na.rm = FALSE,   as.df = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/barroso_lighting_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Circadian lighting metrics from Barroso et al. (2014) — barroso_lighting_metrics","text":"Light.vector Numeric vector containing light data. Time.vector Vector containing time data. Can POSIXct, hms, duration, difftime. epoch epoch data sampled. Can either duration string. string, needs either \"dominant.epoch\" (default) guess based data, valid duration string, e.g., \"1 day\" \"10 sec\". loop Logical. data looped? Defaults FALSE. na.rm Logical. missing values (NA) removed calculation? Defaults FALSE. TRUE, calculation bright_cluster dark_cluster, missing values replaced 0 (see period_above_threshold). .df Logical. data frame returned? TRUE, data frame seven columns returned. Defaults FALSE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/barroso_lighting_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Circadian lighting metrics from Barroso et al. (2014) — barroso_lighting_metrics","text":"List dataframe seven values: bright_threshold, dark_threshold, bright_mean_level, dark_mean_level, bright_cluster, dark_cluster, circadian_variation. output type bright_cluster, dark_cluster, duration object.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/barroso_lighting_metrics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Circadian lighting metrics from Barroso et al. (2014) — barroso_lighting_metrics","text":"bright_threshold maximum light intensity least six hours measurements higher level. dark_threshold minimum light intensity least eight hours measurements lower level. bright_mean_level 20% trimmed mean light intensity measurements equal bright_threshold. dark_mean_level 20% trimmed mean light intensity measurements equal dark_threshold. bright_cluster longest continuous time interval bright_threshold. dark_cluster longest continuous time interval dark_threshold. circadian_variation measure periodicity daily lighting schedule given set days. Calculated coefficient variation input light data.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/barroso_lighting_metrics.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Circadian lighting metrics from Barroso et al. (2014) — barroso_lighting_metrics","text":"Barroso, ., Simons, K., & Jager, P. de. (2014). Metrics circadian lighting clinical investigations. Lighting Research & Technology, 46(6), 637–649. doi:10.1177/1477153513502664 Hartmeyer, S.L., Andersen, M. (2023). Towards framework light-dosimetry studies: Quantification metrics. Lighting Research & Technology. doi:10.1177/14771535231170500","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/barroso_lighting_metrics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Circadian lighting metrics from Barroso et al. (2014) — barroso_lighting_metrics","text":"","code":"dataset1 <-   tibble::tibble(     Id = rep(\"B\", 60 * 24),     Datetime = lubridate::as_datetime(0) + lubridate::minutes(0:(60*24-1)),     MEDI = c(rep(sample(seq(0,1,0.1), 60*8, replace = TRUE)),               rep(sample(1:1000, 16, replace = TRUE), each = 60))   )  dataset1 %>%   dplyr::reframe(barroso_lighting_metrics(MEDI, Datetime, as.df = TRUE)) #> # A tibble: 1 × 7 #>   bright_threshold dark_threshold bright_mean_level dark_mean_level #>              <dbl>          <dbl>             <dbl>           <dbl> #> 1              455              1              874.           0.503 #> # ℹ 3 more variables: bright_cluster <Duration>, dark_cluster <Duration>, #> #   circadian_variation <dbl>"},{"path":"https://tscnlab.github.io/LightLogR/reference/bright_dark_period.html","id":null,"dir":"Reference","previous_headings":"","what":"Brightest or darkest continuous period — bright_dark_period","title":"Brightest or darkest continuous period — bright_dark_period","text":"function finds brightest darkest continuous period given timespan calculates mean light level, well timing period's onset, midpoint, offset. defined period maximum minimum mean light level. Note data need regularly spaced (.e., gaps) correct results.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/bright_dark_period.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Brightest or darkest continuous period — bright_dark_period","text":"","code":"bright_dark_period(   Light.vector,   Time.vector,   period = c(\"brightest\", \"darkest\"),   timespan = \"10 hours\",   epoch = \"dominant.epoch\",   loop = FALSE,   na.rm = FALSE,   as.df = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/bright_dark_period.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Brightest or darkest continuous period — bright_dark_period","text":"Light.vector Numeric vector containing light data. Time.vector Vector containing time data. Can POSIXct, hms, duration, difftime. period String indicating type period look . Can either \"brightest\"(default) \"darkest\". timespan timespan across calculate. Can either duration duration string, e.g., \"1 day\" \"10 sec\". epoch epoch data sampled. Can either duration string. string, needs either \"dominant.epoch\" (default) guess based data, valid duration string, e.g., \"1 day\" \"10 sec\". loop Logical. data looped? TRUE, full copy data concatenated end data. Makes sense 24 h data. Defaults FALSE. na.rm Logical. missing values removed calculation? Defaults FALSE. .df Logical. output returned data frame? Defaults TRUE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/bright_dark_period.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Brightest or darkest continuous period — bright_dark_period","text":"named list mean, onset, midpoint, offset calculated brightest darkest period, .df == TRUE data frame columns named {period}_{timespan}_{metric}. output type corresponds type Time.vector, e.g., Time.vector HMS, timing metrics also HMS, vice versa POSIXct.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/bright_dark_period.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Brightest or darkest continuous period — bright_dark_period","text":"Assumes regular 24h light data. Otherwise, results may meaningful. Looping data recommended finding darkest period.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/bright_dark_period.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Brightest or darkest continuous period — bright_dark_period","text":"Hartmeyer, S.L., Andersen, M. (2023). Towards framework light-dosimetry studies: Quantification metrics. Lighting Research & Technology. doi:10.1177/14771535231170500","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/bright_dark_period.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Brightest or darkest continuous period — bright_dark_period","text":"","code":"# Dataset with light > 250lx between 06:00 and 18:00 dataset1 <-   tibble::tibble(     Id = rep(\"A\", 24),     Datetime = lubridate::as_datetime(0) + lubridate::hours(0:23),     MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))   )  dataset1 %>%   dplyr::reframe(bright_dark_period(MEDI, Datetime, \"brightest\", \"10 hours\",     as.df = TRUE)) #> # A tibble: 1 × 4 #>   brightest_10h_mean brightest_10h_midpoint brightest_10h_onset #>                <dbl> <dttm>                 <dttm>              #> 1                250 1970-01-01 10:00:00    1970-01-01 06:00:00 #> # ℹ 1 more variable: brightest_10h_offset <dttm> dataset1 %>%   dplyr::reframe(bright_dark_period(MEDI, Datetime, \"darkest\", \"7 hours\",     loop = TRUE, as.df = TRUE)) #> # A tibble: 1 × 4 #>   darkest_7h_mean darkest_7h_midpoint darkest_7h_onset    darkest_7h_offset   #>             <dbl> <dttm>              <dttm>              <dttm>              #> 1               1 1970-01-01 22:00:00 1970-01-01 19:00:00 1970-01-01 02:00:00  # Dataset with duration as Time.vector dataset2 <-   tibble::tibble(     Id = rep(\"A\", 24),     Datetime = lubridate::dhours(0:23),     MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))   )  dataset2 %>%   dplyr::reframe(bright_dark_period(MEDI, Datetime, \"brightest\", \"10 hours\",                                     as.df = TRUE)) #> # A tibble: 1 × 4 #>   brightest_10h_mean brightest_10h_midpoint brightest_10h_onset #>                <dbl> <Duration>             <Duration>          #> 1                250 36000s (~10 hours)     21600s (~6 hours)   #> # ℹ 1 more variable: brightest_10h_offset <Duration> dataset2 %>%   dplyr::reframe(bright_dark_period(MEDI, Datetime, \"darkest\", \"5 hours\",                                     loop = TRUE, as.df = TRUE)) #> # A tibble: 1 × 4 #>   darkest_5h_mean darkest_5h_midpoint darkest_5h_onset darkest_5h_offset #>             <dbl> <Duration>          <Duration>       <Duration>        #> 1               1 7200s (~2 hours)    0s               18000s (~5 hours)"},{"path":"https://tscnlab.github.io/LightLogR/reference/centroidLE.html","id":null,"dir":"Reference","previous_headings":"","what":"Centroid of light exposure — centroidLE","title":"Centroid of light exposure — centroidLE","text":"function calculates centroid light exposure mean time vector weighted proportion corresponding binned light intensity.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/centroidLE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Centroid of light exposure — centroidLE","text":"","code":"centroidLE(   Light.vector,   Time.vector,   bin.size = NULL,   na.rm = FALSE,   as.df = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/centroidLE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Centroid of light exposure — centroidLE","text":"Light.vector Numeric vector containing light data. Time.vector Vector containing time data. Can POSIXct, hms, duration, difftime. bin.size Value specifying size bins average light data . Must either duration duration string, e.g., \"1 day\" \"10 sec\". nothing provided, binning performed. na.rm Logical. missing values removed calculation? Defaults FALSE. .df Logical. output returned data frame? TRUE, data frame single column named centroidLE returned. Defaults FALSE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/centroidLE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Centroid of light exposure — centroidLE","text":"Single column data frame vector.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/centroidLE.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Centroid of light exposure — centroidLE","text":"Phillips, . J. K., Clerx, W. M., O’Brien, C. S., Sano, ., Barger, L. K., Picard, R. W., Lockley, S. W., Klerman, E. B., & Czeisler, C. . (2017). Irregular sleep/wake patterns associated poorer academic performance delayed circadian sleep/wake timing. Scientific Reports, 7(1), 3216. doi:10.1038/s41598-017-03171-4 Hartmeyer, S.L., Andersen, M. (2023). Towards framework light-dosimetry studies: Quantification metrics. Lighting Research & Technology. doi:10.1177/14771535231170500","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/centroidLE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Centroid of light exposure — centroidLE","text":"","code":"# Dataset with POSIXct time vector dataset1 <-   tibble::tibble(     Id = rep(\"A\", 24),     Datetime = lubridate::as_datetime(0) + lubridate::hours(0:23),     MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))   ) dataset1 %>%   dplyr::reframe(     \"Centroid of light exposure\" = centroidLE(MEDI, Datetime, \"2 hours\")   ) #> # A tibble: 1 × 1 #>   `Centroid of light exposure` #>   <dttm>                       #> 1 1970-01-01 11:32:04           # Dataset with hms time vector dataset2 <-   tibble::tibble(     Id = rep(\"A\", 24),     Time = hms::as_hms(lubridate::as_datetime(0) + lubridate::hours(0:23)),     MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))   ) dataset2 %>%   dplyr::reframe(     \"Centroid of light exposure\" = centroidLE(MEDI, Time, \"2 hours\")   ) #> # A tibble: 1 × 1 #>   `Centroid of light exposure` #>   <time>                       #> 1 11:32:04                      # Dataset with duration time vector dataset3 <-   tibble::tibble(     Id = rep(\"A\", 24),     Hour = lubridate::duration(0:23, \"hours\"),     MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))   ) dataset3 %>%   dplyr::reframe(     \"Centroid of light exposure\" = centroidLE(MEDI, Hour, \"2 hours\")   ) #> # A tibble: 1 × 1 #>   `Centroid of light exposure` #>   <Duration>                   #> 1 41524s (~11.53 hours)"},{"path":"https://tscnlab.github.io/LightLogR/reference/count_difftime.html","id":null,"dir":"Reference","previous_headings":"","what":"Counts the Time differences (epochs) per group (in a grouped dataset) — count_difftime","title":"Counts the Time differences (epochs) per group (in a grouped dataset) — count_difftime","text":"Counts Time differences (epochs) per group (grouped dataset)","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/count_difftime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Counts the Time differences (epochs) per group (in a grouped dataset) — count_difftime","text":"","code":"count_difftime(dataset, Datetime.colname = Datetime)"},{"path":"https://tscnlab.github.io/LightLogR/reference/count_difftime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Counts the Time differences (epochs) per group (in a grouped dataset) — count_difftime","text":"dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variable Datetime.colname. Datetime.colname column name contains datetime. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. Needs part dataset. Must type POSIXct.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/count_difftime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Counts the Time differences (epochs) per group (in a grouped dataset) — count_difftime","text":"tibble number occurences time difference per group","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/count_difftime.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Counts the Time differences (epochs) per group (in a grouped dataset) — count_difftime","text":"","code":"#count_difftime returns the number of occurences of each time difference #and is more comprehensive in terms of a summary than `gap_finder` or  #`dominant_epoch` count_difftime(sample.data.irregular) #> # A tibble: 4 × 4 #> # Groups:   Id [1] #>   Id    difftime       n group.indices #>   <chr> <Duration> <int>         <int> #> 1 P1    15s        10015             1 #> 2 P1    16s         1367             1 #> 3 P1    17s           23             1 #> 4 P1    18s           16             1 dominant_epoch(sample.data.irregular) #> # A tibble: 1 × 3 #>   Id    dominant.epoch group.indices #>   <chr> <Duration>             <int> #> 1 P1    15s                        1 gap_finder(sample.data.irregular) #> Found 10758 gaps. 761 Datetimes fall into the regular sequence.  #irregular data can be regularized with `aggregate_Datetime` sample.data.irregular |>   aggregate_Datetime(unit = \"15 secs\") |>   count_difftime() #> # A tibble: 2 × 4 #> # Groups:   Id [1] #>   Id    difftime       n group.indices #>   <chr> <Duration> <int>         <int> #> 1 P1    15s        11324             1 #> 2 P1    30s           97             1"},{"path":"https://tscnlab.github.io/LightLogR/reference/create_Timedata.html","id":null,"dir":"Reference","previous_headings":"","what":"create_Timedata — create_Timedata","title":"create_Timedata — create_Timedata","text":"create_Timedata","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/create_Timedata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"create_Timedata — create_Timedata","text":"","code":"create_Timedata(...)"},{"path":"https://tscnlab.github.io/LightLogR/reference/create_Timedata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"create_Timedata — create_Timedata","text":"... Input arguments add_Time_col()","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/create_Timedata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"create_Timedata — create_Timedata","text":"data.frame object identical dataset added column Time--Day data, vector Time--Day-data","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/create_Timedata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"create_Timedata — create_Timedata","text":"","code":"sample.data.environment %>% create_Timedata() #> Warning: `create_Timedata()` is deprecated as of LightLogR 0.9.1. Please use `add_Time_col()` instead.  #> # A tibble: 69,120 × 4 #> # Groups:   Id [2] #>    Id          Datetime             MEDI Time   #>    <fct>       <dttm>              <dbl> <time> #>  1 Participant 2023-08-29 00:00:04     0 00'04\" #>  2 Participant 2023-08-29 00:00:14     0 00'14\" #>  3 Participant 2023-08-29 00:00:24     0 00'24\" #>  4 Participant 2023-08-29 00:00:34     0 00'34\" #>  5 Participant 2023-08-29 00:00:44     0 00'44\" #>  6 Participant 2023-08-29 00:00:54     0 00'54\" #>  7 Participant 2023-08-29 00:01:04     0 01'04\" #>  8 Participant 2023-08-29 00:01:14     0 01'14\" #>  9 Participant 2023-08-29 00:01:24     0 01'24\" #> 10 Participant 2023-08-29 00:01:34     0 01'34\" #> # ℹ 69,110 more rows"},{"path":"https://tscnlab.github.io/LightLogR/reference/cut_Datetime.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Datetime bins for visualization and calculation — cut_Datetime","title":"Create Datetime bins for visualization and calculation — cut_Datetime","text":"cut_Datetime wrapper around lubridate::round_date() (friends) combined dplyr::mutate(), create new column light logger dataset specified binsize. can \"3 hours\", \"15 secs\", \"0.5 days\". useful step dataset visualization summary step.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/cut_Datetime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Datetime bins for visualization and calculation — cut_Datetime","text":"","code":"cut_Datetime(   dataset,   unit = \"3 hours\",   type = c(\"round\", \"floor\", \"ceiling\"),   Datetime.colname = Datetime,   New.colname = Datetime.rounded,   group_by = FALSE,   ... )"},{"path":"https://tscnlab.github.io/LightLogR/reference/cut_Datetime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Datetime bins for visualization and calculation — cut_Datetime","text":"dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variable Datetime.colname. unit Unit binning. See lubridate::round_date() examples. default \"3 hours\". type One \"round\"(default), \"ceiling\" \"floor\". Setting chooses relevant function lubridate. Datetime.colname column name contains datetime. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. Needs part dataset. Must type POSIXct. New.colname Column name added column dataset. group_by data grouped new column? Defaults FALSE ... Parameter handed lubridate::round_date() siblings","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/cut_Datetime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Datetime bins for visualization and calculation — cut_Datetime","text":"data.frame object identical dataset added column binned datetimes.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/cut_Datetime.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Datetime bins for visualization and calculation — cut_Datetime","text":"","code":"#compare Datetime and Datetime.rounded sample.data.environment %>%   cut_Datetime() %>%   dplyr::slice_sample(n = 5) #> # A tibble: 10 × 4 #> # Groups:   Id [2] #>    Id          Datetime            Datetime.rounded        MEDI #>    <fct>       <dttm>              <dttm>                 <dbl> #>  1 Environment 2023-09-02 13:37:08 2023-09-02 15:00:00 77609.   #>  2 Environment 2023-08-30 13:21:38 2023-08-30 12:00:00 34427.   #>  3 Environment 2023-09-03 13:31:08 2023-09-03 15:00:00 76025.   #>  4 Environment 2023-08-29 01:30:08 2023-08-29 03:00:00     0    #>  5 Environment 2023-09-02 09:34:08 2023-09-02 09:00:00 50373.   #>  6 Participant 2023-08-31 18:32:04 2023-08-31 18:00:00   284.   #>  7 Participant 2023-09-01 11:24:24 2023-09-01 12:00:00   264.   #>  8 Participant 2023-08-29 07:53:14 2023-08-29 09:00:00     2.66 #>  9 Participant 2023-08-30 12:54:04 2023-08-30 12:00:00    80.8  #> 10 Participant 2023-09-01 06:27:44 2023-09-01 06:00:00     0"},{"path":"https://tscnlab.github.io/LightLogR/reference/data2reference.html","id":null,"dir":"Reference","previous_headings":"","what":"Create reference data from other data — data2reference","title":"Create reference data from other data — data2reference","text":"Create reference data almost data datetime column data column. reference data can even created subsets data. Examples one participant can used reference participants, first (second,...) day every participant data reference day. function needs carefully handled, reference data time intervals shorter data time intervals. case, use aggregate_Datetime() reference data beforehand lengthen interval.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/data2reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create reference data from other data — data2reference","text":"","code":"data2reference(   dataset,   Reference.data = dataset,   Datetime.column = Datetime,   Data.column = MEDI,   Id.column = Id,   Reference.column = Reference,   overwrite = FALSE,   filter.expression.reference = NULL,   across.id = FALSE,   shift.start = FALSE,   length.restriction.seconds = 60,   shift.intervals = \"auto\",   Reference.label = NULL )"},{"path":"https://tscnlab.github.io/LightLogR/reference/data2reference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create reference data from other data — data2reference","text":"dataset light logger dataset Reference.data data used reference. default dataset used reference. Datetime.column Datetime column dataset Reference.data. Need sets. Default Datetime. Data.column Data column Reference.data converted reference. Default MEDI. Id.column Name Id.column dataset Reference.data. Reference.column Name reference column added dataset. Default Reference. column dataset throw error . overwrite TRUE (defaults FALSE), function overwrite Reference.colname column already exists. filter.expression.reference Expression used filter Reference.data used reference. Default NULL. See across.id Grouping variables ignored creating reference data. Default FALSE. TRUE, grouping variables ignored. FALSE, grouping variables ignored. vector grouping variables given, ignored. shift.start TRUE, reference data shifted start respective group. Default FALSE. shift ignores groups specified across.id. length.restriction.seconds Restricts application reference data maximum length seconds. Default 60 seconds. useful avoid reference data applied long periods time, e.g., gaps reference data shift.intervals Time shift seconds, applied every data point reference data. Default \"auto\". \"auto\", shift calculated halving frequent time difference two data points reference data. number given, number seconds used shift. Can also use lubridate::duration() specify shift. Reference.label Label added reference data. NULL, label added.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/data2reference.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create reference data from other data — data2reference","text":"dataset new column Reference contains reference data.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/data2reference.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create reference data from other data — data2reference","text":"use subsets data, use filter.expression.reference argument specify subsets data. across.id argument specifies whether reference data used across grouping variables (e.g., across participants). shift.start argument enables shift reference data start time start respective group. @examples information. expression evaluated within dplyr::filter().","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/data2reference.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create reference data from other data — data2reference","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union library(lubridate) #>  #> Attaching package: ‘lubridate’ #> The following objects are masked from ‘package:base’: #>  #>     date, intersect, setdiff, union library(ggplot2)  gg_reference <- function(dataset) { dataset %>% ggplot(aes(x = Datetime, y = MEDI, color = Id)) + geom_line(linewidth = 1) + geom_line(aes(y = Reference), color = \"black\", size = 0.25, linetype = \"dashed\") + theme_minimal() + facet_wrap(~ Id, scales = \"free_y\") }  #in this example, each data point is its own reference sample.data.environment %>%   data2reference() %>%   gg_reference() #> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. #> ℹ Please use `linewidth` instead.   #in this example, the first day of each ID is the reference for the other days #this requires grouping of the Data by Day, which is then specified in across.id #also, shift.start needs to be set to TRUE, to shift the reference data to the #start of the groupings sample.data.environment %>% group_by(Id, Day = as_date(Datetime)) %>% data2reference(   filter.expression.reference =  as_date(Datetime) == min(as_date(Datetime)),   shift.start = TRUE,   across.id = \"Day\") %>%   gg_reference() #> Joining with `by = join_by(Id, Day)` #> Adding missing grouping variables: `Id` #> Joining with `by = join_by(Id)` #> Joining with `by = join_by(Id, Day)` #> Joining with `by = join_by(Id, Day)` #> Adding missing grouping variables: `Day`   #in this example, the Environment Data will be used as a reference sample.data.environment %>% data2reference(   filter.expression.reference =  Id == \"Environment\",   across.id = TRUE) %>%   gg_reference()"},{"path":"https://tscnlab.github.io/LightLogR/reference/disparity_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Disparity index — disparity_index","title":"Disparity index — disparity_index","text":"function calculates continuous disparity index described Fernández-Martínez et al. (2018).","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/disparity_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Disparity index — disparity_index","text":"","code":"disparity_index(Light.vector, na.rm = FALSE, as.df = FALSE)"},{"path":"https://tscnlab.github.io/LightLogR/reference/disparity_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Disparity index — disparity_index","text":"Light.vector Numeric vector containing light data. na.rm Logical. missing values removed? Defaults FALSE .df Logical. output returned data frame? TRUE, data frame single column named disparity_index returned. Defaults FALSE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/disparity_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Disparity index — disparity_index","text":"Single column data frame vector.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/disparity_index.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Disparity index — disparity_index","text":"Fernández-Martínez, M., Vicca, S., Janssens, . ., Carnicer, J., Martín-Vide, J., & Peñuelas, J. (2018). consecutive disparity index, D: measure temporal variability ecological studies. Ecosphere, 9(12), e02527. doi:10.1002/ecs2.2527 Hartmeyer, S.L., Andersen, M. (2023). Towards framework light-dosimetry studies: Quantification metrics. Lighting Research & Technology. doi:10.1177/14771535231170500","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/disparity_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Disparity index — disparity_index","text":"","code":"dataset1 <-   tibble::tibble(     Id = rep(\"A\", 24),     Datetime = lubridate::as_datetime(0) + lubridate::hours(0:23),     MEDI = sample(0:1000, 24),   ) dataset1 %>%   dplyr::reframe(     \"Disparity index\" = disparity_index(MEDI)   ) #> # A tibble: 1 × 1 #>   `Disparity index` #>               <dbl> #> 1              1.02"},{"path":"https://tscnlab.github.io/LightLogR/reference/dominant_epoch.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine the dominant epoch/interval of a dataset — dominant_epoch","title":"Determine the dominant epoch/interval of a dataset — dominant_epoch","text":"Calculate dominant epoch/interval dataset. dominant epoch/interval epoch/interval frequent dataset. calculation done per group, might get multiple variables. two epochs/intervals equally frequent, first one (shortest one) chosen.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/dominant_epoch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Determine the dominant epoch/interval of a dataset — dominant_epoch","text":"","code":"dominant_epoch(dataset, Datetime.colname = Datetime)"},{"path":"https://tscnlab.github.io/LightLogR/reference/dominant_epoch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determine the dominant epoch/interval of a dataset — dominant_epoch","text":"dataset light logger dataset. Needs dataframe. Datetime.colname column contains datetime. Needs POSIXct part dataset.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/dominant_epoch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine the dominant epoch/interval of a dataset — dominant_epoch","text":"tibble one row per group column dominant.epoch lubridate::duration(). Also column group.indices, helpful referencing dominant.epoch across dataframes equal grouping.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/dominant_epoch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Determine the dominant epoch/interval of a dataset — dominant_epoch","text":"","code":"dataset <- tibble::tibble(Id = c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\"),               Datetime = lubridate::as_datetime(1) +                          lubridate::days(c(0:2, 4, 6, 8))) dataset #> # A tibble: 6 × 2 #>   Id    Datetime            #>   <chr> <dttm>              #> 1 A     1970-01-01 00:00:01 #> 2 A     1970-01-02 00:00:01 #> 3 A     1970-01-03 00:00:01 #> 4 B     1970-01-05 00:00:01 #> 5 B     1970-01-07 00:00:01 #> 6 B     1970-01-09 00:00:01 #get the dominant epoch by group dataset %>% dplyr::group_by(Id) %>% dominant_epoch() #> # A tibble: 2 × 3 #>   Id    dominant.epoch    group.indices #>   <chr> <Duration>                <int> #> 1 A     86400s (~1 days)              1 #> 2 B     172800s (~2 days)             2  #get the dominant epoch of the whole dataset dataset %>% dominant_epoch()               #> # A tibble: 1 × 2 #>   dominant.epoch    group.indices #>   <Duration>                <int> #> 1 172800s (~2 days)             1"},{"path":"https://tscnlab.github.io/LightLogR/reference/dose.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the dose (value·hours) — dose","title":"Calculate the dose (value·hours) — dose","text":"function calculates dose time series. light, equal actual definition light exposure (CIE term luminous exposure). Output always provided value·hours (e.g., light, lx·hours).","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/dose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the dose (value·hours) — dose","text":"","code":"dose(   Light.vector,   Time.vector,   epoch = \"dominant.epoch\",   na.rm = FALSE,   as.df = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/dose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the dose (value·hours) — dose","text":"Light.vector Numeric vector containing light data. Time.vector Vector containing time data. Can POSIXct, hms, duration, difftime. epoch epoch data sampled. Can either duration string. string, needs either \"dominant.epoch\" (default) guess based data, valid duration string, e.g., \"1 day\" \"10 sec\". na.rm Logical. missing values (NA) removed calculation? Defaults FALSE. .df Logical. data frame returned? TRUE, data frame single column named dose returned. Defaults FALSE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/dose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the dose (value·hours) — dose","text":"numeric object single value, single column data frame dose value·hours","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/dose.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate the dose (value·hours) — dose","text":"time series regular, however, aggregated regular timeseries given epoch. Implicit gaps (.e., observations), converted NA values (can ignored na.rm = TRUE).","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/dose.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate the dose (value·hours) — dose","text":"Hartmeyer, S.L., Andersen, M. (2023). Towards framework light-dosimetry studies: Quantification metrics. Lighting Research & Technology. doi:10.1177/14771535231170500","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/dose.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the dose (value·hours) — dose","text":"","code":"dose(c(1,1,1,1), lubridate::dhours(c(1:4)), na.rm = TRUE) #> [1] 4 #with gaps dose(c(1,1,1), lubridate::dhours(c(1,3:4)), na.rm = TRUE) #> [1] 3 #gaps can be aggregated to a coarser interval, which can be sensibe #if they are still representative dose(c(1,1,1), lubridate::dhours(c(1,3:4)), na.rm = TRUE, epoch = \"2 hours\") #> [1] 4"},{"path":"https://tscnlab.github.io/LightLogR/reference/dst_change_handler.html","id":null,"dir":"Reference","previous_headings":"","what":"Handle jumps in Daylight Savings (DST) that are missing in the data — dst_change_handler","title":"Handle jumps in Daylight Savings (DST) that are missing in the data — dst_change_handler","text":"data imported LightLogR timezone applied, assumed timestamps correct - case, e.g., timestamps stored UTC, local time. measurement devices set local time recording interval starts. recording daylight savings jump happens (either direction), device might adjust timestamps change. results unwanted shift data, starting time DST jump likely continues end file. dst_change_handler used detect jumps within group apply correct shift data (.e., shift applied device). important Note function useful time stamp raw data deviates actual date-time. Note also, function results gap DST jump, handled gap_handler() afterwards. also result potentially double timestamps jum back DST standard time. result inconsistencies functions, recommend use aggregate_Datetime() afterwards unit equal dominant epoch. Finally, function equipped handle one jump per group. jump based whether group starts DST . function remove datetime rows NA values.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/dst_change_handler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Handle jumps in Daylight Savings (DST) that are missing in the data — dst_change_handler","text":"","code":"dst_change_handler(   dataset,   Datetime.colname = Datetime,   filename.colname = NULL )"},{"path":"https://tscnlab.github.io/LightLogR/reference/dst_change_handler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Handle jumps in Daylight Savings (DST) that are missing in the data — dst_change_handler","text":"dataset dataset summarized, must dataframe Datetime.colname name column contains Datetime data, expects symbol filename.colname (optional) column name contains filename. provided, use column temporary grouping variable additionally dataset grouping.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/dst_change_handler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Handle jumps in Daylight Savings (DST) that are missing in the data — dst_change_handler","text":"tibble columns input dataset, shifted","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/dst_change_handler.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Handle jumps in Daylight Savings (DST) that are missing in the data — dst_change_handler","text":"detection DST jump based function lubridate::dst() jumps applied within group. import, function used dst_adjustment = TRUE set includes default filename grouping variable, additionally Id.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/dst_change_handler.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Handle jumps in Daylight Savings (DST) that are missing in the data — dst_change_handler","text":"","code":"#create some data that crosses a DST jump data <-   tibble::tibble(  Datetime = seq.POSIXt(from = as.POSIXct(\"2023-03-26 01:30:00\", tz = \"Europe/Berlin\"),                      to = as.POSIXct(\"2023-03-26 03:00:00\", tz = \"Europe/Berlin\"),                      by = \"30 mins\"),                      Value = 1)  #as can be seen next, there is a gap in the data - this is necessary when  #using a timezone with DST.   data$Datetime #> [1] \"2023-03-26 01:30:00 CET\"  \"2023-03-26 03:00:00 CEST\"  #Let us say now, that the device did not adjust for the DST - thus the 03:00   #timestamp is actually 04:00 in local time. This can be corrected for by:  data %>% dst_change_handler() %>% .$Datetime #> [1] \"2023-03-26 01:30:00 CET\"  \"2023-03-26 04:00:00 CEST\""},{"path":"https://tscnlab.github.io/LightLogR/reference/dst_change_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a summary of groups where a daylight saving time change occurs. — dst_change_summary","title":"Get a summary of groups where a daylight saving time change occurs. — dst_change_summary","text":"Get summary groups daylight saving time change occurs.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/dst_change_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a summary of groups where a daylight saving time change occurs. — dst_change_summary","text":"","code":"dst_change_summary(dataset, Datetime.colname = Datetime)"},{"path":"https://tscnlab.github.io/LightLogR/reference/dst_change_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a summary of groups where a daylight saving time change occurs. — dst_change_summary","text":"dataset dataset summarized, must dataframe Datetime.colname name column contains Datetime data, expects symbol","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/dst_change_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a summary of groups where a daylight saving time change occurs. — dst_change_summary","text":"tibble groups dst change occurs. column dst_start boolean indicates whether start group occurs daylight savings.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/dst_change_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get a summary of groups where a daylight saving time change occurs. — dst_change_summary","text":"","code":"sample.data.environment %>%    dplyr::mutate(Datetime =    Datetime + lubridate::dweeks(8)) %>%   dst_change_summary() #> # A tibble: 2 × 2 #>   Id          dst_start #>   <fct>       <lgl>     #> 1 Environment TRUE      #> 2 Participant TRUE"},{"path":"https://tscnlab.github.io/LightLogR/reference/duration_above_threshold.html","id":null,"dir":"Reference","previous_headings":"","what":"Duration above/below threshold or within threshold range — duration_above_threshold","title":"Duration above/below threshold or within threshold range — duration_above_threshold","text":"function calculates duration spent /specified threshold light level within specified range light levels.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/duration_above_threshold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Duration above/below threshold or within threshold range — duration_above_threshold","text":"","code":"duration_above_threshold(   Light.vector,   Time.vector,   comparison = c(\"above\", \"below\"),   threshold,   epoch = \"dominant.epoch\",   na.rm = FALSE,   as.df = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/duration_above_threshold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Duration above/below threshold or within threshold range — duration_above_threshold","text":"Light.vector Numeric vector containing light data. Time.vector Vector containing time data. Can POSIXct, hms, duration, difftime. comparison String specifying whether time threshold calculated. Can either \"\" (default) \"\". two values provided threshold, argument ignored. threshold Single numeric value two numeric values specifying threshold light level(s) compare . vector two values provided, time within two thresholds calculated. epoch epoch data sampled. Can either duration string. string, needs either \"dominant.epoch\" (default) guess based data, valid duration string, e.g., \"1 day\" \"10 sec\". na.rm Logical. missing values (NA) removed calculation? Defaults FALSE. .df Logical. data frame returned? TRUE, data frame single column named duration_{comparison}_{threshold} returned. Defaults FALSE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/duration_above_threshold.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Duration above/below threshold or within threshold range — duration_above_threshold","text":"duration object single value, single column data frame.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/duration_above_threshold.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Duration above/below threshold or within threshold range — duration_above_threshold","text":"Hartmeyer, S.L., Andersen, M. (2023). Towards framework light-dosimetry studies: Quantification metrics. Lighting Research & Technology. doi:10.1177/14771535231170500","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/duration_above_threshold.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Duration above/below threshold or within threshold range — duration_above_threshold","text":"","code":"N <- 60 # Dataset with epoch = 1min dataset1 <-   tibble::tibble(     Id = rep(\"A\", N),     Datetime = lubridate::as_datetime(0) + lubridate::minutes(1:N),     MEDI = sample(c(sample(1:249, N / 2), sample(250:1000, N / 2))),   ) # Dataset with epoch = 30s dataset2 <-   tibble::tibble(     Id = rep(\"B\", N),     Datetime = lubridate::as_datetime(0) + lubridate::seconds(seq(30, N * 30, 30)),     MEDI = sample(c(sample(1:249, N / 2), sample(250:1000, N / 2))),   ) dataset.combined <- rbind(dataset1, dataset2)  dataset1 %>%   dplyr::reframe(\"TAT >250lx\" = duration_above_threshold(MEDI, Datetime, threshold = 250)) #> # A tibble: 1 × 1 #>   `TAT >250lx`        #>   <Duration>          #> 1 1800s (~30 minutes)  dataset1 %>%   dplyr::reframe(duration_above_threshold(MEDI, Datetime, threshold = 250, as.df = TRUE)) #> # A tibble: 1 × 1 #>   duration_above_250  #>   <Duration>          #> 1 1800s (~30 minutes)  # Group by Id to account for different epochs dataset.combined %>%   dplyr::group_by(Id) %>%   dplyr::reframe(\"TAT >250lx\" = duration_above_threshold(MEDI, Datetime, threshold = 250)) #> # A tibble: 2 × 2 #>   Id    `TAT >250lx`        #>   <chr> <Duration>          #> 1 A     1800s (~30 minutes) #> 2 B     900s (~15 minutes)"},{"path":"https://tscnlab.github.io/LightLogR/reference/durations.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate duration of data in each group — durations","title":"Calculate duration of data in each group — durations","text":"function calculates total duration data group dataset, based datetime column variable column. uses dominant epoch (interval) group calculate duration.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/durations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate duration of data in each group — durations","text":"","code":"durations(   dataset,   Variable.colname = Datetime,   Datetime.colname = Datetime,   count.NA = FALSE,   show.missing = FALSE,   show.interval = FALSE,   FALSE.as.NA = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/durations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate duration of data in each group — durations","text":"dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variables Datetime.colname Variable.colname. Variable.colname Column name contains variable calculate duration. Expects symbol. Needs part dataset. Datetime.colname Column name contains datetime. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. Needs part dataset. Must type POSIXct. count.NA Logical. NA values Variable.colname counted part duration? Defaults FALSE. show.missing Logical. duration NAs provided separate column \"Missing\"? Defaults FALSE. show.interval Logical. dominant epoch (interval) shown column \"interval\"? Defaults FALSE. FALSE..NA Logical. FALSE values Variable.colname treated NA (.e., missing)?","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/durations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate duration of data in each group — durations","text":"tibble one row per group column \"duration\" containing duration group lubridate::duration(). show.missing = TRUE, column \"missing\" added duration NAs, column \"total\" total duration. show.interval = TRUE, column \"interval\" added dominant epoch group.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/durations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate duration of data in each group — durations","text":"","code":"# Calculate the duration of a dataset durations(sample.data.environment) #> # A tibble: 2 × 2 #> # Groups:   Id [2] #>   Id          duration          #>   <fct>       <Duration>        #> 1 Environment 518400s (~6 days) #> 2 Participant 518400s (~6 days)  # create artificial gaps in the data gapped_data <- sample.data.environment |>   dplyr::filter(MEDI >= 10) |>   gap_handler(full.days = TRUE)  #by default, the Datetime column is selected for the `Variable.colname`,  #basically ignoring NA measurement values gapped_data |>  durations(count.NA = TRUE) #> # A tibble: 2 × 2 #> # Groups:   Id [2] #>   Id          duration          #>   <fct>       <Duration>        #> 1 Environment 518400s (~6 days) #> 2 Participant 518400s (~6 days)  # Calculate the duration where MEDI are available durations(gapped_data, MEDI) #> # A tibble: 2 × 2 #> # Groups:   Id [2] #>   Id          duration             #>   <fct>       <Duration>           #> 1 Environment 307950s (~3.56 days) #> 2 Participant 257470s (~2.98 days)  # Calculate the duration, show the duration of NAs separately durations(gapped_data, MEDI, show.missing = TRUE) #> # A tibble: 2 × 4 #> # Groups:   Id [2] #>   Id          duration             missing              total             #>   <fct>       <Duration>           <Duration>           <Duration>        #> 1 Environment 307950s (~3.56 days) 210450s (~2.44 days) 518400s (~6 days) #> 2 Participant 257470s (~2.98 days) 260930s (~3.02 days) 518400s (~6 days)  # Calculate the duration, show the dominant epoch durations(gapped_data, Variable.colname = MEDI, show.interval = TRUE) #> # A tibble: 2 × 3 #> # Groups:   Id [2] #>   Id          duration             interval   #>   <fct>       <Duration>           <Duration> #> 1 Environment 307950s (~3.56 days) 30s        #> 2 Participant 257470s (~2.98 days) 10s         # Calculate durations for day and night separately gapped_data |>   add_photoperiod(coordinates = c(48.52, 9.06)) |>   dplyr::group_by(photoperiod.state, .add = TRUE) |>   durations(Variable.colname = MEDI, show.interval = TRUE, show.missing = TRUE) #> # A tibble: 4 × 6 #> # Groups:   Id, photoperiod.state [4] #>   Id          photoperiod.state duration             missing               #>   <fct>       <chr>             <Duration>           <Duration>            #> 1 Environment day               307950s (~3.56 days) 6270s (~1.74 hours)   #> 2 Environment night             0s                   204180s (~2.36 days)  #> 3 Participant day               232550s (~2.69 days) 81680s (~22.69 hours) #> 4 Participant night             24920s (~6.92 hours) 179250s (~2.07 days)  #> # ℹ 2 more variables: total <Duration>, interval <Duration>"},{"path":"https://tscnlab.github.io/LightLogR/reference/exponential_moving_average.html","id":null,"dir":"Reference","previous_headings":"","what":"Exponential moving average filter (EMA) — exponential_moving_average","title":"Exponential moving average filter (EMA) — exponential_moving_average","text":"function smoothes data using exponential moving average filter specified decay half-life.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/exponential_moving_average.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Exponential moving average filter (EMA) — exponential_moving_average","text":"","code":"exponential_moving_average(   Light.vector,   Time.vector,   decay = \"90 min\",   epoch = \"dominant.epoch\" )"},{"path":"https://tscnlab.github.io/LightLogR/reference/exponential_moving_average.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Exponential moving average filter (EMA) — exponential_moving_average","text":"Light.vector Numeric vector containing light data. Missing values replaced 0. Time.vector Vector containing time data. Can POSIXct, hms, duration, difftime. decay decay half-life controlling exponential smoothing. Can either duration string. string, needs valid duration string, e.g., \"1 day\" \"10 sec\". default set \"90 mins\" biologically relevant estimate (see reference paper). epoch epoch data sampled. Can either duration string. string, needs either \"dominant.epoch\" (default) guess based data, valid duration string, e.g., \"1 day\" \"10 sec\".","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/exponential_moving_average.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Exponential moving average filter (EMA) — exponential_moving_average","text":"numeric vector containing smoothed light data. output length Light.vector.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/exponential_moving_average.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Exponential moving average filter (EMA) — exponential_moving_average","text":"timeseries assumed regular. Missing values light data replaced 0.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/exponential_moving_average.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Exponential moving average filter (EMA) — exponential_moving_average","text":"Price, L. L. . (2014). Role Exponential Smoothing Circadian Dosimetry. Photochemistry Photobiology, 90(5), 1184-1192. doi:10.1111/php.12282 Hartmeyer, S.L., Andersen, M. (2023). Towards framework light-dosimetry studies: Quantification metrics. Lighting Research & Technology. doi:10.1177/14771535231170500","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/exponential_moving_average.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Exponential moving average filter (EMA) — exponential_moving_average","text":"","code":"sample.data.environment.EMA = sample.data.environment %>%   dplyr::filter(Id == \"Participant\") %>%   filter_Datetime(length = lubridate::days(2)) %>%   dplyr::mutate(MEDI.EMA = exponential_moving_average(MEDI, Datetime))  # Plot to compare results sample.data.environment.EMA %>%   ggplot2::ggplot(ggplot2::aes(x = Datetime)) +   ggplot2::geom_line(ggplot2::aes(y = MEDI), colour = \"black\") +   ggplot2::geom_line(ggplot2::aes(y = MEDI.EMA), colour = \"red\")"},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Find and extract clusters from a dataset — extract_clusters","title":"Find and extract clusters from a dataset — extract_clusters","text":"extract_clusters() searches summarizes clusters data meets certain condition. Clusters specified duration can interrupted still counting one cluster. variable can either column dataset expression gets evaluated dplyr::mutate() call. Cluster start end times shifted half epoch . E.g., state lasting 4 measurement points duration 4 measurement intervals, state occuring , one interval. deviates simply using time difference first last occurance, one epoch shorter (e.g., start end points state lasting single point identical, .e., zero duration) Groups dropped, meaning summaries based clusters account groups without clusters. correct cluster identification, can gaps data! Gaps can inadvertently introduced gapless dataset grouping. E.g., grouping photoperiod (day/night) within participant, introduces gaps individual days nights together form group. avoid , either group individual days nights (e.g., using number_states() grouping), make sure cluster extend beyond grouping. Alternatively, can set handle.gaps = TRUE (computational cost). add_clusters() identifies clusters adds back dataset rolling join. convenience function built extract_clusters().","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find and extract clusters from a dataset — extract_clusters","text":"","code":"extract_clusters(   data,   Variable,   Datetime.colname = Datetime,   cluster.duration = \"30 mins\",   duration.type = c(\"min\", \"max\"),   interruption.duration = 0,   interruption.type = c(\"max\", \"min\"),   cluster.colname = state.count,   return.only.clusters = TRUE,   drop.empty.groups = TRUE,   handle.gaps = FALSE,   add.label = FALSE )  add_clusters(   data,   Variable,   Datetime.colname = Datetime,   cluster.duration = \"30 mins\",   duration.type = c(\"min\", \"max\"),   interruption.duration = 0,   interruption.type = c(\"max\", \"min\"),   cluster.colname = state,   handle.gaps = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_clusters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find and extract clusters from a dataset — extract_clusters","text":"data light logger dataset. Expects dataframe. Variable variable condition evaluated clustering. Can column name expression. Datetime.colname Column name contains datetime. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. cluster.duration minimum maximum duration cluster. Defaults 30 minutes. Expects lubridate duration object (numeric seconds). duration.type Type duration requirement clusters. Either \"min\" (minimum duration) \"max\" (maximum duration). Defaults \"min\". interruption.duration duration allowed interruptions within cluster. Defaults 0 (interruptions allowed). interruption.type Type interruption duration. Either \"max\" (maximum interruption) \"min\" (minimum interruption). Defaults \"max\". cluster.colname Name column use cluster identification. Defaults \"state.count\". Expects symbol. return..clusters Whether return identified clusters (TRUE) also include non-clusters (FALSE). Defaults TRUE. drop.empty.groups Logical. empty groups dropped? works .drop = FALSE used current grouping prior calling function. Default TRUE. set FALSE can lead error factors present grouping levels actual data. Can, however, useful necessary summarizing groups , e.g. summarize_numeric() - empty group present important averaging numbers. handle.gaps Logical whether data shall treated gap_handler(). set FALSE default, due computational costs. add.label Logical. Option add label output containing condition. E.g., MEDI>500|d>=30min|<=5min clusters melanopic EDI larger 500, least 30 minutes long (d), allowing interruptions 5 minutes time ().","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_clusters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find and extract clusters from a dataset — extract_clusters","text":"extract_clusters() dataframe containing identified clusters time periods, depending return..clusters. add_clusters() dataframe containing original data additional column cluster identification.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_clusters.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find and extract clusters from a dataset — extract_clusters","text":"","code":"dataset <- sample.data.environment |> dplyr::filter(Id == \"Participant\") |> filter_Date(length = \"1 day\")  # Extract clusters with minimum duration of 1 hour and interruptions of up to 5 minutes dataset |>  extract_clusters(   MEDI > 250,   cluster.duration = \"1 hour\",   interruption.duration = \"5 mins\" ) #> # A tibble: 1 × 6 #> # Groups:   Id [1] #>   Id          state.count start               end                 epoch      #>   <fct>       <chr>       <dttm>              <dttm>              <Duration> #> 1 Participant 1           2023-08-29 16:34:49 2023-08-29 17:38:09 10s        #> # ℹ 1 more variable: duration <Duration>  # Add clusters to a dataset where lux values are above 20 for at least 30 minutes dataset_with_clusters <-  dataset %>% add_clusters(MEDI > 20)  #peak into the dataset dataset_with_clusters[4500:4505,] #> # A tibble: 6 × 4 #> # Groups:   Id [1] #>   Id          Datetime             MEDI state #>   <fct>       <dttm>              <dbl> <chr> #> 1 Participant 2023-08-29 12:29:54  40.6 2     #> 2 Participant 2023-08-29 12:30:04  48.3 2     #> 3 Participant 2023-08-29 12:30:14  46.5 2     #> 4 Participant 2023-08-29 12:30:24  48.5 2     #> 5 Participant 2023-08-29 12:30:34  42.3 2     #> 6 Participant 2023-08-29 12:30:44  44.6 2"},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_gaps.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract gap episodes from the data — extract_gaps","title":"Extract gap episodes from the data — extract_gaps","text":"Finds extracts gap episodes dataset. variable provided, look implicit gaps (gaps regular interval), variable provided, look implicit explicit gaps (NA variable)","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_gaps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract gap episodes from the data — extract_gaps","text":"","code":"extract_gaps(   dataset,   Variable.colname = NULL,   Datetime.colname = Datetime,   epoch = \"dominant.epoch\",   full.days = TRUE,   include.implicit.gaps = TRUE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_gaps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract gap episodes from the data — extract_gaps","text":"dataset light logger dataset. Needs dataframe. Variable.colname Column name variable check NA values. Expects symbol NULL (implicit gaps). Datetime.colname column contains datetime. Needs POSIXct part dataset. epoch epoch use gapless sequence. Can either lubridate::duration() string. string, needs either '\"dominant.epoch\"' (default) guess based data valid lubridate::duration() string, e.g., \"1 day\" \"10 sec\". full.days TRUE, gapless sequence include whole first last day data. include.implicit.gaps Logical. Whether expand datetime sequence search implicit gaps, . Default TRUE. Variable.colname provided, argument ignored. implicit gaps, gap calculation can incorrect whenever missing explicit gaps flanking implicit gaps!","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_gaps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract gap episodes from the data — extract_gaps","text":"dataframe containing gap times per grouping variable","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_gaps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract gap episodes from the data — extract_gaps","text":"","code":"#removing some data to create gaps sample.data.environment |>   dplyr::filter(MEDI <= 50000) |>   extract_gaps() |> head() #> # A tibble: 6 × 6 #> # Groups:   Id [1] #>   Id     gap.id epoch start               end                 duration           #>   <fct>   <int> <dbl> <dttm>              <dttm>              <Duration>         #> 1 Envir…      1    30 2023-08-30 11:27:23 2023-08-30 11:28:53 90s (~1.5 minutes) #> 2 Envir…      2    30 2023-08-30 11:29:53 2023-08-30 11:31:23 90s (~1.5 minutes) #> 3 Envir…      3    30 2023-08-30 11:33:53 2023-08-30 11:35:23 90s (~1.5 minutes) #> 4 Envir…      4    30 2023-08-30 11:48:53 2023-08-30 11:49:23 30s                #> 5 Envir…      5    30 2023-08-30 12:14:23 2023-08-30 12:14:53 30s                #> 6 Envir…      6    30 2023-08-30 12:15:23 2023-08-30 12:15:53 30s                 #not searching for implicit gaps sample.data.environment |>    dplyr::filter(MEDI <= 50000) |>   extract_gaps(MEDI, include.implicit.gaps = FALSE) #> Warning: There are implicit gaps in the dataset that will not be part of the extracted summary, due to `include.implicit.gaps = FALSE`. #> No gaps found #> # A tibble: 0 × 6 #> # Groups:   Id [0] #> # ℹ 6 variables: Id <fct>, gap.id <int>, epoch <dbl>, start <dttm>, end <dttm>, #> #   duration <Duration>  #making implicit gaps explicit changes the summary sample.data.environment |>    dplyr::filter(MEDI <= 50000) |>    gap_handler()|>    extract_gaps(MEDI, include.implicit.gaps = FALSE) |> head() #> # A tibble: 6 × 6 #> # Groups:   Id [1] #>   Id     gap.id epoch start               end                 duration           #>   <fct>   <int> <dbl> <dttm>              <dttm>              <Duration>         #> 1 Envir…      1    30 2023-08-30 11:27:23 2023-08-30 11:28:53 90s (~1.5 minutes) #> 2 Envir…      2    30 2023-08-30 11:29:53 2023-08-30 11:31:23 90s (~1.5 minutes) #> 3 Envir…      3    30 2023-08-30 11:33:53 2023-08-30 11:35:23 90s (~1.5 minutes) #> 4 Envir…      4    30 2023-08-30 11:48:53 2023-08-30 11:49:23 30s                #> 5 Envir…      5    30 2023-08-30 12:14:23 2023-08-30 12:14:53 30s                #> 6 Envir…      6    30 2023-08-30 12:15:23 2023-08-30 12:15:53 30s"},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Add metrics to extracted sSummary — extract_metric","title":"Add metrics to extracted sSummary — extract_metric","text":"helper function adds metric values extract, like extract_states() extract_clusters(). E.g., average value variable cluster state instance might interest. metrics must specified user using ... argument.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add metrics to extracted sSummary — extract_metric","text":"","code":"extract_metric(   extracted_data,   data,   identifying.colname = state.count,   Datetime.colname = Datetime,   ... )"},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add metrics to extracted sSummary — extract_metric","text":"extracted_data dataframe containing cluster state summaries, typically extract_clusters() extract_states(). data original dataset produced extracted_data identifying.colname Name column extracted_data uniquely identifies row (addition groups. Expects symbol. Defaults state.count Datetime.colname Column name contains datetime data. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. argument necessary data contain cluster.colname. ... Arguments specifying metrics add summary. example: \"mean_lux\" = mean(lux).","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_metric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add metrics to extracted sSummary — extract_metric","text":"dataframe containing extracted data added metrics.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_metric.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add metrics to extracted sSummary — extract_metric","text":"original data cluster/state information, computationally faster .","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_metric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add metrics to extracted sSummary — extract_metric","text":"","code":"# Extract clusters and add mean MEDI value sample.data.environment |> filter_Date(length = \"2 days\") |>  extract_clusters(MEDI > 1000) |> extract_metric(   sample.data.environment,   \"mean_medi\" = mean(MEDI, na.rm = TRUE) ) |> dplyr::select(Id, state.count, duration, mean_medi) #> # A tibble: 2 × 4 #> # Groups:   Id [1] #>   Id          state.count duration              mean_medi #>   <fct>       <chr>       <Duration>                <dbl> #> 1 Environment 1           46050s (~12.79 hours)    11906. #> 2 Environment 2           47370s (~13.16 hours)    25446.  # Extract states and add mean MEDI value dataset <- sample.data.environment |> filter_Date(length = \"2 days\") |>   add_photoperiod(c(48.5, 9))  dataset |>   extract_states(photoperiod.state) |>   extract_metric(dataset, mean_lux = mean(MEDI)) |>   dplyr::select(state.count, duration, mean_lux) #> Adding missing grouping variables: `Id`, `photoperiod.state` #> # A tibble: 10 × 5 #> # Groups:   Id, photoperiod.state [4] #>    Id          photoperiod.state state.count duration                mean_lux #>    <fct>       <chr>             <chr>       <Duration>                 <dbl> #>  1 Environment day               day 1       52920s (~14.7 hours)  10388.     #>  2 Environment day               day 2       52710s (~14.64 hours) 22893.     #>  3 Environment night             night 1     21810s (~6.06 hours)      0      #>  4 Environment night             night 2     33570s (~9.32 hours)      0.0142 #>  5 Environment night             night 3     11790s (~3.28 hours)      0.0433 #>  6 Participant day               day 1       52910s (~14.7 hours)    145.     #>  7 Participant day               day 2       52690s (~14.64 hours)   145.     #>  8 Participant night             night 1     21820s (~6.06 hours)      0      #>  9 Participant night             night 2     33580s (~9.33 hours)      6.29   #> 10 Participant night             night 3     11800s (~3.28 hours)     38.6"},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_states.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract summaries of states — extract_states","title":"Extract summaries of states — extract_states","text":"Extracts state dataset provides start end times, well duration epoch. state exist dataset, can dynamically created. Extracted states can group-dropping disabled, meaning summaries based extracted states show empty groups well.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_states.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract summaries of states — extract_states","text":"","code":"extract_states(   data,   State.colname,   State.expression = NULL,   Datetime.colname = Datetime,   handle.gaps = FALSE,   epoch = \"dominant.epoch\",   drop.empty.groups = TRUE,   group.by.state = TRUE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_states.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract summaries of states — extract_states","text":"data light logger dataset. Expects dataframe. State.colname variable condition evaluated state exctration. Expects symbol. part data, State.expression required. State.expression State.colname part data, expression evaluated generate state. result expression used grouping, recommended factor-like. State.colname part data, argument ignored Datetime.colname Column name contains datetime. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. handle.gaps Logical whether data shall treated gap_handler(). set FALSE default, due computational costs. epoch epoch use gapless sequence. Can either lubridate::duration() string. string, needs either '\"dominant.epoch\"' (default) guess based data valid lubridate::duration() string, e.g., \"1 day\" \"10 sec\". drop.empty.groups Logical. empty groups dropped? works .drop = FALSE used current grouping prior calling function. Default TRUE. set FALSE can lead error factors present grouping levels actual data. Can, however, useful necessary summarizing groups , e.g. summarize_numeric() - empty group present important averaging numbers. group..state Logical. output automatically grouped new state?","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_states.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract summaries of states — extract_states","text":"dataframe one row per state instance. row consist original dataset grouping, state column. state.count column, start end Datetimes, well duration state","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/extract_states.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract summaries of states — extract_states","text":"","code":"#summarizing states \"photoperiod\" states <- sample.data.environment |>   add_photoperiod(c(48.52, 9.06)) |>   extract_states(photoperiod.state) states |> head(2) #> # A tibble: 2 × 7 #> # Groups:   Id, photoperiod.state [1] #>   Id          photoperiod.state state.count epoch start               #>   <fct>       <chr>             <chr>       <dbl> <dttm>              #> 1 Environment day               day 1          30 2023-08-29 06:03:23 #> 2 Environment day               day 2          30 2023-08-30 06:04:53 #> # ℹ 2 more variables: end <dttm>, duration <Duration> states |> tail(2) #> # A tibble: 2 × 7 #> # Groups:   Id, photoperiod.state [1] #>   Id          photoperiod.state state.count epoch start               #>   <fct>       <chr>             <chr>       <dbl> <dttm>              #> 1 Participant night             night 6        10 2023-09-02 20:36:49 #> 2 Participant night             night 7        10 2023-09-03 20:34:39 #> # ℹ 2 more variables: end <dttm>, duration <Duration> states |> summarize_numeric(c(\"state.count\", \"epoch\")) #> # A tibble: 4 × 7 #> # Groups:   Id [2] #>   Id          photoperiod.state mean_start mean_end mean_duration         #>   <fct>       <chr>             <time>     <time>   <Duration>            #> 1 Environment day               06:07:08   20:39:58 52370s (~14.55 hours) #> 2 Environment night             21:08:32   08:40:23 29169s (~8.1 hours)   #> 3 Participant day               06:07:04   20:39:56 52372s (~14.55 hours) #> 4 Participant night             21:08:30   08:40:20 29167s (~8.1 hours)   #> # ℹ 2 more variables: total_duration <Duration>, episodes <int>"},{"path":"https://tscnlab.github.io/LightLogR/reference/filter_Datetime.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter Datetimes in a dataset. — filter_Datetime","title":"Filter Datetimes in a dataset. — filter_Datetime","text":"Filtering dataset based Dates Datetimes may often necessary prior calcuation visualization. functions allow filtering based simple strings Datetime scalars, specifying length. also support prior dplyr grouping, useful, e.g., want filter first two days measurement data every participant, regardless actual date. want filter based times day, look filter_Time().","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/filter_Datetime.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter Datetimes in a dataset. — filter_Datetime","text":"","code":"filter_Datetime(   dataset,   Datetime.colname = Datetime,   start = NULL,   end = NULL,   length = NULL,   length_from_start = TRUE,   full.day = FALSE,   tz = NULL,   only_Id = NULL,   filter.expr = NULL )  filter_Date(..., start = NULL, end = NULL)"},{"path":"https://tscnlab.github.io/LightLogR/reference/filter_Datetime.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter Datetimes in a dataset. — filter_Datetime","text":"dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variable Datetime.colname. Datetime.colname column name contains datetime. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. Needs part dataset. Must type POSIXct. start, end filter_Datetime() POSIXct character scalar form \"yyyy-mm-dd hh-mm-ss\" giving respective start end time positions filtered dataframe. want provide dates form \"yyyy-mm-dd\", use wrapper function filter_Date(). one start/end provided, times taken respective extreme values dataset. length provided one start/end , calculated based given value. length provided start/end NULL, time respective start taken. length Either Period Duration lubridate. E.g., days(2) + hours(12) give period 2.5 days, whereas ddays(2) + dhours(12) give duration. difference periods durations look documentation lubridate. Basically, periods model clocktimes, whereas durations model physical processes. matters several occasions, like leap years, daylight savings. can also provide character scalar form e.g. \"1 day\", converted period. length_from_start logical indicating whether length argument applied start (default, TRUE) end data (FALSE). relevant neither start end arguments provided. full.day logical indicating whether start param rounded full day, length argument provided (Default FALSE). useful, e.g., first observation dataset slightly midnight. TRUE, count length midnight avoid empty days plotting gg_day(). tz Timezone start/end times. NULL (default), take timezone Datetime.colname column. only_Id expression ids filtering applied . NULL (default), filtering applied ids. Based expression, dataset split two given expression evaluates TRUE, filtering take place. Afterwards sets recombined sorted Datetime. filter.expr Advanced filtering conditions. NULL (default) given expression, used dplyr::filter() results. can useful filter, e.g. group-specific conditions, like starting first two days measurement (see examples). ... Parameter handed lubridate::round_date() siblings","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/filter_Datetime.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter Datetimes in a dataset. — filter_Datetime","text":"data.frame object identical dataset specified Dates/Times.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/filter_Datetime.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter Datetimes in a dataset. — filter_Datetime","text":"","code":"library(lubridate) library(dplyr) #baseline range.unfiltered <- sample.data.environment$Datetime %>% range() range.unfiltered #> [1] \"2023-08-29 00:00:04 CEST\" \"2023-09-03 23:59:54 CEST\"  #setting the start of a dataset sample.data.environment %>% filter_Datetime(start = \"2023-08-31 12:00:00\") %>% pull(Datetime) %>% range() #> [1] \"2023-08-31 12:00:04 CEST\" \"2023-09-03 23:59:44 CEST\"  #setting the end of a dataset sample.data.environment %>% filter_Datetime(end = \"2023-08-31 12:00:00\") %>% pull(Datetime) %>% range() #> [1] \"2023-08-29 00:00:04 CEST\" \"2023-08-31 11:59:54 CEST\"  #setting a period of a dataset sample.data.environment %>% filter_Datetime(end = \"2023-08-31 12:00:00\", length = days(2)) %>% pull(Datetime) %>% range() #> [1] \"2023-08-29 12:00:04 CEST\" \"2023-08-31 11:59:54 CEST\"  #setting only the period of a dataset sample.data.environment %>% filter_Datetime(length = days(2)) %>% pull(Datetime) %>% range() #> [1] \"2023-08-29 00:00:04 CEST\" \"2023-08-30 23:59:54 CEST\"  #advanced filtering based on grouping (second day of each group) sample.data.environment %>% #shift the \"Environment\" group by one day mutate( Datetime = ifelse(Id == \"Environment\", Datetime + ddays(1), Datetime) %>% as_datetime()) -> sample sample %>% summarize(Daterange = paste(min(Datetime), max(Datetime), sep = \" - \")) #> # A tibble: 2 × 2 #>   Id          Daterange                                 #>   <fct>       <chr>                                     #> 1 Environment 2023-08-29 22:00:08 - 2023-09-04 21:59:38 #> 2 Participant 2023-08-28 22:00:04 - 2023-09-03 21:59:54 #now we can use the `filter.expr` argument to filter from the second day of each group sample %>% filter_Datetime(filter.expr = Datetime > Datetime[1] + days(1)) %>% summarize(Daterange = paste(min(Datetime), max(Datetime), sep = \" - \")) #> # A tibble: 2 × 2 #>   Id          Daterange                                 #>   <fct>       <chr>                                     #> 1 Environment 2023-08-30 22:00:38 - 2023-09-04 21:59:08 #> 2 Participant 2023-08-29 22:00:14 - 2023-09-03 21:59:54  sample.data.environment %>% filter_Date(end = \"2023-08-31\") #> # A tibble: 34,560 × 3 #> # Groups:   Id [2] #>    Id          Datetime             MEDI #>    <fct>       <dttm>              <dbl> #>  1 Participant 2023-08-29 00:00:04     0 #>  2 Participant 2023-08-29 00:00:14     0 #>  3 Participant 2023-08-29 00:00:24     0 #>  4 Participant 2023-08-29 00:00:34     0 #>  5 Participant 2023-08-29 00:00:44     0 #>  6 Participant 2023-08-29 00:00:54     0 #>  7 Participant 2023-08-29 00:01:04     0 #>  8 Participant 2023-08-29 00:01:14     0 #>  9 Participant 2023-08-29 00:01:24     0 #> 10 Participant 2023-08-29 00:01:34     0 #> # ℹ 34,550 more rows"},{"path":"https://tscnlab.github.io/LightLogR/reference/filter_Datetime_multiple.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter multiple times based on a list of arguments. — filter_Datetime_multiple","title":"Filter multiple times based on a list of arguments. — filter_Datetime_multiple","text":"filter_Datetime_multiple() wrapper around filter_Datetime() filter_Date() allows cumulative filtering Datetimes based varying filter conditions. useful conjunction only_Id argument, e.g., selectively cut dates depending participants (see examples)","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/filter_Datetime_multiple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter multiple times based on a list of arguments. — filter_Datetime_multiple","text":"","code":"filter_Datetime_multiple(   dataset,   arguments,   filter_function = filter_Datetime,   ... )"},{"path":"https://tscnlab.github.io/LightLogR/reference/filter_Datetime_multiple.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter multiple times based on a list of arguments. — filter_Datetime_multiple","text":"dataset light logger dataset arguments list arguments passed filter_Datetime() filter_Date(). list entry must list arguments, e.g, list(start = \"2021-01-01\", only_Id = quote(Id == 216)). Expressions quoted quote() rlang::expr(). filter_function function used filtering, either filter_Datetime (default) filter_Date ... Additional arguments passed filter function. length argument provided instead argument, written string, e.g., length = \"1 day\", instead length = lubridate::days(1).","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/filter_Datetime_multiple.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter multiple times based on a list of arguments. — filter_Datetime_multiple","text":"dataframe filtered data","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/filter_Datetime_multiple.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter multiple times based on a list of arguments. — filter_Datetime_multiple","text":"","code":"arguments <- list(  list(start = \"2023-08-31\", only_Id = quote(Id == \"Participant\")),  list(end = \"2023-08-31\", only_Id = quote(Id == \"Environment\")))  #compare the unfiltered dataset  sample.data.environment %>% gg_overview(Id.colname = Id)   #compare the unfiltered dataset  sample.data.environment %>%  filter_Datetime_multiple(arguments = arguments, filter_Date) %>%  gg_overview(Id.colname = Id)"},{"path":"https://tscnlab.github.io/LightLogR/reference/filter_Time.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter Times in a dataset. — filter_Time","title":"Filter Times in a dataset. — filter_Time","text":"Filter Times dataset.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/filter_Time.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter Times in a dataset. — filter_Time","text":"","code":"filter_Time(   dataset,   Datetime.colname = Datetime,   start = NULL,   end = NULL,   length = NULL )"},{"path":"https://tscnlab.github.io/LightLogR/reference/filter_Time.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter Times in a dataset. — filter_Time","text":"dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variable Datetime.colname. Datetime.colname column name contains datetime. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. Needs part dataset. Must type POSIXct. start, end, length character scalar form \"hh-mm-ss\" giving respective start, end, length filtered dataframe. input can also come POSIXct datetime, time component used. one start/end provided, times taken respective extreme values dataset. length provided one start/end , calculated based given value. length provided start/end , time respective start taken.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/filter_Time.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter Times in a dataset. — filter_Time","text":"data.frame object identical dataset specified Times.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/filter_Time.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter Times in a dataset. — filter_Time","text":"","code":"sample.data.environment %>% filter_Time(start = \"4:00:34\", length = \"12:00:00\") %>% dplyr::pull(Time) %>% range() %>% hms::as_hms() #> 04:00:34 #> 16:00:34"},{"path":"https://tscnlab.github.io/LightLogR/reference/frequency_crossing_threshold.html","id":null,"dir":"Reference","previous_headings":"","what":"Frequency of crossing light threshold — frequency_crossing_threshold","title":"Frequency of crossing light threshold — frequency_crossing_threshold","text":"functions calculates number times given threshold light level crossed.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/frequency_crossing_threshold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Frequency of crossing light threshold — frequency_crossing_threshold","text":"","code":"frequency_crossing_threshold(   Light.vector,   threshold,   na.rm = FALSE,   as.df = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/frequency_crossing_threshold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Frequency of crossing light threshold — frequency_crossing_threshold","text":"Light.vector Numeric vector containing light data. threshold Single numeric value specifying threshold light level compare . na.rm Logical. missing light values removed? Defaults FALSE. .df Logical. output returned data frame? TRUE, data frame single column named frequency_crossing_{threshold} returned. Defaults FALSE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/frequency_crossing_threshold.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Frequency of crossing light threshold — frequency_crossing_threshold","text":"Data frame matrix pairs threshold calculated values.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/frequency_crossing_threshold.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Frequency of crossing light threshold — frequency_crossing_threshold","text":"Alvarez, . ., & Wildsoet, C. F. (2013). Quantifying light exposure patterns young adult students. Journal Modern Optics, 60(14), 1200–1208. doi:10.1080/09500340.2013.845700 Hartmeyer, S.L., Andersen, M. (2023). Towards framework light-dosimetry studies: Quantification metrics. Lighting Research & Technology. doi:10.1177/14771535231170500","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/frequency_crossing_threshold.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Frequency of crossing light threshold — frequency_crossing_threshold","text":"","code":"N = 60 dataset1 <-   tibble::tibble(     Id = rep(\"A\", N),     Datetime = lubridate::as_datetime(0) + lubridate::minutes(1:N),     MEDI = sample(c(sample(1:249, N / 2), sample(250:1000, N / 2))),   )  dataset1 %>%   dplyr::reframe(\"Frequency crossing 250lx\" = frequency_crossing_threshold(MEDI, threshold = 250)) #> # A tibble: 1 × 1 #>   `Frequency crossing 250lx` #>                        <int> #> 1                         28  dataset1 %>%   dplyr::reframe(frequency_crossing_threshold(MEDI, threshold = 250, as.df = TRUE)) #> # A tibble: 1 × 1 #>   frequency_crossing_250 #>                    <int> #> 1                     28"},{"path":"https://tscnlab.github.io/LightLogR/reference/gain.ratio.tables.html","id":null,"dir":"Reference","previous_headings":"","what":"Gain / Gain-ratio tables to normalize counts — gain.ratio.tables","title":"Gain / Gain-ratio tables to normalize counts — gain.ratio.tables","text":"list tables containing gain gain-ratios normalize counts across different sensor gains.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gain.ratio.tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gain / Gain-ratio tables to normalize counts — gain.ratio.tables","text":"","code":"gain.ratio.tables"},{"path":"https://tscnlab.github.io/LightLogR/reference/gain.ratio.tables.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Gain / Gain-ratio tables to normalize counts — gain.ratio.tables","text":"gain.ratio.tables list containing two-column tibbles TSL2585 gain table ambient light sensor TSL2585 Info named character vector specifying version date sensor added","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gain.ratio.tables.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gain / Gain-ratio tables to normalize counts — gain.ratio.tables","text":"Utility: sensors provide raw counts gain levels part output. cases desirable compare counts sensors, e.g., gauge daylight outside comparing UV counts photopic counts (high ratio UV/Pho indicates outside daylight). gauge daylight inside comparing IR counts photopic counts (high ratio IR/Pho low ratio UV/Pho indicates daylight context LED fluorescent lighting)","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gap_finder.html","id":null,"dir":"Reference","previous_headings":"","what":"Check for and output gaps in a dataset — gap_finder","title":"Check for and output gaps in a dataset — gap_finder","text":"Quickly check implicit missing Datetime data. Outputs message short summary, can optionally return gaps tibble. Uses gap_handler() internally.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gap_finder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check for and output gaps in a dataset — gap_finder","text":"","code":"gap_finder(   dataset,   Datetime.colname = Datetime,   epoch = \"dominant.epoch\",   gap.data = FALSE,   silent = FALSE,   full.days = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/gap_finder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check for and output gaps in a dataset — gap_finder","text":"dataset light logger dataset. Needs dataframe. Datetime.colname column contains datetime. Needs POSIXct part dataset. epoch epoch use gapless sequence. Can either lubridate::duration() string. string, needs either '\"dominant.epoch\"' (default) guess based data valid lubridate::duration() string, e.g., \"1 day\" \"10 sec\". gap.data Logical. TRUE, returns tibble gaps dataset. Default FALSE. silent Logical. TRUE, suppresses message summary gaps dataset. Default FALSE. used unit tests. full.days TRUE, gapless sequence include whole first last day data.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gap_finder.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check for and output gaps in a dataset — gap_finder","text":"Prints message short summary gaps dataset. gap.data = TRUE, returns tibble gaps dataset.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gap_finder.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check for and output gaps in a dataset — gap_finder","text":"gap_finder() function wrapper around gap_handler() behavior argument set \"gaps\". main difference gap_finder() returns message short summary gaps dataset, tibble gaps contains column gap.id indicates gap number, useful determine, e.g., consecutive number gaps measurement data.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/gap_finder.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check for and output gaps in a dataset — gap_finder","text":"","code":"dataset <- tibble::tibble(Id = c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\"),               Datetime = lubridate::as_datetime(1) +                          lubridate::days(c(0:2, 4, 6, 8)) +                          lubridate::hours(c(0,12,rep(0,4)))) %>% dplyr::group_by(Id) dataset #> # A tibble: 6 × 2 #> # Groups:   Id [2] #>   Id    Datetime            #>   <chr> <dttm>              #> 1 A     1970-01-01 00:00:01 #> 2 A     1970-01-02 12:00:01 #> 3 A     1970-01-03 00:00:01 #> 4 B     1970-01-05 00:00:01 #> 5 B     1970-01-07 00:00:01 #> 6 B     1970-01-09 00:00:01  #look for gaps assuming the epoch is the dominant epoch of each group gap_finder(dataset) #> Found 2 gaps. 6 Datetimes fall into the regular sequence.  #return the gaps as a tibble gap_finder(dataset, gap.data = TRUE) #> Found 2 gaps. 6 Datetimes fall into the regular sequence. #> # A tibble: 2 × 3 #> # Groups:   Id [1] #>   gap.id Datetime            Id    #>    <int> <dttm>              <chr> #> 1      1 1970-01-01 12:00:01 A     #> 2      1 1970-01-02 00:00:01 A      #assuming the epoch is 1 day, we have different gaps, and the datapoint at noon is now `irregular` gap_finder(dataset, epoch = \"1 day\") #> Found 3 gaps. 5 Datetimes fall into the regular sequence."},{"path":"https://tscnlab.github.io/LightLogR/reference/gap_handler.html","id":null,"dir":"Reference","previous_headings":"","what":"Fill implicit gaps in a light logger dataset — gap_handler","title":"Fill implicit gaps in a light logger dataset — gap_handler","text":"Datasets light loggers often implicit gaps. gaps implicit sense consecutive timestamps (Datetimes) might follow regular epoch/interval. function fills implicit gaps creating gapless sequence Datetimes joining dataset. gapless sequence determined minimum maximum Datetime dataset (per group) epoch. epoch can either guessed dataset specified user. sequence gapless Datetimes can created gapless_Datetimes() function, whereas dominant epoch data can checked dominant_epoch() function. behaviour argument specifies data combined. default, data joined full join, means rows gapless sequence kept, even matching row dataset.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gap_handler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fill implicit gaps in a light logger dataset — gap_handler","text":"","code":"gap_handler(   dataset,   Datetime.colname = Datetime,   epoch = \"dominant.epoch\",   behavior = c(\"full_sequence\", \"regulars\", \"irregulars\", \"gaps\"),   full.days = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/gap_handler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fill implicit gaps in a light logger dataset — gap_handler","text":"dataset light logger dataset. Needs dataframe. Datetime.colname column contains datetime. Needs POSIXct part dataset. epoch epoch use gapless sequence. Can either lubridate::duration() string. string, needs either '\"dominant.epoch\"' (default) guess based data valid lubridate::duration() string, e.g., \"1 day\" \"10 sec\". behavior behavior join dataset gapless sequence. Can one \"full_sequence\" (default), \"regulars\", \"irregulars\", \"gaps\". See @return details. full.days TRUE, gapless sequence include whole first last day data.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gap_handler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fill implicit gaps in a light logger dataset — gap_handler","text":"modified tibble similar dataset handling implicit gaps, depending behavior argument: \"full_sequence\" adds timestamps dataset missing based full sequence Datetimes (.e., gapless sequence). dataset equal (gaps) greater number rows input. One column added. .implicit indicates whether row added (TRUE) (FALSE). helps differentiating measurement values values might imputed later . \"regulars\" keeps rows gapless sequence matching row dataset. can interpreted row-reduced dataset regular timestamps according epoch. case gaps tibble number rows input. \"irregulars\" keeps rows dataset follow regular sequence Datetimes according epoch. case gaps tibble 0 rows. \"gaps\" returns tibble implicit gaps dataset. case gaps tibble 0 rows.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/gap_handler.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fill implicit gaps in a light logger dataset — gap_handler","text":"","code":"dataset <- tibble::tibble(Id = c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\"),               Datetime = lubridate::as_datetime(1) +                          lubridate::days(c(0:2, 4, 6, 8)) +                          lubridate::hours(c(0,12,rep(0,4)))) %>%  dplyr::group_by(Id) dataset #> # A tibble: 6 × 2 #> # Groups:   Id [2] #>   Id    Datetime            #>   <chr> <dttm>              #> 1 A     1970-01-01 00:00:01 #> 2 A     1970-01-02 12:00:01 #> 3 A     1970-01-03 00:00:01 #> 4 B     1970-01-05 00:00:01 #> 5 B     1970-01-07 00:00:01 #> 6 B     1970-01-09 00:00:01 #assuming the epoch is 1 day, we can add implicit data to our dataset dataset %>% gap_handler(epoch = \"1 day\") #> # A tibble: 9 × 3 #> # Groups:   Id [2] #>   Id    Datetime            is.implicit #>   <chr> <dttm>              <lgl>       #> 1 A     1970-01-01 00:00:01 FALSE       #> 2 A     1970-01-02 00:00:01 TRUE        #> 3 A     1970-01-02 12:00:01 FALSE       #> 4 A     1970-01-03 00:00:01 FALSE       #> 5 B     1970-01-05 00:00:01 FALSE       #> 6 B     1970-01-06 00:00:01 TRUE        #> 7 B     1970-01-07 00:00:01 FALSE       #> 8 B     1970-01-08 00:00:01 TRUE        #> 9 B     1970-01-09 00:00:01 FALSE        #we can also check whether there are irregular Datetimes in our dataset dataset %>% gap_handler(epoch = \"1 day\", behavior = \"irregulars\") #> # A tibble: 1 × 3 #> # Groups:   Id [1] #>   Id    Datetime            is.implicit #>   <chr> <dttm>              <lgl>       #> 1 A     1970-01-02 12:00:01 FALSE        #to get to the gaps, we can use the \"gaps\" behavior dataset %>% gap_handler(epoch = \"1 day\", behavior = \"gaps\") #> # A tibble: 3 × 2 #> # Groups:   Id [2] #>   Id    Datetime            #>   <chr> <dttm>              #> 1 A     1970-01-02 00:00:01 #> 2 B     1970-01-06 00:00:01 #> 3 B     1970-01-08 00:00:01   #finally, we can also get just the regular Datetimes dataset %>% gap_handler(epoch = \"1 day\", behavior = \"regulars\") #> # A tibble: 5 × 3 #> # Groups:   Id [2] #>   Id    Datetime            is.implicit #>   <chr> <dttm>              <lgl>       #> 1 A     1970-01-01 00:00:01 FALSE       #> 2 A     1970-01-03 00:00:01 FALSE       #> 3 B     1970-01-05 00:00:01 FALSE       #> 4 B     1970-01-07 00:00:01 FALSE       #> 5 B     1970-01-09 00:00:01 FALSE"},{"path":"https://tscnlab.github.io/LightLogR/reference/gap_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Tabular summary of data and gaps in all groups — gap_table","title":"Tabular summary of data and gaps in all groups — gap_table","text":"gap_table() creates gt::gt() one row per group, summarizing key gap gap-related information dataset. include available data, total duration, number gaps, missing implicit explicit data, , optionally, irregular data.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gap_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tabular summary of data and gaps in all groups — gap_table","text":"","code":"gap_table(   dataset,   Variable.colname = MEDI,   Variable.label = \"melanopic EDI\",   title = \"Summary of available and missing data\",   Datetime.colname = Datetime,   epoch = \"dominant.epoch\",   full.days = TRUE,   include.implicit.gaps = TRUE,   check.irregular = TRUE,   get.df = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/gap_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tabular summary of data and gaps in all groups — gap_table","text":"dataset light logger dataset. Needs dataframe. Variable.colname Column name variable check NA values. Expects symbol. Variable.label Clear name variable. Expects string title Title string table Datetime.colname column contains datetime. Needs POSIXct part dataset. epoch epoch use gapless sequence. Can either lubridate::duration() string. string, needs either '\"dominant.epoch\"' (default) guess based data valid lubridate::duration() string, e.g., \"1 day\" \"10 sec\". full.days TRUE, gapless sequence include whole first last day data. include.implicit.gaps Logical. Whether expand datetime sequence search implicit gaps, . Default TRUE. Variable.colname provided, argument ignored. implicit gaps, gap calculation can incorrect whenever missing explicit gaps flanking implicit gaps! check.irregular Logical whether include irregular data summary, .e. data points fall regular sequence. get.df Logical whether dataframe returned instead gt::gt() table","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gap_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tabular summary of data and gaps in all groups — gap_table","text":"gt table data gaps dataset","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gap_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tabular summary of data and gaps in all groups — gap_table","text":"","code":"sample.data.environment |> dplyr::filter(MEDI <= 50000) |> gap_table()     Summary of available and missing data     Variable: melanopic EDI                     Data                       Missing                            Regular                       Irregular                       Range                       Interval                       Gaps                       Implicit                       Explicit            Time       %       n1       n2,1       Time       n1       Time       N       ø       øn1       Time       %       n1       Time       %       n1       Time       %       n1     Overall 1w 4d 6h 42m 50s 94.0%3 67,003 0 1w 5d 69,120 30; 10 200 7m 8s 15 17h 17m 10s 6.0%3 2,117 17h 17m 10s 6.0%3 2,117 0s 0.0%3 0Environment      5d 6h 53m 30s 88.1% 15,227 0 6d 17,280 30s 148 6m 56s 14 17h 6m 30s 11.9% 2,053 17h 6m 30s 11.9% 2,053 0s 0.0% 0Participant      5d 23h 49m 20s 99.9% 51,776 0 6d 51,840 10s 52 12s 1 10m 40s 0.1% 64 10m 40s 0.1% 64 0s 0.0% 01 Number of (missing or actual) observations     2 If n > 0: it is possible that the other summary statistics are affected, as they are calculated based on the most prominent interval.     3 Based on times, not necessarily number of observations"},{"path":"https://tscnlab.github.io/LightLogR/reference/gapless_Datetimes.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a gapless sequence of Datetimes — gapless_Datetimes","title":"Create a gapless sequence of Datetimes — gapless_Datetimes","text":"Create gapless sequence Datetimes. Datetimes determined minimum maximum Datetime dataset epoch. epoch can either guessed dataset specified user.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gapless_Datetimes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a gapless sequence of Datetimes — gapless_Datetimes","text":"","code":"gapless_Datetimes(   dataset,   Datetime.colname = Datetime,   epoch = \"dominant.epoch\",   full.days = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/gapless_Datetimes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a gapless sequence of Datetimes — gapless_Datetimes","text":"dataset light logger dataset. Needs dataframe. Datetime.colname column contains datetime. Needs POSIXct part dataset. epoch epoch use gapless sequence. Can either lubridate::duration() string. string, needs either '\"dominant.epoch\"' (default) guess based data valid lubridate::duration() string, e.g., \"1 day\" \"10 sec\". full.days TRUE, gapless sequence include whole first last day data.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gapless_Datetimes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a gapless sequence of Datetimes — gapless_Datetimes","text":"tibble gapless sequence Datetime specified epoch.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/gapless_Datetimes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a gapless sequence of Datetimes — gapless_Datetimes","text":"","code":"dataset <-   tibble::tibble(Id = c(\"A\", \"A\", \"A\", \"B\", \"B\", \"B\"),                  Datetime = lubridate::as_datetime(1) +                  lubridate::days(c(0:2, 4, 6, 8))) %>%                  dplyr::group_by(Id)    dataset %>% gapless_Datetimes() #> # A tibble: 6 × 2 #> # Groups:   Id [2] #>   Id    Datetime            #>   <chr> <dttm>              #> 1 A     1970-01-01 00:00:01 #> 2 A     1970-01-02 00:00:01 #> 3 A     1970-01-03 00:00:01 #> 4 B     1970-01-05 00:00:01 #> 5 B     1970-01-07 00:00:01 #> 6 B     1970-01-09 00:00:01   dataset %>% dplyr::ungroup() %>%  gapless_Datetimes() #> # A tibble: 5 × 1 #>   Datetime            #>   <dttm>              #> 1 1970-01-01 00:00:01 #> 2 1970-01-03 00:00:01 #> 3 1970-01-05 00:00:01 #> 4 1970-01-07 00:00:01 #> 5 1970-01-09 00:00:01   dataset %>% gapless_Datetimes(epoch = \"1 day\") #> # A tibble: 8 × 2 #> # Groups:   Id [2] #>   Id    Datetime            #>   <chr> <dttm>              #> 1 A     1970-01-01 00:00:01 #> 2 A     1970-01-02 00:00:01 #> 3 A     1970-01-03 00:00:01 #> 4 B     1970-01-05 00:00:01 #> 5 B     1970-01-06 00:00:01 #> 6 B     1970-01-07 00:00:01 #> 7 B     1970-01-08 00:00:01 #> 8 B     1970-01-09 00:00:01"},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_day.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a simple Time-of-Day plot of light logger data, faceted by Date — gg_day","title":"Create a simple Time-of-Day plot of light logger data, faceted by Date — gg_day","text":"gg_day() create simple ggplot every data dataset. result can manipulated like ggplot. sensible refine styling guides.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_day.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a simple Time-of-Day plot of light logger data, faceted by Date — gg_day","text":"","code":"gg_day(   dataset,   start.date = NULL,   end.date = NULL,   x.axis = Datetime,   y.axis = MEDI,   aes_col = NULL,   aes_fill = NULL,   group = Id,   geom = \"point\",   scales = c(\"fixed\", \"free_x\", \"free_y\", \"free\"),   x.axis.breaks = hms::hms(hours = seq(0, 24, by = 3)),   y.axis.breaks = c(-10^(5:0), 0, 10^(0:5)),   y.scale = \"symlog\",   y.scale.sc = FALSE,   x.axis.label = \"Time of Day\",   y.axis.label = \"Illuminance (lx, MEDI)\",   format.day = \"%d/%m\",   title = NULL,   subtitle = NULL,   interactive = FALSE,   facetting = TRUE,   jco_color = TRUE,   ... )"},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_day.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a simple Time-of-Day plot of light logger data, faceted by Date — gg_day","text":"dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variable x.axis.. start.date, end.date Choose optional start end date within dataset. Expects date, can also character interpretable date, e.g., \"2023-06-03\". need Datetime want cut specific times day, use filter_Datetime() function. Defaults NULL, means plot starts/ends earliest/latest date within dataset. x.axis, y.axis column name contains datetime (x, defaults \"Datetime\" automatically correct data imported LightLogR) dependent variable (y, defaults \"MEDI\", melanopic EDI, standard measure stimulus strength nonvisual effects light). Expects symbol. Needs part dataset. aes_col, aes_fill optional arguments define separate sets colors fills . Expects anything works layer data ggplot2::aes(). default color palette can overwritten outside function (see examples). group Optional column name defines separate sets. Useful certain geoms like boxplot.Expects anything works layer data ggplot2::aes() geom geom used visualization? Expects character \"point\" ggplot2::geom_point() \"line\"  ggplot2::geom_line() \"ribbon\" ggplot2::geom_ribbon() value just input geom_ function ggplot2, variants work well, extensively tested. scales ggplot2::facet_wrap(), scales \"fixed\", \"free\" free one dimension (\"free_y\" default). Expects character. x.axis.breaks, y.axis.breaks breaks occur x y.axis? Expects numeric vector breaks. want activate default behaviour ggplot2, need put ggplot2::waiver(). y.scale y-axis scaled? Defaults \"symlog\", logarithmic scale can also handle negative values. \"log10\" straight logarithmic scale, handle negative values. \"identity\" nothing (continuous scaling). transforming function, symlog_trans() scales::identity_trans(), allow control. y.scale.sc logical whether scientific notation shall used. Defaults FALSE. x.axis.label, y.axis.label labels x- y-axis. Expects character. format.day Label day. Default %d/%m, shows day month. Expects character. overview sensible options look base::strptime() title Plot title. Expects character. subtitle Plot subtitle. Expects character. interactive plot interactive? Expects logical. Defaults FALSE. facetting automated facet day applied? Default TRUE uses Day.data variable function also creates present. jco_color ggsci::scale_color_jco() color palette used? Defaults TRUE. ... options get passed main geom function. Can used adjust adjust size, linewidth, linetype.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_day.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a simple Time-of-Day plot of light logger data, faceted by Date — gg_day","text":"ggplot object","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_day.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a simple Time-of-Day plot of light logger data, faceted by Date — gg_day","text":"Besides plotting, function creates two new variables given Datetime: Day.data factor used facetting ggplot2::facet_wrap(). Make sure use variable, change faceting manually. Also, function checks, whether variable already exists. , convert factor faceting variable. Time hms created hms::as_hms() used x.axis default scaling y-axis symlog scale, logarithmic scale starts scaling given threshold (default = 0). enables values 0 plot, common light logger data, even enables negative values, might sensible non-light data. See symlog_trans() details tweaking scale. scale can also changed normal logarithmic scale - see y.scale argument . default scaling color fill scales discrete, ggsci::scale_color_jco() ggsci::scale_fill_jco() scales. use continuous scale, use jco_color = FALSE setting. fill color aesthetics set NULL default. geoms, important, geoms automatically use aesthetics (like geom_bin2d, fill = stat(count)) affected . Manually adding required aesthetic (like aes_fill = ggplot2::stat(count) fix ).","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_day.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a simple Time-of-Day plot of light logger data, faceted by Date — gg_day","text":"","code":"#use `col`for separation of different sets plot <- gg_day( sample.data.environment, scales = \"fixed\", end.date = \"2023-08-31\", y.axis.label = \"mEDI (lx)\", aes_col = Id) #> Only Dates will be used from start.date and end.date input. If you also want to set Datetimes or Times, consider using the `filter_Datetime()` function instead. plot   #you can easily overwrite the color scale afterwards plot + ggplot2::scale_color_discrete() #> Scale for colour is already present. #> Adding another scale for colour, which will replace the existing scale.   #or change the facetting plot + ggplot2::facet_wrap(~Day.data + Id)"},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_days.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a simple datetime plot of light logger data, faceted by group — gg_days","title":"Create a simple datetime plot of light logger data, faceted by group — gg_days","text":"gg_days() create simple ggplot along timeline. result can manipulated like ggplot. sensible refine styling guides. x.axis.limits arguments, plot can much refined align several groups differing datetime ranges. uses Datetime_limits() function calculate limits x-axis. Another notable functions used Datetime_breaks() calculate breaks x-axis.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_days.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a simple datetime plot of light logger data, faceted by group — gg_days","text":"","code":"gg_days(   dataset,   x.axis = Datetime,   y.axis = MEDI,   aes_col = NULL,   aes_fill = NULL,   group = NULL,   geom = \"line\",   scales = c(\"free_x\", \"free_y\", \"fixed\", \"free\"),   x.axis.breaks = Datetime_breaks,   y.axis.breaks = c(-10^(5:0), 0, 10^(0:5)),   y.scale = \"symlog\",   y.scale.sc = FALSE,   x.axis.label = \"Local Date/Time\",   y.axis.label = \"Illuminance (lx, MEDI)\",   x.axis.limits = Datetime_limits,   x.axis.format = \"%a %D\",   title = NULL,   subtitle = NULL,   interactive = FALSE,   facetting = TRUE,   jco_color = TRUE,   ... )"},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_days.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a simple datetime plot of light logger data, faceted by group — gg_days","text":"dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variable x.axis.. x.axis, y.axis column name contains datetime (x, defaults \"Datetime\" automatically correct data imported LightLogR) dependent variable (y, defaults \"MEDI\", melanopic EDI, standard measure stimulus strength nonvisual effects light). Expects symbol. Needs part dataset. aes_col, aes_fill optional input defines separate sets colors fills . Expects anything works layer data ggplot2::aes(). group Optional column name defines separate sets. Useful certain geoms like boxplot.Expects anything works layer data ggplot2::aes() geom geom used visualization? Expects character \"point\" ggplot2::geom_point() \"line\"  ggplot2::geom_line() \"ribbon\" ggplot2::geom_ribbon() value just input geom_ function ggplot2, variants work well, extensively tested. scales ggplot2::facet_wrap(), scales \"fixed\", \"free\" \"free\" one dimension (\"free_x\" default). Expects character. x.axis.breaks (major) breaks x-axis. Defaults Datetime_breaks(). function several options adjustment. default setting place major break every 12 hours, starting 12:00 first day. y.axis.breaks breaks occur y.axis? Expects numeric vector breaks function calculates based limits. want activate default behaviour ggplot2, need put ggplot2::waiver(). y.scale y-axis scaled? Defaults \"symlog\", logarithmic scale can also handle negative values. \"log10\" straight logarithmic scale, handle negative values. \"identity\" nothing (continuous scaling). transforming function, symlog_trans() scales::identity_trans(), allow control. y.scale.sc logical whether scientific notation shall used. Defaults FALSE. x.axis.label, y.axis.label labels x- y-axis. Expects character. x.axis.limits limits x-axis. Defaults Datetime_limits(). Can adjusted shift x-axis align different groups data. x.axis.format format x-axis labels. Defaults \"%%D\", weekday date. See base::strptime() options. title Plot title. Expects character. subtitle Plot subtitle. Expects character. interactive plot interactive? Expects logical. Defaults FALSE. facetting automated facet grouping applied? Default TRUE. jco_color ggsci::scale_color_jco() color palette used? Defaults TRUE. ... options get passed main geom function. Can used adjust adjust size, linewidth, linetype.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_days.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a simple datetime plot of light logger data, faceted by group — gg_days","text":"ggplot object","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_days.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a simple datetime plot of light logger data, faceted by group — gg_days","text":"default scaling y-axis symlog scale, logarithmic scale starts scaling given threshold (default = 0). enables values 0 plot, common light logger data, even enables negative values, might sensible non-light data. See symlog_trans() details tweaking scale. scale can also changed normal logarithmic scale - see y.scale argument .","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_days.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a simple datetime plot of light logger data, faceted by group — gg_days","text":"","code":"dataset <- sample.data.environment %>% aggregate_Datetime(unit = \"5 mins\")  dataset %>% gg_days()  #restrict the x-axis to 3 days dataset %>% gg_days( x.axis.limits = \\(x) Datetime_limits(x, length = lubridate::ddays(3)) ) #> Warning: Removed 864 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_doubleplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Double Plots — gg_doubleplot","title":"Double Plots — gg_doubleplot","text":"function default opinionated, automatically select best way display double date plot. However, user can also manually select type double date plot displayed: repeating day (default one day groups), displaying consecutive days (default multiple days groups).","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_doubleplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Double Plots — gg_doubleplot","text":"","code":"gg_doubleplot(   dataset,   Datetime.colname = Datetime,   type = c(\"auto\", \"repeat\", \"next\"),   geom = \"ribbon\",   alpha = 0.5,   col = \"grey40\",   fill = \"#EFC000FF\",   linewidth = 0.4,   x.axis.breaks.next = Datetime_breaks,   x.axis.format.next = \"%a %D\",   x.axis.breaks.repeat = ~Datetime_breaks(.x, by = \"6 hours\", shift =     lubridate::duration(0, \"hours\")),   x.axis.format.repeat = \"%H:%M\",   ... )"},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_doubleplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Double Plots — gg_doubleplot","text":"dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variable Datetime.colname. Datetime.colname column name contains datetime. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. Needs part dataset. Must type POSIXct. type One \"auto\", \"repeat\", \"next\". default \"auto\", automatically select best way display double date plot based amount days dataset (= 1 >> \"repeat\", else \"next). \"repeat\" repeat day plot, \"next\" display consecutive days. geom type geom used plot. default \"ribbon\". alpha, linewidth alpha linewidth setting geom. default 0.5 0.4, respectively. col, fill color fill geom. default \"#EFC000FF\". parameters aes_col aes_fill used ..., override respective col fill parameters. x.axis.breaks.next, x.axis.breaks.repeat Datetime breaks consecutive days displayed (type = \"next\") days repeated (type = \"repeat\"). Must function. default next label 12:00 day, repeat label every 6 hours. x.axis.format.next, x.axis.format.repeat Datetime label format consecutive days displayed (type = \"next\") days repeated (type = \"repeat\"). default next \"%%D\", showing date, repeat ist \"%H:%M\", showing hours minutes. See base::strptime() options. ... Arguments passed gg_days(). arguments aes_col aes_fill used, invalidate col fill parameters.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_doubleplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Double Plots — gg_doubleplot","text":"ggplot object","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_doubleplot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Double Plots — gg_doubleplot","text":"gg_doubleplot() wrapper function gg_days(), combined internal function duplicate reorganize dates dataset double plot view. means day displayed multiple times within plot order reveal pattern across days.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_doubleplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Double Plots — gg_doubleplot","text":"","code":"#take only the Participant data from sample data, and three days library(dplyr) library(lubridate) library(ggplot2) sample.data <-  sample.data.environment %>%  dplyr::filter(Id == \"Participant\") %>%  filter_Date(length = ddays(3))  #create a double plot with the default settings sample.data %>% gg_doubleplot()   #repeat the same day in the plot sample.data %>% gg_doubleplot(type = \"repeat\")   #more examples that are not executed for computation time: # \\donttest{ #use the function with more than one Id sample.data.environment %>%  filter_Date(length = ddays(3)) %>%  gg_doubleplot(aes_fill = Id, aes_col = Id) + facet_wrap(~ Date.data, ncol = 1, scales = \"free_x\", strip.position = \"left\")   #if data is already grouped by days, type = \"repeat\" will be automatic sample.data.environment %>%  dplyr::group_by(Date = date(Datetime), .add = TRUE) %>%  filter_Date(length = ddays(3)) %>%  gg_doubleplot(aes_fill = Id, aes_col = Id) +  guides(fill = \"none\", col = \"none\") + #remove the legend facet_wrap(~ Date.data, ncol = 1, scales = \"free_x\", strip.position = \"left\")   #combining `aggregate_Date()` with `gg_doubleplot()` easily creates a good #overview of the data sample.data.environment %>% aggregate_Date() %>% gg_doubleplot()  # }"},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_gaps.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize gaps and irregular data — gg_gaps","title":"Visualize gaps and irregular data — gg_gaps","text":"gg_gaps() built upon gg_days(), gap_finder(), gg_state() visualize gaps irregular data dataset . function differentiate implicit gaps, missing timestamps regular interval, explicit gaps, NA values. Optionally, function shows irregular data, datapoints fall outside regular interval.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_gaps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize gaps and irregular data — gg_gaps","text":"","code":"gg_gaps(   dataset,   Variable.colname = MEDI,   Datetime.colname = Datetime,   fill.gaps = \"red\",   col.irregular = \"red\",   alpha = 0.5,   on.top = FALSE,   epoch = \"dominant.epoch\",   full.days = TRUE,   show.irregulars = FALSE,   group.by.days = FALSE,   include.implicit.gaps = TRUE,   ... )"},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_gaps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize gaps and irregular data — gg_gaps","text":"dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variable x.axis.. Variable.colname Variable becomes basis gap analysis. expects symbol Datetime.colname column contains datetime. Needs POSIXct part dataset. fill.gaps Fill color gaps col.irregular Dot color irregular data alpha numerical value 0 1 representing transparency gaps Default 0.5. .top Logical scalar. TRUE, states plotted top existing plot. FALSE, states plotted underneath epoch epoch use gapless sequence. Can either lubridate::duration() string. string, needs either '\"dominant.epoch\"' (default) guess based data valid lubridate::duration() string, e.g., \"1 day\" \"10 sec\". full.days Logical. Whether full days expected, even first last measurement show.irregulars Logical. Show irregular data points. Default FALSE. group..days Logical. Whether data grouped days. can make sense days large groups affected include.implicit.gaps Logical. Whether time series expanded current observations taken. ... Additional arguments given gg_days(). Can used change color aesthetic properties.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_gaps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize gaps and irregular data — gg_gaps","text":"ggplot object gaps optionally irregular data. Groups gaps irregular data removed clarity. Null groups remain","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_gaps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize gaps and irregular data — gg_gaps","text":"","code":"#calling gg_gaps on a healthy dataset is pointless sample.data.environment |> gg_gaps() #> No gaps nor irregular values were found. Plot creation skipped  #creating a gapped and irregular dataset bad_dataset <- sample.data.environment |>   aggregate_Datetime(unit = \"5 mins\") |>   dplyr::filter(Id == \"Participant\") |>    filter_Date(length = \"2 days\") |>   dplyr::mutate(    Datetime = dplyr::if_else(      lubridate::date(Datetime) == max(lubridate::date(Datetime)),            Datetime, Datetime + 1      )    ) |> dplyr::filter(MEDI <250) bad_dataset |> has_gaps() #> [1] TRUE bad_dataset |> has_irregulars() #> [1] TRUE  #by default, gg_gaps() only shows gaps bad_dataset |> gg_gaps() #> Warning: Removed 1 row containing missing values or values outside the scale range #> (`geom_line()`).   #it can also show irregular data bad_dataset |> gg_gaps(show.irregulars = TRUE) #> Warning: Removed 1 row containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_heatmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a heatmap across days and times of day — gg_heatmap","title":"Plot a heatmap across days and times of day — gg_heatmap","text":"function plots heatmap binned values across day days group. also allows doubleplot functionality. **gg_heatmap() work additive functions gg_photoperiod() gg_state().","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_heatmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a heatmap across days and times of day — gg_heatmap","text":"","code":"gg_heatmap(   dataset,   Variable.colname = MEDI,   Datetime.colname = Datetime,   unit = \"1 hour\",   doubleplot = c(\"no\", \"same\", \"next\"),   date.title = \"Date\",   date.breaks = 1,   date.labels = \"%d/%m\",   time.title = \"Local time (HH:MM)\",   time.breaks = hms::hms(hours = seq(0, 48, by = 6)),   time.labels = \"%H:%M\",   fill.title = \"Illuminance\\n(lx, mel EDI)\",   fill.scale = \"symlog\",   fill.labels = function(x) format(x, scientific = FALSE, big.mark = \" \"),   fill.breaks = c(-10^(5:0), 0, 10^(0:5)),   fill.limits = c(0, 10^5),   fill.remove = FALSE,   ... )"},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_heatmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a heatmap across days and times of day — gg_heatmap","text":"dataset light dataset Variable.colname column name variable display. Defaults MEDI. Expects symbol. Datetime.colname column name datetime column. Defaults Datetime. Expects symbol. unit level aggregation Variable.colname. Defaults \"1 hour\". Expects duration duration-coercible value doubleplot data plotted doubleplot. Default \"\". \"next\" plot respective next day first, \"\" plot day twice. date.title Title text y-axis. Defaults Date date.breaks Spacing date breaks. Defaults 1 (every day) date.labels Formatting code date labels time.title Title text x-axis. Defaults Local time (HH:MM) time.breaks Spacing time breaks. Defauls every six hours. time.labels Formatting code time labels fill.title Title text value (fill) scale. fill.scale Scaling value (fill) scale. Defaults \"symlog\" (see symlog_trans()) fill.labels Formula format label values. fill.breaks Breaks fill scale fill.limits Limits fill scale. length-2 numeric lower upper scale. one replaced NA, limit based data. fill.remove Logical. fill scale removed? Handy fill scale replaced another scale without console messages warning existing scale ... arguments provide underlying ggplot2::geom_raster()","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_heatmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a heatmap across days and times of day — gg_heatmap","text":"ggplot object","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_heatmap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot a heatmap across days and times of day — gg_heatmap","text":"function uses ggplot2::scale_fill_viridis_c() fill scale. scale can substituted scale via standard + command ggplot2. recommended set fill.remove = TRUE reduce warnings.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_heatmap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a heatmap across days and times of day — gg_heatmap","text":"","code":"sample.data.environment |> gg_heatmap()   #heatmap with doubleplot sample.data.environment |> gg_heatmap(doubleplot = \"next\")   #change the unit of aggregation sample.data.environment |> gg_heatmap(unit = \"5 mins\")   #change the limits of the fill scale sample.data.environment |> gg_heatmap(fill.limits = c(0, 10^4))"},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_overview.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot an overview of dataset intervals with implicit missing data — gg_overview","title":"Plot an overview of dataset intervals with implicit missing data — gg_overview","text":"Plot overview dataset intervals implicit missing data","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_overview.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot an overview of dataset intervals with implicit missing data — gg_overview","text":"","code":"gg_overview(   dataset,   Datetime.colname = Datetime,   Id.colname = Id,   gap.data = NULL,   ...,   interactive = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_overview.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot an overview of dataset intervals with implicit missing data — gg_overview","text":"dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variable x.axis.. Datetime.colname column name contains datetime. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. Needs part dataset. Id.colname column name Id column (default Id), needs dataset. also used y-axis variable minimum grouping variable. gap.data Optionally provide tibble start end Datetimes gaps per group. provided, function uses gap_finder() calculate implicit missing data. might computationally intensive large datasets many missing data. cases can make sense calculate gaps beforehand provide function. empty tibble (tibble::tibble()) provided, function just plot start end dates dataset, computationally fast cost additional info. ... Additional arguments given main ggplot2::aes() used styling depending data within dataset interactive plot interactive? Expects logical. Defaults FALSE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_overview.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot an overview of dataset intervals with implicit missing data — gg_overview","text":"ggplot object","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_overview.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot an overview of dataset intervals with implicit missing data — gg_overview","text":"","code":"sample.data.environment %>% gg_overview()"},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_photoperiod.html","id":null,"dir":"Reference","previous_headings":"","what":"Add photoperiods to gg_day() or gg_days() plots — gg_photoperiod","title":"Add photoperiods to gg_day() or gg_days() plots — gg_photoperiod","text":"gg_photoperiod() helper function add photoperiod information plots generated gg_day() gg_days(). function can either draw dawn dusk columns dataset use coordinates solarDep arguments calculate photoperiods. time series must based column called Datetime.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_photoperiod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add photoperiods to gg_day() or gg_days() plots — gg_photoperiod","text":"","code":"gg_photoperiod(   ggplot_obj,   coordinates = NULL,   alpha = 0.2,   solarDep = 6,   on.top = FALSE,   ... )"},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_photoperiod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add photoperiods to gg_day() or gg_days() plots — gg_photoperiod","text":"ggplot_obj ggplot object generated gg_day() gg_days() (gg_doubleplot(). dataset used create must Datetime column. coordinates two element numeric vector representing latitude longitude location. NULL, default, function look dawn dusk columns dataset. present, (POSIXct format), function stop error. , NULL, solarDep argument ignored. alpha numerical value 0 1 representing transparency photoperiods. Default 0.2. solarDep numerical value representing solar depression angle 90 -90. means value 6 equals -6 degrees horizon. Default 6, equalling Civil dawn/dusk. common values 12 degrees Nautical dawn/dusk, 18 degrees Astronomical dawn/dusk, 0 degrees Sunrise/Sunset. Note output columns always named dawn dusk, regardless solarDep value. .top Logical scalar. TRUE, photoperiods plotted top existing plot. FALSE, photoperiods plotted underneath existing plot. Default FALSE. ... Additional arguments given ggplot2::geom_rect() used construct photoperiod shading. Can used change fill color aesthetic properties.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_photoperiod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add photoperiods to gg_day() or gg_days() plots — gg_photoperiod","text":"modified ggplot object photoperiods added.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_photoperiod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add photoperiods to gg_day() or gg_days() plots — gg_photoperiod","text":"used combination gg_doubleplot(), function type = \"repeat\" setting (either manually set, one day data per group present), photoperiods need added separately add_photoperiod(), second photoperiod panel one day. See examples information. general, photoperiod setup complex, makes sense add prior plotting make sure photoperiods correct.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_photoperiod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add photoperiods to gg_day() or gg_days() plots — gg_photoperiod","text":"","code":"coordinates <- c(48.521637, 9.057645) #adding photoperiods to a ggplot sample.data.environment |>   gg_days() |>   gg_photoperiod(coordinates)   #adding photoperiods prior to plotting sample.data.environment |>   add_photoperiod(coordinates, solarDep = 0) |>   gg_days() |>   gg_photoperiod()   #more examples that are not executed for computation time: # \\donttest{ #plotting photoperiods automatically works for both gg_day() and gg_days() sample.data.environment |>   gg_day() |>   gg_photoperiod(coordinates)   #plotting for gg_doubleplot mostly works fine sample.data.environment |>   filter_Date(length = \"2 days\") |>   gg_doubleplot() |>   gg_photoperiod(coordinates)   #however, in cases where only one day of data per group is available, or the #type = \"repeat\" setting is used, the photoperiods need to be added #separately. Otherwise the second day will be off by one day in each panel. #The visual difference is subtle, and might not be visible at all, as #photoperiod only every changes by few minutes per day.  #WRONG sample.data.environment |>   filter_Date(length = \"1 days\") |>   gg_doubleplot() |>   gg_photoperiod(coordinates)   #CORRECT sample.data.environment |>   filter_Date(length = \"1 days\") |>   add_photoperiod(coordinates) |>   gg_doubleplot() |>   gg_photoperiod()    # }"},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_state.html","id":null,"dir":"Reference","previous_headings":"","what":"Add states to gg_day() or gg_days() plots — gg_state","title":"Add states to gg_day() or gg_days() plots — gg_state","text":"gg_state() helper function add state information plots generated gg_day(), gg_days(), gg_doubleplot(). function can draw column dataset, factor-like logical columns make sense. time series must based column called Datetime.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_state.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add states to gg_day() or gg_days() plots — gg_state","text":"","code":"gg_state(   ggplot_obj,   State.colname,   aes_fill = NULL,   aes_col = NULL,   alpha = 0.2,   on.top = FALSE,   ignore.FALSE = TRUE,   ... )"},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_state.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add states to gg_day() or gg_days() plots — gg_state","text":"ggplot_obj ggplot object generated gg_day() gg_days() (gg_doubleplot(). dataset used create must Datetime column. State.colname colname state add plot. Must part dataset. Expects symbol. aes_fill, aes_col conditional aesthetics ggplot2::geom_rect(). default (NULL) ignored, col fill arguments can set ... arguments. states work summarized dataset, columns available filling/coloring: State.colname, Grouping variables, variables created using extract_states(). alpha numerical value 0 1 representing transparency states. Default 0.2. .top Logical scalar. TRUE, states plotted top existing plot. FALSE, states plotted underneath existing plot. Default FALSE. ignore.FALSE Logical drops FALSE values logical state column, TRUE values recognized state. relevant logical state columns ignored otherwise. Default TRUE. ... Additional arguments given ggplot2::geom_rect() used construct state shading. Can used change fill color aesthetic properties.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_state.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add states to gg_day() or gg_days() plots — gg_state","text":"modified ggplot object states added.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/gg_state.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add states to gg_day() or gg_days() plots — gg_state","text":"","code":"#creating a simple TRUE/FALSE state in the sample data: Light above 250 lx mel EDI #and a second state that cuts data into chunks relating to the Brown et al. 2022 thresholds #(+aggregating Data to 5 minute intervals & reducing it to three days) state_data <-   sample.data.environment |>    dplyr::mutate(state = MEDI > 250) |>    Brown_cut(MEDI, state2) |>     aggregate_Datetime(unit = \"5 mins\") |>    filter_Datetime(length = \"3 days\")  state_data |>  gg_days() |>  gg_state(state)   #state 2 has more than one valid state, thus we need to assign a fill aesthetic state_data |>  gg_days() |>  gg_state(state2, aes_fill = state2) +  ggplot2::scale_fill_manual(values=c(\"#868686FF\", \"#EFC000FF\", \"#0073C2FF\")) #> Scale for fill is already present. #> Adding another scale for fill, which will replace the existing scale.   #this line is simply for sensible colors  #same, but with gg_day() state_data |>  dplyr::filter(Id == \"Participant\") |>  gg_day(geom = \"line\") |>  gg_state(state, fill = \"red\")    #more complex state  state_data |>  dplyr::filter(Id == \"Participant\") |>  gg_day(geom = \"line\") |>  gg_state(state2, aes_fill = state2)    #with gg_doubleplot  state_data |>  dplyr::filter(Id == \"Participant\") |>  gg_doubleplot() |>  gg_state(state2, aes_fill = state2)"},{"path":"https://tscnlab.github.io/LightLogR/reference/has_gaps.html","id":null,"dir":"Reference","previous_headings":"","what":"Does a dataset have implicit gaps — has_gaps","title":"Does a dataset have implicit gaps — has_gaps","text":"Returns TRUE implicit gaps dataset FALSE gapless. Gaps can make sense depending grouping structure, general sequence Datetimes within dataset always gapless.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/has_gaps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Does a dataset have implicit gaps — has_gaps","text":"","code":"has_gaps(dataset, Datetime.colname = Datetime, epoch = \"dominant.epoch\")"},{"path":"https://tscnlab.github.io/LightLogR/reference/has_gaps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Does a dataset have implicit gaps — has_gaps","text":"dataset light logger dataset. Needs dataframe. Datetime.colname column contains datetime. Needs POSIXct part dataset. epoch epoch use gapless sequence. Can either lubridate::duration() string. string, needs either '\"dominant.epoch\"' (default) guess based data valid lubridate::duration() string, e.g., \"1 day\" \"10 sec\".","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/has_gaps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Does a dataset have implicit gaps — has_gaps","text":"logical","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/has_gaps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Does a dataset have implicit gaps — has_gaps","text":"","code":"#The sample dataset does not have gaps sample.data.environment |> has_gaps() #> [1] FALSE #removing some of the data creates gaps sample.data.environment |> dplyr::filter(MEDI <= 50000) |> has_gaps() #> [1] TRUE  #having a grouped dataframe where the groups span multiple unconnected parts  #is considered a gap, which can be relevant, e.g., when searching for clusters sample.data.environment |>   add_photoperiod(c(47.1, 10)) |>   dplyr::group_by(photoperiod.state) |>   has_gaps() #> [1] TRUE   #to avoid this, use `number_states()` for grouping  sample.data.environment |>   add_photoperiod(c(48.52, 9.06)) |>   number_states(photoperiod.state) |>   dplyr::group_by(photoperiod.state.count, .add = TRUE) |>   has_gaps() #> [1] FALSE"},{"path":"https://tscnlab.github.io/LightLogR/reference/has_irregulars.html","id":null,"dir":"Reference","previous_headings":"","what":"Does a dataset have irregular data — has_irregulars","title":"Does a dataset have irregular data — has_irregulars","text":"Returns TRUE irregular data dataset FALSE . Irregular data can make sense two datasets within single group shifted one another, e.g., contains data two separate recording sessions. second session unlikely started exact interval timing first session. problematic , still recommended rectify Datetimes common timestamp time precision permits , e.g., aggregate_Datetime() cut_Datetime().","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/has_irregulars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Does a dataset have irregular data — has_irregulars","text":"","code":"has_irregulars(dataset, Datetime.colname = Datetime, epoch = \"dominant.epoch\")"},{"path":"https://tscnlab.github.io/LightLogR/reference/has_irregulars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Does a dataset have irregular data — has_irregulars","text":"dataset light logger dataset. Needs dataframe. Datetime.colname column contains datetime. Needs POSIXct part dataset. epoch epoch use gapless sequence. Can either lubridate::duration() string. string, needs either '\"dominant.epoch\"' (default) guess based data valid lubridate::duration() string, e.g., \"1 day\" \"10 sec\".","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/has_irregulars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Does a dataset have irregular data — has_irregulars","text":"logical","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/has_irregulars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Does a dataset have irregular data — has_irregulars","text":"","code":"#the sample dataset does not have any irregular data sample.data.environment |> has_irregulars() #> [1] FALSE  #even removing some data does not make it irregular, as all the Datetimes #still fall in the regular interval sample.data.environment |> dplyr::filter(MEDI <= 50000) |> has_irregulars() #> [1] FALSE  #shifting some of the data will create irregular data sample.data.environment |>    dplyr::mutate(    Datetime = dplyr::if_else(      sample(c(TRUE, FALSE), dplyr::n(), replace = TRUE), Datetime, Datetime + 1      )    ) |>     has_irregulars() #> [1] TRUE"},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Import a light logger dataset or related data — import_Dataset","title":"Import a light logger dataset or related data — import_Dataset","text":"Imports dataset necessary transformations get right column formats. Unless specified otherwise, function set timezone data UTC. also enforce Id separate different datasets order/arrange dataset within Id Datetime. See Details Devices section information full list arguments.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import a light logger dataset or related data — import_Dataset","text":"","code":"import_Dataset(device, ...)  import"},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Import a light logger dataset or related data — import_Dataset","text":"object class list length 19.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import a light logger dataset or related data — import_Dataset","text":"device device want import? devices, sample data file can use test function (see examples). See supported_devices() list supported devices see information devices specific requirements. ... Parameters get handed specific import functions","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import a light logger dataset or related data — import_Dataset","text":"Tibble/Dataframe POSIXct column datetime","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import a light logger dataset or related data — import_Dataset","text":"specific general import function. general import function described , whereas specific import functions take form import$device(). general import function thin wrapper around specific import functions. specific import functions take following arguments: filename: Filename(s) Dataset. Can also contain filepath, path must NULL. Expects character. vector longer 1, multiple files read one Tibble. path: Optional path dataset(s). NULL default. Expects character. n_max: maximum number lines read. Default Inf. tz: Timezone data. \"UTC\" default. Expects character. can look supported timezones OlsonNames(). Id.colname: Lets specify column id dataset. Expects symbol (Default Id). column used grouping (dplyr::group_by()). auto.id: Id.colname column part dataset, Id can automatically extracted filename. argument expects regular expression regex default just give whole filename without file extension. manual.id: argument NULL, Id column part dataset, character scalar used. discourage use arguments importing one file silent: set TRUE, function print summary message import plot overview. Default FALSE. locale: locale controls defaults vary place place. .: Remove data prior date. argument provided start filter_Date(). Data filtered summaries shown. dst_adjustment: file crosses daylight savings time, device adjust time stamps accordingly, can set argument TRUE, apply shift manually. selective, done files cross DST standard time. Default FALSE. Uses dst_change_handler() adjustment. Look infos. equipped handle two jumps one file (back forth DST standard time), work fine jums occur separate files. auto.plot: logical whether call gg_overview() import. Default TRUE. set FALSE argument silent set TRUE. ...: supply additional arguments readr import functions, like na. Might also used supply arguments specific import functions, like column_names Actiwatch_Spectrum devices. devices always throw helpful error message forget supply necessary arguments. Id column already part dataset just use column. column present add column fill filename importfile (see param auto.id). print_n can used want see rows observation intervals remove_duplicates can used identical observations present within across multiple files. default FALSE. function keeps unique observations (=rows) set ' TRUE'. convenience implementation dplyr::distinct().","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"devices","dir":"Reference","previous_headings":"","what":"Devices","title":"Import a light logger dataset or related data — import_Dataset","text":"set import functions provide convenient way import light logger data perfectly formatted add metadata, make visualizations analyses. number devices supported, import just work box. get overview, can simply call supported_devices() dataset. list grow continuously package maintained.","code":"supported_devices() #>  [1] \"ActLumus\"              \"ActTrust\"              \"Actiwatch_Spectrum\" #>  [4] \"Actiwatch_Spectrum_de\" \"Circadian_Eye\"         \"Clouclip\" #>  [7] \"DeLux\"                 \"GENEActiv_GGIR\"        \"Kronowise\" #> [10] \"LIMO\"                  \"LYS\"                   \"LiDo\" #> [13] \"LightWatcher\"          \"MotionWatch8\"          \"OcuWEAR\" #> [16] \"Speccy\"                \"SpectraWear\"           \"VEET\" #> [19] \"nanoLambda\""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"actlumus","dir":"Reference","previous_headings":"","what":"ActLumus","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: Condor Instruments Model: ActLumus Implemented: Sep 2023 sample file provided package, can accessed system.file(\"extdata/205_actlumus_Log_1020_20230904101707532.txt.zip\", package = \"LightLogR\"). need unzipped imported. sample file good example regular dataset without gaps","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"lys","dir":"Reference","previous_headings":"","what":"LYS","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: LYS Technologies Model: LYS Button Implemented: Sep 2023 sample file provided package, can accessed system.file(\"extdata/sample_data_LYS.csv\", package = \"LightLogR\"). sample file good example irregular dataset.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"actiwatch-spectrum-amp-actiwatch-spectrum-de","dir":"Reference","previous_headings":"","what":"Actiwatch_Spectrum & Actiwatch_Spectrum_de","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: Philips Respironics Model: Actiwatch Spectrum Implemented: Nov 2023 / July 2024 Important note: Actiwatch_Spectrum function international/english formatting. Actiwatch_Spectrum_de function german formatting, slightly differs datetime format, column names, decimal separator.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"acttrust","dir":"Reference","previous_headings":"","what":"ActTrust","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: Condor Instruments Model: ActTrust1, ActTrust2 Implemented: Mar 2024 function works ActTrust 1 2 devices","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"speccy","dir":"Reference","previous_headings":"","what":"Speccy","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: Monash University Model: Speccy Implemented: Feb 2024","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"delux","dir":"Reference","previous_headings":"","what":"DeLux","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: Intelligent Automation Inc Model: DeLux Implemented: Dec 2023","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"lido","dir":"Reference","previous_headings":"","what":"LiDo","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: University Lucerne Model: LiDo Implemented: Nov 2023","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"spectrawear","dir":"Reference","previous_headings":"","what":"SpectraWear","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: University Manchester Model: SpectraWear Implemented: May 2024","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"nanolambda","dir":"Reference","previous_headings":"","what":"NanoLambda","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: NanoLambda Model: XL-500 BLE Implemented: May 2024","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"lightwatcher","dir":"Reference","previous_headings":"","what":"LightWatcher","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: Object-Tracker Model: LightWatcher Implemented: June 2024","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"veet","dir":"Reference","previous_headings":"","what":"VEET","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: Meta Reality Labs Model: VEET Implemented: July 2024 Required Argument: modality character scalar describing modality imported . Can one \"ALS\" (Ambient light sensor), \"IMU\" (Inertial Measurement Unit), \"INF\" (Information), \"PHO\" (Spectral Sensor), \"TOF\" (Time Flight)","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"circadian-eye","dir":"Reference","previous_headings":"","what":"Circadian_Eye","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: Max-Planck-Institute Biological Cybernetics, Tübingen Model: melanopiQ Circadian Eye (Prototype) Implemented: July 2024","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"kronowise","dir":"Reference","previous_headings":"","what":"Kronowise","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: Kronohealth Model: Kronowise Implemented: July 2024","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"geneactiv-with-ggir-preprocessing","dir":"Reference","previous_headings":"","what":"GENEActiv with GGIR preprocessing","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: Activeinsights Model: GENEActiv Note: import function takes GENEActiv data preprocessed GGIR package. default, GGIR aggregates light data intervals 15 minutes. can set windowsizes argument GGIR, three-value vector, second values set 900 seconds default. import preprocessed data LightLogR, filename argument requires path parent directory GGIR output folders, specifically meta folder, contains light exposure data. Multiple filenames can specified, needs path different GGIR parent directory. GGIR exports can contain data multiple participants, always imported fully providing parent directory. Use pattern argument extract sensible Ids .RData filenames within meta/basic/ folder. per author, Dr. Vincent van Hees, GGIR preprocessed data always local time, provided desiredtz/configtz properly set GGIR. LightLogR still requires timezone set, timeshift import data.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"motionwatch-","dir":"Reference","previous_headings":"","what":"MotionWatch 8","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: CamNtech Implemented: September 2024","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"limo","dir":"Reference","previous_headings":"","what":"LIMO","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: ENTPE Implemented: September 2024 LIMO exports LIGHT data IMU (inertia measurements, also UV) separate files. can read function, time. Please decide type data need provide respective filenames.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"ocuwear","dir":"Reference","previous_headings":"","what":"OcuWEAR","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: Ocutune Implemented: September 2024 OcuWEAR data contains spectral data. Due format data file, spectrum directly part tibble, rather list column tibbles within imported data, containing Wavelength (nm) Intensity (mW/m^2) column.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"clouclip","dir":"Reference","previous_headings":"","what":"Clouclip","title":"Import a light logger dataset or related data — import_Dataset","text":"Manufacturer: Clouclip Implemented: April 2025 Clouclip export files ending .xls, real Microsoft Excel files, rather tab-separated text files. LightLogR thus read excel import routine. measurement columns Lux Dis contain sentinel values. -1 (Dis Lux) indicates sleep mode, whereas 204 (Dis) indicates range measurement. values set NA, additional column added translates status codes. columns carry name {.col}_status.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Dataset.html","id":"imports-made-easy","dir":"Reference","previous_headings":"","what":"Imports made easy","title":"Import a light logger dataset or related data — import_Dataset","text":"import file, simple specify filename (path) feed import_Dataset function. sample datasets devices. import functions provide basic overview data import, intervals measurements start end dates.   Import functions can also called directly:","code":"filepath <- system.file(\"extdata/205_actlumus_Log_1020_20230904101707532.txt.zip\", package = \"LightLogR\") dataset <- import_Dataset(\"ActLumus\", filepath, auto.plot = FALSE) #> #> Successfully read in 61'016 observations across 1 Ids from 1 ActLumus-file(s). #> Timezone set is UTC. #> The system timezone is Europe/Berlin. Please correct if necessary! #> #> First Observation: 2023-08-28 08:47:54 #> Last Observation: 2023-09-04 10:17:04 #> Timespan: 7.1 days #> #> Observation intervals: #>   Id                                          interval.time     n pct #> 1 205_actlumus_Log_1020_20230904101707532.txt 10s           61015 100% dataset <- import$ActLumus(filepath, auto.plot = FALSE) #> #> Successfully read in 61'016 observations across 1 Ids from 1 ActLumus-file(s). #> Timezone set is UTC. #> The system timezone is Europe/Berlin. Please correct if necessary! #> #> First Observation: 2023-08-28 08:47:54 #> Last Observation: 2023-09-04 10:17:04 #> Timespan: 7.1 days #> #> Observation intervals: #>   Id                                          interval.time     n pct #> 1 205_actlumus_Log_1020_20230904101707532.txt 10s           61015 100% dataset %>% dplyr::select(Datetime, TEMPERATURE, LIGHT, MEDI, Id) %>% dplyr::slice(1500:1505) #> # A tibble: 6 x 5 #> # Groups:   Id [1] #>   Datetime            TEMPERATURE LIGHT  MEDI Id #>   <dttm>                    <dbl> <dbl> <dbl> <fct> #> 1 2023-08-28 12:57:44        26.9  212.  202. 205_actlumus_Log_1020_20230904101~ #> 2 2023-08-28 12:57:54        26.9  208.  199. 205_actlumus_Log_1020_20230904101~ #> 3 2023-08-28 12:58:04        26.9  205.  196. 205_actlumus_Log_1020_20230904101~ #> 4 2023-08-28 12:58:14        26.8  204.  194. 205_actlumus_Log_1020_20230904101~ #> 5 2023-08-28 12:58:24        26.9  203.  194. 205_actlumus_Log_1020_20230904101~ #> 6 2023-08-28 12:58:34        26.8  204.  195. 205_actlumus_Log_1020_20230904101~"},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Statechanges.html","id":null,"dir":"Reference","previous_headings":"","what":"Import data that contain Datetimes of Statechanges — import_Statechanges","title":"Import data that contain Datetimes of Statechanges — import_Statechanges","text":"Auxiliary data greatly enhances data analysis. function allows import files contain Statechanges, .e., specific time points State (like sleep wake) starts.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Statechanges.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import data that contain Datetimes of Statechanges — import_Statechanges","text":"","code":"import_Statechanges(   filename,   path = NULL,   sep = \",\",   dec = \".\",   structure = c(\"wide\", \"long\"),   Datetime.format = \"ymdHMS\",   tz = \"UTC\",   State.colnames,   State.encoding = State.colnames,   Datetime.column = Datetime,   Id.colname,   State.newname = State,   Id.newname = Id,   keep.all = FALSE,   silent = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Statechanges.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import data that contain Datetimes of Statechanges — import_Statechanges","text":"filename Filename(s) Dataset. Can also contain filepath, path must NULL. Expects character. vector longer 1, multiple files read one Tibble. path Optional path dataset(s). NULL default. Expects character. sep String separates columns import file. Defaults \",\". dec String indicates decimal separator import file. Defaults \".\". structure String specifies whether import file long wide format. Defaults \"wide\". Datetime.format String specifies format Datetimes file. default \"ymdHMS\" specifies format like \"2023-07-10 10:00:00\". function, lubridate::parse_date_time() actual conversion - documentation can searched valid inputs. tz Timezone data. \"UTC\" default. Expects character. can look supported timezones OlsonNames(). State.colnames Column name vector column names (latter wide format). Expects character. wide format, column names indicate State must contain Datetimes. columns pivoted columns specified Datetime.column State.newname. long format, column contains State State.encoding wide format, enables recoding column names state names, differences. default uses State.colnames argument. Expects character (vector) length State.colnames. Datetime.column Symbol Datetime column (also default). wide format, newly created column Datetimes State.colnames. long format, existing column contains Datetimes. Id.colname Symbol column contains ID subject. State.newname Symbol column contain State subject. wide format, newly created column State.colnames. long format, argument used rename State column. Id.newname Column name used renaming Id.colname column. keep.Logical specifies whether columns kept output. Defaults FALSE. silent Logical specifies whether summary imported data shown. Defaults FALSE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Statechanges.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import data that contain Datetimes of Statechanges — import_Statechanges","text":"dataset ID, State, Datetime columns. May contain additional columns keep.TRUE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Statechanges.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import data that contain Datetimes of Statechanges — import_Statechanges","text":"Data can present long wide format. wide format, multiple Datetime columns indicate state column name. get pivoted long format can recoded State.encoding argument. long format, one column indicates State, gives Datetime.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_Statechanges.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import data that contain Datetimes of Statechanges — import_Statechanges","text":"","code":"#get the example file from within the package path <- system.file(\"extdata/\", package = \"LightLogR\") file.sleep <- \"205_sleepdiary_all_20230904.csv\"  #import Data in the wide format (sleep/wake times) import_Statechanges(file.sleep, path, Datetime.format = \"dmyHM\", State.colnames = c(\"sleep\", \"offset\"), State.encoding = c(\"sleep\", \"wake\"), Id.colname = record_id, sep = \";\", dec = \",\") #>  #> Successfully read in 14 observations across 1 Ids from 1 Statechanges-file(s). #> Timezone set is UTC. #>  #> First Observation: 2023-08-28 23:20:00 #> Last Observation: 2023-09-04 07:25:00 #> Timespan: 6.3 days #>  #> Observation intervals:  #>    Id    interval.time             n pct   #>  1 205   34860s (~9.68 hours)      1 8%    #>  2 205   35520s (~9.87 hours)      1 8%    #>  3 205   35700s (~9.92 hours)      1 8%    #>  4 205   36000s (~10 hours)        1 8%    #>  5 205   36900s (~10.25 hours)     1 8%    #>  6 205   37020s (~10.28 hours)     1 8%    #>  7 205   37920s (~10.53 hours)     1 8%    #>  8 205   45780s (~12.72 hours)     1 8%    #>  9 205   48480s (~13.47 hours)     1 8%    #> 10 205   49200s (~13.67 hours)     1 8%    #> # ℹ 3 more rows #> # A tibble: 14 × 3 #> # Groups:   Id [1] #>    Id    State Datetime            #>    <fct> <chr> <dttm>              #>  1 205   sleep 2023-08-28 23:20:00 #>  2 205   wake  2023-08-29 09:37:00 #>  3 205   sleep 2023-08-29 23:40:00 #>  4 205   wake  2023-08-30 09:21:00 #>  5 205   sleep 2023-08-30 23:15:00 #>  6 205   wake  2023-08-31 09:47:00 #>  7 205   sleep 2023-08-31 23:15:00 #>  8 205   wake  2023-09-01 09:30:00 #>  9 205   sleep 2023-09-01 23:10:00 #> 10 205   wake  2023-09-02 09:10:00 #> 11 205   sleep 2023-09-02 22:55:00 #> 12 205   wake  2023-09-03 08:47:00 #> 13 205   sleep 2023-09-03 21:30:00 #> 14 205   wake  2023-09-04 07:25:00  #import in the long format (Comments on sleep) import_Statechanges(file.sleep, path,                    Datetime.format = \"dmyHM\",                    State.colnames = \"comments\",                    Datetime.column = sleep,                    Id.colname = record_id,                    sep = \";\",                    dec = \",\", structure = \"long\") #>  #> Successfully read in 7 observations across 1 Ids from 1 Statechanges-file(s). #> Timezone set is UTC. #>  #> First Observation: 2023-08-28 23:20:00 #> Last Observation: 2023-09-03 21:30:00 #> Timespan: 5.9 days #>  #> Observation intervals:  #>   Id    interval.time             n pct   #> 1 205   81300s (~22.58 hours)     1 17%   #> 2 205   84900s (~23.58 hours)     1 17%   #> 3 205   85500s (~23.75 hours)     1 17%   #> 4 205   86100s (~23.92 hours)     1 17%   #> 5 205   86400s (~1 days)          1 17%   #> 6 205   87600s (~1.01 days)       1 17%   #> # A tibble: 7 × 3 #> # Groups:   Id [1] #>   Id    State                                                Datetime            #>   <fct> <chr>                                                <dttm>              #> 1 205   Slept longer than usual since my kids are on Summer… 2023-08-28 23:20:00 #> 2 205   no                                                   2023-08-29 23:40:00 #> 3 205   Kids slept in my bed                                 2023-08-30 23:15:00 #> 4 205   none                                                 2023-08-31 23:15:00 #> 5 205   woke Up and could Not Fall asleep. went to the dini… 2023-09-01 23:10:00 #> 6 205   none                                                 2023-09-02 22:55:00 #> 7 205   no                                                   2023-09-03 21:30:00"},{"path":"https://tscnlab.github.io/LightLogR/reference/import_adjustment.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjust device imports or make your own — import_adjustment","title":"Adjust device imports or make your own — import_adjustment","text":"Adjust device imports make ","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_adjustment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adjust device imports or make your own — import_adjustment","text":"","code":"import_adjustment(import_expr)"},{"path":"https://tscnlab.github.io/LightLogR/reference/import_adjustment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjust device imports or make your own — import_adjustment","text":"import_expr named list import expressions. basis LightLogR's import functions included dataset ll_import_expr(). function given exact dataset, bound variable called import, identical import function. See details.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_adjustment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjust device imports or make your own — import_adjustment","text":"list import functions","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_adjustment.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Adjust device imports or make your own — import_adjustment","text":"function used knowledge expressions work R. minimal required output expression work expected, must lead data frame containing Datetime column correct time zone. access arguments defined description import_Dataset(). ... argument passed whatever csv reader function used, works expected. Look ll_import_expr()$ActLumus quite minimal example.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/import_adjustment.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adjust device imports or make your own — import_adjustment","text":"","code":"#create a new import function for the ActLumus device, same as the old new_import <- import_adjustment(ll_import_expr()) #the new one is identical to the old one in terms of the function body identical(body(import$ActLumus), body(new_import$ActLumus)) #> [1] TRUE  #change the import expression for the LYS device to add a message at the top new_import_expr <- ll_import_expr() new_import_expr$ActLumus[[4]] <- rlang::expr({ cat(\"**This is a new import function**\\n\") data }) new_import <- import_adjustment(new_import_expr) filepath <-  system.file(\"extdata/205_actlumus_Log_1020_20230904101707532.txt.zip\",              package = \"LightLogR\") #Now, a message is printed when the import function is called data <- new_import$ActLumus(filepath, auto.plot = FALSE) #> **This is a new import function** #>  #> Successfully read in 61'016 observations across 1 Ids from 1 ActLumus-file(s). #> Timezone set is UTC. #>  #> First Observation: 2023-08-28 08:47:54 #> Last Observation: 2023-09-04 10:17:04 #> Timespan: 7.1 days #>  #> Observation intervals:  #>   Id                                          interval.time     n pct   #> 1 205_actlumus_Log_1020_20230904101707532.txt 10s           61015 100%"},{"path":"https://tscnlab.github.io/LightLogR/reference/interdaily_stability.html","id":null,"dir":"Reference","previous_headings":"","what":"Interdaily stability (IS) — interdaily_stability","title":"Interdaily stability (IS) — interdaily_stability","text":"function calculates variability 24h light exposure patterns across multiple days. Calculated ratio variance average daily pattern total variance across days. Calculated mean hourly light levels. Ranges 0 (Gaussian noise) 1 (Perfect Stability).","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/interdaily_stability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interdaily stability (IS) — interdaily_stability","text":"","code":"interdaily_stability(   Light.vector,   Datetime.vector,   use.samplevar = FALSE,   na.rm = FALSE,   as.df = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/interdaily_stability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interdaily stability (IS) — interdaily_stability","text":"Light.vector Numeric vector containing light data. Datetime.vector Vector containing time data. Must POSIXct. use.samplevar Logical. sample variance used (divide N-1)? default (FALSE), population variance (divide N) used, described Van Someren et al. (1999). na.rm Logical. missing values removed? Defaults FALSE. .df Logical. output returned data frame? TRUE, data frame single column named interdaily_stability returned. Defaults FALSE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/interdaily_stability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interdaily stability (IS) — interdaily_stability","text":"Numeric value dataframe column ''.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/interdaily_stability.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Interdaily stability (IS) — interdaily_stability","text":"Note metric always 1 data contains one 24 h day.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/interdaily_stability.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Interdaily stability (IS) — interdaily_stability","text":"Van Someren, E. J. W., Swaab, D. F., Colenda, C. C., Cohen, W., McCall, W. V., & Rosenquist, P. B. (1999). Bright Light Therapy: Improved Sensitivity Effects Rest-Activity Rhythms Alzheimer Patients Application Nonparametric Methods. Chronobiology International, 16(4), 505–518. doi:10.3109/07420529908998724 Hartmeyer, S.L., Andersen, M. (2023). Towards framework light-dosimetry studies: Quantification metrics. Lighting Research & Technology. doi:10.1177/14771535231170500","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/interdaily_stability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interdaily stability (IS) — interdaily_stability","text":"","code":"set.seed(1) N <- 24 * 7 # Calculate metric for seven 24 h days with two measurements per hour dataset1 <-   tibble::tibble(     Id = rep(\"A\", N * 2),     Datetime = lubridate::as_datetime(0) + c(lubridate::minutes(seq(0, N * 60 - 30, 30))),     MEDI = sample(1:1000, N * 2)   ) dataset1 %>%   dplyr::summarise(     \"Interdaily stability\" = interdaily_stability(MEDI, Datetime)   ) #> # A tibble: 1 × 1 #>   `Interdaily stability` #>                    <dbl> #> 1                  0.147"},{"path":"https://tscnlab.github.io/LightLogR/reference/interval2state.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds a state column to a dataset from interval data — interval2state","title":"Adds a state column to a dataset from interval data — interval2state","text":"function can make use Interval data contain States (like \"sleep\", \"wake\", \"wear\") add column light logger dataset, State  every Datetime specified, based participant's Id.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/interval2state.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds a state column to a dataset from interval data — interval2state","text":"","code":"interval2state(   dataset,   State.interval.dataset,   Datetime.colname = Datetime,   State.colname = State,   Interval.colname = Interval,   Id.colname.dataset = Id,   Id.colname.interval = Id,   overwrite = FALSE,   output.dataset = TRUE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/interval2state.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds a state column to a dataset from interval data — interval2state","text":"dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variable Datetime.colname. State.interval.dataset Name dataset contains State Interval columns. Interval data can created, e.g., sc2interval(). Datetime.colname column name contains datetime. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. Needs part dataset. Must type POSIXct. State.colname, Interval.colname Column names State Interval State.interval.dataset. Expects symbol. State dataset yet function give error. can also set overwrite = TRUE. Id.colname.dataset, Id.colname.interval Column names participant's Id dataset State.interval.dataset. -chance inconsistencies, names can different. datasets imported preprocessed LightLogR, just works. datasets need Id, states added based Datetime, also depending dataset. overwrite TRUE (defaults FALSE), function overwrite State.colname column already exists. output.dataset output data.frame (Default TRUE) vector hms (FALSE) times? Expects logical scalar.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/interval2state.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adds a state column to a dataset from interval data — interval2state","text":"One data.frame object identical dataset state column added vector states","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/interval2state.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adds a state column to a dataset from interval data — interval2state","text":"","code":"#create a interval dataset library(tibble) library(dplyr) library(lubridate) library(rlang) library(purrr) #>  #> Attaching package: ‘purrr’ #> The following objects are masked from ‘package:rlang’: #>  #>     %@%, flatten, flatten_chr, flatten_dbl, flatten_int, flatten_lgl, #>     flatten_raw, invoke, splice states <- tibble::tibble(Datetime = c(\"2023-08-15 6:00:00\",                                       \"2023-08-15 23:00:00\",                                       \"2023-08-16 6:00:00\",                                       \"2023-08-16 22:00:00\",                                       \"2023-08-17 6:30:00\",                                       \"2023-08-18 1:00:00\",                                       \"2023-08-18 6:00:00\",                                       \"2023-08-18 22:00:00\",                                       \"2023-08-19 6:00:00\",                                       \"2023-08-19 23:00:00\",                                       \"2023-08-20 6:00:00\",                                       \"2023-08-20 22:00:00\"),                          State = rep(c(\"wake\", \"sleep\"), 6),                          Wear = rep(c(\"wear\", \"no wear\"), 6),                          Performance = rep(c(100, 0), 6),                          Id = \"Participant\") intervals <- sc2interval(states)  #create a dataset with states dataset_with_states <- sample.data.environment %>% interval2state(State.interval.dataset = intervals) #> Warning: The time zone of the dataset and the State.interval.dataset are not the same. This might lead to unexpected results or time shifts.  #visualize the states - note that the states are only added to the respective ID in the dataset library(ggplot2) ggplot(dataset_with_states, aes(x = Datetime, y = MEDI, color = State)) +  geom_point() +  facet_wrap(~Id, ncol = 1)   #import multiple State columns from the interval dataset #interval2state will only add a single State column to the dataset,  #which represents sleep/wake in our case dataset_with_states[8278:8283,] #> # A tibble: 6 × 4 #> # Groups:   Id [1] #>   Id          Datetime             MEDI State #>   <chr>       <dttm>              <dbl> <chr> #> 1 Participant 2023-08-29 22:59:34  17.7 sleep #> 2 Participant 2023-08-29 22:59:44  18.1 sleep #> 3 Participant 2023-08-29 22:59:54  17.9 sleep #> 4 Participant 2023-08-29 23:00:04  17.2 sleep #> 5 Participant 2023-08-29 23:00:14  16.9 sleep #> 6 Participant 2023-08-29 23:00:24  13.7 sleep  #if we want to add multiple columns we can either perfom the function  #multiple times with different states: dataset_with_states2 <-  dataset_with_states %>% interval2state(State.interval.dataset = intervals, State.colname = Wear) #> Warning: The time zone of the dataset and the State.interval.dataset are not the same. This might lead to unexpected results or time shifts. dataset_with_states2[8278:8283,] #> # A tibble: 6 × 5 #> # Groups:   Id [1] #>   Id          Datetime             MEDI State Wear    #>   <chr>       <dttm>              <dbl> <chr> <chr>   #> 1 Participant 2023-08-29 22:59:34  17.7 sleep no wear #> 2 Participant 2023-08-29 22:59:44  18.1 sleep no wear #> 3 Participant 2023-08-29 22:59:54  17.9 sleep no wear #> 4 Participant 2023-08-29 23:00:04  17.2 sleep no wear #> 5 Participant 2023-08-29 23:00:14  16.9 sleep no wear #> 6 Participant 2023-08-29 23:00:24  13.7 sleep no wear  #or we can use `purrr::reduce` to add multiple columns at once dataset_with_states3 <- syms(c(\"State\", \"Wear\", \"Performance\")) %>%  reduce(\\(x,y) interval2state(x, State.interval.dataset = intervals, State.colname = !!y),  .init = sample.data.environment) #> Warning: The time zone of the dataset and the State.interval.dataset are not the same. This might lead to unexpected results or time shifts. #> Warning: The time zone of the dataset and the State.interval.dataset are not the same. This might lead to unexpected results or time shifts. #> Warning: The time zone of the dataset and the State.interval.dataset are not the same. This might lead to unexpected results or time shifts.  #Note:  # - the State.colnames have to be provided as symbols (`rlang::syms`) # - the reduce function requires a two argument function `\\(x,y)`, where `x`  #   is the dataset to be continiously modified and `y` is the symbol of the #   State column name to be added # - the `!!` operator from `rlang` is used to exchange `y` with each symbol # - the `.init` argument is the initial dataset to be modified  #this results in all states being applied dataset_with_states3[8278:8283,] #> # A tibble: 6 × 6 #> # Groups:   Id [1] #>   Id          Datetime             MEDI State Wear    Performance #>   <chr>       <dttm>              <dbl> <chr> <chr>         <dbl> #> 1 Participant 2023-08-29 22:59:34  17.7 sleep no wear           0 #> 2 Participant 2023-08-29 22:59:44  18.1 sleep no wear           0 #> 3 Participant 2023-08-29 22:59:54  17.9 sleep no wear           0 #> 4 Participant 2023-08-29 23:00:04  17.2 sleep no wear           0 #> 5 Participant 2023-08-29 23:00:14  16.9 sleep no wear           0 #> 6 Participant 2023-08-29 23:00:24  13.7 sleep no wear           0"},{"path":"https://tscnlab.github.io/LightLogR/reference/intradaily_variability.html","id":null,"dir":"Reference","previous_headings":"","what":"Intradaily variability (IV) — intradaily_variability","title":"Intradaily variability (IV) — intradaily_variability","text":"function calculates variability consecutive Light levels within 24h day. Calculated ratio variance differences consecutive Light levels total variance across day. Calculated mean hourly Light levels. Higher values indicate fragmentation.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/intradaily_variability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Intradaily variability (IV) — intradaily_variability","text":"","code":"intradaily_variability(   Light.vector,   Datetime.vector,   use.samplevar = FALSE,   na.rm = FALSE,   as.df = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/intradaily_variability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Intradaily variability (IV) — intradaily_variability","text":"Light.vector Numeric vector containing light data. Datetime.vector Vector containing time data. Must POSIXct. use.samplevar Logical. sample variance used (divide N-1)? default (FALSE), population variance (divide N) used, described Van Someren et al. (1999). na.rm Logical. missing values removed? Defaults FALSE. .df Logical. output returned data frame? TRUE, data frame single column named intradaily_variability returned. Defaults FALSE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/intradaily_variability.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Intradaily variability (IV) — intradaily_variability","text":"Numeric value dataframe column 'IV'.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/intradaily_variability.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Intradaily variability (IV) — intradaily_variability","text":"Van Someren, E. J. W., Swaab, D. F., Colenda, C. C., Cohen, W., McCall, W. V., & Rosenquist, P. B. (1999). Bright Light Therapy: Improved Sensitivity Effects Rest-Activity Rhythms Alzheimer Patients Application Nonparametric Methods. Chronobiology International, 16(4), 505–518. doi:10.3109/07420529908998724 Hartmeyer, S.L., Andersen, M. (2023). Towards framework light-dosimetry studies: Quantification metrics. Lighting Research & Technology. doi:10.1177/14771535231170500","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/intradaily_variability.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Intradaily variability (IV) — intradaily_variability","text":"","code":"set.seed(1) N <- 24 * 2 # Calculate metric for two 24 h days with two measurements per hour dataset1 <-   tibble::tibble(     Id = rep(\"A\", N * 2),     Datetime = lubridate::as_datetime(0) + c(lubridate::minutes(seq(0, N * 60 - 30, 30))),     MEDI = sample(1:1000, N * 2)   ) dataset1 %>%   dplyr::summarise(     \"Intradaily variability\" = intradaily_variability(MEDI, Datetime)   ) #> # A tibble: 1 × 1 #>   `Intradaily variability` #>                      <dbl> #> 1                     1.75"},{"path":"https://tscnlab.github.io/LightLogR/reference/join_datasets.html","id":null,"dir":"Reference","previous_headings":"","what":"Join similar Datasets — join_datasets","title":"Join similar Datasets — join_datasets","text":"Join Light logging datasets common structure. least commonality identical columns Datetime Id across sets.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/join_datasets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Join similar Datasets — join_datasets","text":"","code":"join_datasets(   ...,   Datetime.column = Datetime,   Id.column = Id,   add.origin = FALSE,   debug = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/join_datasets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Join similar Datasets — join_datasets","text":"... Object names datasets need joined. Datetime.column, Id.column Column names Datetime id columns. defaults (Datetime, Id) already set data imported LightLogR. add.origin column named dataset joined data indicate dataset observation originated? Defaults FALSE Id column suffice. Expects logical. debug Output changes tibble indicating dataset missing respective Datetime Id column. Expects logical defaults FALSE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/join_datasets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Join similar Datasets — join_datasets","text":"One data.frame joined datasets tibble datasets missing columns. debug = TRUE","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/join_datasets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Join similar Datasets — join_datasets","text":"","code":"#load in two datasets path <- system.file(\"extdata\",  package = \"LightLogR\") file.LL <- \"205_actlumus_Log_1020_20230904101707532.txt.zip\" file.env <- \"cyepiamb_CW35_Log_1431_20230904081953614.txt.zip\" dataset.LL <- import$ActLumus(file.LL, path = path, auto.id = \"^(\\\\d{3})\") #>  #> Successfully read in 61'016 observations across 1 Ids from 1 ActLumus-file(s). #> Timezone set is UTC. #>  #> First Observation: 2023-08-28 08:47:54 #> Last Observation: 2023-09-04 10:17:04 #> Timespan: 7.1 days #>  #> Observation intervals:  #>   Id    interval.time     n pct   #> 1 205   10s           61015 100%   dataset.env <- import$ActLumus(file.env, path = path, manual.id = \"CW35\") #>  #> Successfully read in 20'143 observations across 1 Ids from 1 ActLumus-file(s). #> Timezone set is UTC. #>  #> First Observation: 2023-08-28 08:28:39 #> Last Observation: 2023-09-04 08:19:38 #> Timespan: 7 days #>  #> Observation intervals:  #>   Id    interval.time     n pct   #> 1 CW35  29s               1 0%    #> 2 CW35  30s           20141 100%    #join the datasets joined <- join_datasets(dataset.LL, dataset.env)  #compare the number of rows nrow(dataset.LL) + nrow(dataset.env) == nrow(joined) #> [1] TRUE  #debug, when set to TRUE, will output a tibble of datasets with missing necessary columns dataset.LL <- dataset.LL %>% dplyr::select(-Datetime) join_datasets(dataset.LL, dataset.env, debug = TRUE) #> # A tibble: 2 × 2 #>   column.names.in dataset.LL #>   <chr>           <lgl>      #> 1 Datetime        FALSE      #> 2 Id              TRUE"},{"path":"https://tscnlab.github.io/LightLogR/reference/ll_import_expr.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the import expression for a device — ll_import_expr","title":"Get the import expression for a device — ll_import_expr","text":"Returns import expression device LightLogR.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/ll_import_expr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the import expression for a device — ll_import_expr","text":"","code":"ll_import_expr()"},{"path":"https://tscnlab.github.io/LightLogR/reference/ll_import_expr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the import expression for a device — ll_import_expr","text":"list import expressions supported devices","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/ll_import_expr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the import expression for a device — ll_import_expr","text":"expressions used import prepare data specific devices. list made explicit, user, requiring slight changes import functions, (e.g., timestamp formatted differently) can modify add list. list can turned fully functional import function import_adjustment().","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/ll_import_expr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the import expression for a device — ll_import_expr","text":"","code":"ll_import_expr()[1] #> $ActLumus #> { #>     data <- suppressMessages(readr::read_delim(filename, skip = 32,  #>         delim = \";\", n_max = n_max, col_types = paste0(\"c\", paste0(rep(\"d\",  #>             32), collapse = \"\")), id = \"file.name\", locale = locale,  #>         name_repair = \"universal\", ...)) #>     data <- data %>% dplyr::rename(Datetime = DATE.TIME, MEDI = MELANOPIC.EDI) %>%  #>         dplyr::mutate(Datetime = Datetime %>% lubridate::dmy_hms(tz = tz)) #> } #>"},{"path":"https://tscnlab.github.io/LightLogR/reference/log_zero_inflated.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a defined number to a numeric and log transform it — log_zero_inflated","title":"Add a defined number to a numeric and log transform it — log_zero_inflated","text":"Frequently, light exposure data need log-transformed. light exposure data frequently also contain many zero-values, adding small value avoids losing observations. Must applied care reported. exp_zero_inflated() reverse function log_zero_inflated().","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/log_zero_inflated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a defined number to a numeric and log transform it — log_zero_inflated","text":"","code":"log_zero_inflated(x, offset = 0.1, base = 10)  exp_zero_inflated(x, offset = 0.1, base = 10)"},{"path":"https://tscnlab.github.io/LightLogR/reference/log_zero_inflated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a defined number to a numeric and log transform it — log_zero_inflated","text":"x numeric vector offset amount add x, default 0.1 base logarithmic base, default 10","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/log_zero_inflated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a defined number to a numeric and log transform it — log_zero_inflated","text":"transformed numeric vector","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/log_zero_inflated.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Add a defined number to a numeric and log transform it — log_zero_inflated","text":"Johannes Zauner, Carolina Guidolin, Manuel Spitschan (2025) deal darkness: Modelling visualization zero-inflated personal light exposure data logarithmic scale. bioRxiv. doi: https://doi.org/10.1101/2024.12.30.630669","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/log_zero_inflated.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a defined number to a numeric and log transform it — log_zero_inflated","text":"","code":"c(0, 1, 10, 100, 1000, 10000) |> log_zero_inflated() #> [1] -1.00000000  0.04139269  1.00432137  2.00043408  3.00004343  4.00000434  #For use in a function sample.data.environment |>    dplyr::filter(Id == \"Participant\") |>    dplyr::group_by(Date = lubridate::wday(Datetime, label = TRUE, week_start = 1)) |>    dplyr::summarize(   TAT250 = duration_above_threshold(log_zero_inflated(MEDI),                                      Datetime,                                      threshold = log_zero_inflated(250)                                     )                    ) #> # A tibble: 6 × 2 #>   Date  TAT250               #>   <ord> <Duration>           #> 1 Tue   5810s (~1.61 hours)  #> 2 Wed   9960s (~2.77 hours)  #> 3 Thu   16080s (~4.47 hours) #> 4 Fri   14130s (~3.92 hours) #> 5 Sat   26930s (~7.48 hours) #> 6 Sun   25610s (~7.11 hours)                      #Calling exp_zero_inflated on data transformed with log_zero_inflated yields to the original result c(0, 1, 10, 100, 1000, 10000) |> log_zero_inflated() |> exp_zero_inflated() #> [1]     0     1    10   100  1000 10000"},{"path":"https://tscnlab.github.io/LightLogR/reference/mean_daily.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate mean daily metrics from daily summary — mean_daily","title":"Calculate mean daily metrics from daily summary — mean_daily","text":"mean_daily calculates three-row summary metrics showing average weekday, weekend, mean daily values non-grouping numeric columns. basis dataframe contains metrics per weekday, per date (calculate..Date = Datetime). function requires column specifying day week factor (Monday weekstart), can calculate date column provided.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/mean_daily.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate mean daily metrics from daily summary — mean_daily","text":"","code":"mean_daily(   data,   Weekend.type = Date,   na.rm = TRUE,   calculate.from.Date = NULL,   prefix = \"average_\",   filter.empty = FALSE,   sub.zero = FALSE,   Datetime2Time = TRUE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/mean_daily.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate mean daily metrics from daily summary — mean_daily","text":"data dataframe containing metrics summarize Weekend.type column dataframe specifies day week factor, weekstart Monday (weekends 6 7 numeric representation). date, converted factor na.rm Logical, whether remove NA values calculating means. Default TRUE. calculate..Date Optional. column dataframe containing dates calculate Weekend.type. provided, Weekend.type generated column. prefix String prefix summarized values filter.empty Filter empty rows. Default FALSE sub.zero Logical. missing values replaced zero? Defaults FALSE. throw error, happens type double. Datetime2Time Logical whether POSIXct columns transformed hms(time) columns, usually sensible averaging (default TRUE). Calls Datetime2Time() default settings (POSIXct affected).","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/mean_daily.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate mean daily metrics from daily summary — mean_daily","text":"dataframe three rows representing average weekday, weekend, mean daily values numeric columns","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/mean_daily.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate mean daily metrics from daily summary — mean_daily","text":"Summary values type POSIXct calculated mean, can nonsensical times (e.g., mean Day1 18:00 Day2 18:00, Day2 6:00, can desired result, focus time, rather datetime, recommended values converted times via hms::as_hms() applying function (mean 18:00 18:00 still 18:00, 6:00).","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/mean_daily.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate mean daily metrics from daily summary — mean_daily","text":"","code":"# Create sample data sample_data <- data.frame(   Date = factor(c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"),                levels = c(\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\")),   lux = c(250, 300, 275, 280, 290, 350, 320),   duration = lubridate::as.duration(c(120, 130, 125, 135, 140, 180, 160)) )  # Calculate mean daily metrics mean_daily(sample_data) #> # A tibble: 3 × 3 #>   Date       average_lux average_duration     #>   <chr>            <dbl> <Duration>           #> 1 Mean daily         295 141s (~2.35 minutes) #> 2 Weekday            279 130s (~2.17 minutes) #> 3 Weekend            335 170s (~2.83 minutes)  # With a Date column sample_data_with_date <- data.frame(   Date = seq(as.Date(\"2023-05-01\"), as.Date(\"2023-05-07\"), by = \"day\"),   lux = c(250, 300, 275, 280, 290, 350, 320),   duration = lubridate::as.duration(c(120, 130, 125, 135, 140, 180, 160)) )  mean_daily(sample_data_with_date) #> # A tibble: 3 × 3 #>   Date       average_lux average_duration     #>   <chr>            <dbl> <Duration>           #> 1 Mean daily         295 141s (~2.35 minutes) #> 2 Weekday            279 130s (~2.17 minutes) #> 3 Weekend            335 170s (~2.83 minutes)"},{"path":"https://tscnlab.github.io/LightLogR/reference/mean_daily_metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate mean daily metrics from Time Series — mean_daily_metric","title":"Calculate mean daily metrics from Time Series — mean_daily_metric","text":"mean_daily_metric convenience wrapper around mean_daily summarizes data imported LightLogR per weekday calculates mean daily values specific metric. Examples include duration_above_threshold() (default), durations().","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/mean_daily_metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate mean daily metrics from Time Series — mean_daily_metric","text":"","code":"mean_daily_metric(   data,   Variable,   Weekend.type = Date,   Datetime.colname = Datetime,   metric_type = duration_above_threshold,   prefix = \"average_\",   filter.empty = FALSE,   Datetime2Time = TRUE,   ... )"},{"path":"https://tscnlab.github.io/LightLogR/reference/mean_daily_metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate mean daily metrics from Time Series — mean_daily_metric","text":"data dataframe containing light logger data imported LightLogR Variable variable column analyze. Expects symbol. Needs part dataset. Weekend.type (new) column dataframe specifies day week factor Datetime.colname Column name containing datetime values. Defaults Datetime metric_type metric function apply, default duration_above_threshold() prefix String prefix summarized values filter.empty Filter empty rows. Default FALSE Datetime2Time Logical whether POSIXct columns transformed hms(time) columns, usually sensible averaging (default TRUE). Calls Datetime2Time() default settings (POSIXct affected). ... Additional arguments passed metric function","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/mean_daily_metric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate mean daily metrics from Time Series — mean_daily_metric","text":"dataframe three rows representing average weekday, weekend, mean daily values specified metric","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/mean_daily_metric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate mean daily metrics from Time Series — mean_daily_metric","text":"","code":"# Calculate mean daily duration above threshold. As the data only contains # data for two days, Weekend and Mean daily will throw NA sample.data.irregular |>  aggregate_Datetime(unit = \"1 min\") |>  mean_daily_metric(   Variable = lux,   threshold = 100 ) #> # A tibble: 3 × 3 #> # Groups:   Id [1] #>   Id    Date       average_duration_above_100 #>   <chr> <chr>      <Duration>                 #> 1 P1    Mean daily NA                         #> 2 P1    Weekday    17220s (~4.78 hours)       #> 3 P1    Weekend    NA                          # again with another dataset sample.data.environment |>    mean_daily_metric(   Variable = MEDI,   threshold = 250) #> # A tibble: 6 × 3 #> # Groups:   Id [2] #>   Id          Date       average_duration_above_250 #>   <fct>       <chr>      <Duration>                 #> 1 Environment Mean daily 48710s (~13.53 hours)      #> 2 Environment Weekday    48712s (~13.53 hours)      #> 3 Environment Weekend    48705s (~13.53 hours)      #> 4 Participant Mean daily 15716s (~4.37 hours)       #> 5 Participant Weekday    11495s (~3.19 hours)       #> 6 Participant Weekend    26270s (~7.3 hours)         # by default, datetime columns are converted to time sample.data.environment |>    mean_daily_metric(   Variable = MEDI,   metric_type = timing_above_threshold,   threshold = 250) #> # A tibble: 6 × 5 #> # Groups:   Id [2] #>   Id          Date       average_mean_timing_above_250 average_first_timing_ab…¹ #>   <fct>       <chr>      <time>                        <time>                    #> 1 Environment Mean daily 13:24:00                      06:38:19                  #> 2 Environment Weekday    13:24:12                      06:38:30                  #> 3 Environment Weekend    13:23:30                      06:37:53                  #> 4 Participant Mean daily 15:15:33                      09:58:06                  #> 5 Participant Weekday    15:11:08                      09:58:09                  #> 6 Participant Weekend    15:26:37                      09:57:59                  #> # ℹ abbreviated name: ¹​average_first_timing_above_250 #> # ℹ 1 more variable: average_last_timing_above_250 <time>"},{"path":"https://tscnlab.github.io/LightLogR/reference/midpointCE.html","id":null,"dir":"Reference","previous_headings":"","what":"Midpoint of cumulative light exposure. — midpointCE","title":"Midpoint of cumulative light exposure. — midpointCE","text":"function calculates timing corresponding half cumulative light exposure within given time series.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/midpointCE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Midpoint of cumulative light exposure. — midpointCE","text":"","code":"midpointCE(Light.vector, Time.vector, na.rm = FALSE, as.df = FALSE)"},{"path":"https://tscnlab.github.io/LightLogR/reference/midpointCE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Midpoint of cumulative light exposure. — midpointCE","text":"Light.vector Numeric vector containing light data. Time.vector Vector containing time data. Can POSIXct, hms, duration, difftime. na.rm Logical. missing values removed calculation? TRUE, missing values replaced zero. Defaults FALSE. .df Logical. output returned data frame? TRUE, data frame single column named midpointCE returned. Defaults FALSE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/midpointCE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Midpoint of cumulative light exposure. — midpointCE","text":"Single column data frame vector.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/midpointCE.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Midpoint of cumulative light exposure. — midpointCE","text":"Shochat, T., Santhi, N., Herer, P., Flavell, S. ., Skeldon, . C., & Dijk, D.-J. (2019). Sleep Timing Late Autumn Late Spring Associates Light Exposure Rather Sun Time College Students. Frontiers Neuroscience, 13. doi:10.3389/fnins.2019.00882 Hartmeyer, S.L., Andersen, M. (2023). Towards framework light-dosimetry studies: Quantification metrics. Lighting Research & Technology. doi:10.1177/14771535231170500","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/midpointCE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Midpoint of cumulative light exposure. — midpointCE","text":"","code":"dataset1 <-   tibble::tibble(     Id = rep(\"A\", 24),     Datetime = lubridate::as_datetime(0) + lubridate::hours(0:23),     MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))   ) dataset1 %>%   dplyr::reframe(     \"Midpoint of cmulative exposure\" = midpointCE(MEDI, Datetime)   ) #> # A tibble: 1 × 1 #>   `Midpoint of cmulative exposure` #>   <dttm>                           #> 1 1970-01-01 11:00:00               # Dataset with HMS time vector dataset2 <-   tibble::tibble(     Id = rep(\"A\", 24),     Time = hms::as_hms(lubridate::as_datetime(0) + lubridate::hours(0:23)),     MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))   ) dataset2 %>%   dplyr::reframe(     \"Midpoint of cmulative exposure\" = midpointCE(MEDI, Time)   ) #> # A tibble: 1 × 1 #>   `Midpoint of cmulative exposure` #>   <time>                           #> 1 11:00                             # Dataset with duration time vector dataset3 <-   tibble::tibble(     Id = rep(\"A\", 24),     Hour = lubridate::duration(0:23, \"hours\"),     MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))   ) dataset3 %>%   dplyr::reframe(     \"Midpoint of cmulative exposure\" = midpointCE(MEDI, Hour)   ) #> # A tibble: 1 × 1 #>   `Midpoint of cmulative exposure` #>   <Duration>                       #> 1 39600s (~11 hours)"},{"path":"https://tscnlab.github.io/LightLogR/reference/normalize_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize counts between sensor outputs — normalize_counts","title":"Normalize counts between sensor outputs — normalize_counts","text":"niche helper function normalize counts. sensors provide raw counts gain levels part output. cases desirable compare counts sensors, e.g., gauge daylight outside comparing UV counts photopic counts (high ratio UV/Pho indicates outside daylight). gauge daylight inside comparing IR counts photopic counts (high ratio IR/Pho low ratio UV/Pho indicates daylight context LED fluorescent lighting). user can provide gain ratiotable, use table provided sensor gain.ratio.table dataset LightLogR.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/normalize_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize counts between sensor outputs — normalize_counts","text":"","code":"normalize_counts(dataset, gain.columns, count.columns, gain.ratio.table)"},{"path":"https://tscnlab.github.io/LightLogR/reference/normalize_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize counts between sensor outputs — normalize_counts","text":"dataset data.table containing gain count columns. gain.columns character vector columns dataset containing gain setting. Columns must repeat. count.columns character vector columns dataset containing raw count data. Must length gain.columns, order must conform order gain.columns. gain.ratio.table two-column tibble containing gain gain.ratio information. Can provided user use gain.ratio.table dataset.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/normalize_counts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize counts between sensor outputs — normalize_counts","text":"extended dataset new columns containing normalized counts","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/normalize_counts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalize counts between sensor outputs — normalize_counts","text":"","code":"example.table <- tibble::tibble( uvGain = c(4096, 1024, 2), visGain = c(4096, 4096, 4096), irGain = c(2,2,2), uvValue = c(692, 709, 658), visValue = c(128369, 129657, 128609), irValue = c(122193, 127113, 124837))  gain.columns = c(\"uvGain\", \"visGain\", \"irGain\") count.columns = c(\"uvValue\", \"visValue\", \"irValue\")  example.table |> normalize_counts(gain.columns, count.columns, gain.ratio.tables$TSL2585) #> # A tibble: 3 × 9 #>   uvGain visGain irGain uvValue visValue irValue uvValue.normalized #>    <dbl>   <dbl>  <dbl>   <dbl>    <dbl>   <dbl>              <dbl> #> 1   4096    4096      2     692   128369  122193               27.3 #> 2   1024    4096      2     709   129657  127113               95.6 #> 3      2    4096      2     658   128609  124837            41433.  #> # ℹ 2 more variables: visValue.normalized <dbl>, irValue.normalized <dbl>"},{"path":"https://tscnlab.github.io/LightLogR/reference/number_states.html","id":null,"dir":"Reference","previous_headings":"","what":"Number non-consecutive state occurrences — number_states","title":"Number non-consecutive state occurrences — number_states","text":"number_states() creates new column dataset takes state column assigns count value state, rising every time state replaced another state. E.g., column states \"day\" \"night\" produce column indicating whether \"day 1\", \"day 2\", forth, \"night\" state \"night 1\", \"night 2\", etc. Grouping within input dataset respected, .e., count reset group.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/number_states.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number non-consecutive state occurrences — number_states","text":"","code":"number_states(   dataset,   state.colname,   colname.extension = \".count\",   use.original.state = TRUE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/number_states.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number non-consecutive state occurrences — number_states","text":"dataset data.frame state column. state.colname Column name contains state. Expects symbol. Needs part dataset. Can type, character factor make sense. colname.extension extension added state name create new column. Defaults \".count\". use.original.state Logical, whether original state part output column.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/number_states.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Number non-consecutive state occurrences — number_states","text":"input dataset additional column counts occurrences state. new column type character use.original.state = TRUE integer otherwise.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/number_states.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Number non-consecutive state occurrences — number_states","text":"state column limited two states, can many states needed. Also, matter time frames states change, necessarily conform 24-hour day. NA values treated state. Gaps data can lead non-sensible outcomes, e.g. -state/observation day state \"18:00:00\" day state \"6:00:00\" - counted day 1 still. cases, gap_handler() function can useful priori add observations.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/number_states.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Number non-consecutive state occurrences — number_states","text":"","code":"dataset <- tibble::tibble(  state =  c(\"day\", \"day\", \"day\", \"night\", \"night\", \"day\", \"day\", \"night\",  \"night\", \"night\", \"day\", \"night\")  ) number_states(dataset, state) #> # A tibble: 12 × 2 #>    state state.count #>    <chr> <chr>       #>  1 day   day 1       #>  2 day   day 1       #>  3 day   day 1       #>  4 night night 1     #>  5 night night 1     #>  6 day   day 2       #>  7 day   day 2       #>  8 night night 2     #>  9 night night 2     #> 10 night night 2     #> 11 day   day 3       #> 12 night night 3     number_states(dataset, state, use.original.state = FALSE) #> # A tibble: 12 × 2 #>    state state.count #>    <chr>       <int> #>  1 day             1 #>  2 day             1 #>  3 day             1 #>  4 night           1 #>  5 night           1 #>  6 day             2 #>  7 day             2 #>  8 night           2 #>  9 night           2 #> 10 night           2 #> 11 day             3 #> 12 night           3  #example with photoperiods, calculating the mean values for each day and night coordinates <- c(48.52, 9.06) sample.data.environment |>   add_photoperiod(coordinates) |>   number_states(photoperiod.state) |>   dplyr::group_by(photoperiod.state.count, .add = TRUE) |>   dplyr::summarize(mean_MEDI = mean(MEDI)) |>   tail(13) #> `summarise()` has grouped output by 'Id'. You can override using the `.groups` #> argument. #> # A tibble: 13 × 3 #> # Groups:   Id [1] #>    Id          photoperiod.state.count mean_MEDI #>    <fct>       <chr>                       <dbl> #>  1 Participant day 1                     145.    #>  2 Participant day 2                     145.    #>  3 Participant day 3                     291.    #>  4 Participant day 4                    1232.    #>  5 Participant day 5                    2723.    #>  6 Participant day 6                    2851.    #>  7 Participant night 1                     0     #>  8 Participant night 2                     6.29  #>  9 Participant night 3                    13.5   #> 10 Participant night 4                    28.0   #> 11 Participant night 5                     5.89  #> 12 Participant night 6                     0.866 #> 13 Participant night 7                    12.1"},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRC.html","id":null,"dir":"Reference","previous_headings":"","what":"Non-visual circadian response — nvRC","title":"Non-visual circadian response — nvRC","text":"function calculates non-visual circadian response (nvRC). takes account assumed response dynamics non-visual system circadian rhythm processes light exposure signal quantify effective circadian-weighted input non-visual system (see Details).","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Non-visual circadian response — nvRC","text":"","code":"nvRC(   MEDI.vector,   Illuminance.vector,   Time.vector,   epoch = \"dominant.epoch\",   sleep.onset = NULL )"},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRC.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Non-visual circadian response — nvRC","text":"MEDI.vector Numeric vector containing melanopic EDI data. Illuminance.vector Numeric vector containing Illuminance data. Time.vector Vector containing time data. Can POSIXct, hms, duration, difftime. epoch epoch data sampled. Can either duration string. string, needs either \"dominant.epoch\" (default) guess based data, valid duration string, e.g., \"1 day\" \"10 sec\". sleep.onset time habitual sleep onset. Can HMS, numeric, NULL. NULL (default), data assumed start habitual sleep onset. Time.vector HMS POSIXct, sleep.onset must HMS. Likewise, Time.vector numeric, sleep.onset must numeric.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRC.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Non-visual circadian response — nvRC","text":"numeric vector containing nvRC data. output length Time.vector.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRC.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Non-visual circadian response — nvRC","text":"timeseries assumed regular. Missing values light data replaced 0.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRC.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Non-visual circadian response — nvRC","text":"Amundadottir, M.L. (2016). Light-driven model identifying indicators non-visual health potential built environment [Doctoral dissertation, EPFL]. EPFL infoscience. doi:10.5075/epfl-thesis-7146","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Non-visual circadian response — nvRC","text":"","code":"dataset1 <-   tibble::tibble(     Id = rep(\"B\", 60 * 48),     Datetime = lubridate::as_datetime(0) + lubridate::minutes(0:(60*48-1)),     Illuminance = c(rep(0, 60*8), rep(sample(1:1000, 16, replace = TRUE), each = 60),                     rep(0, 60*8), rep(sample(1:1000, 16, replace = TRUE), each = 60)),     MEDI = Illuminance * rep(sample(0.5:1.5, 48, replace = TRUE), each = 60)   ) # Time.vector as POSIXct dataset1.nvRC <- dataset1 %>%   dplyr::mutate(     nvRC = nvRC(MEDI, Illuminance, Datetime, sleep.onset = hms::as_hms(\"22:00:00\"))   )  # Time.vector as difftime dataset2 <- dataset1 %>%    dplyr::mutate(Datetime = Datetime - lubridate::as_datetime(lubridate::dhours(22))) dataset2.nvRC <- dataset2 %>%   dplyr::mutate(     nvRC = nvRC(MEDI, Illuminance, Datetime, sleep.onset = lubridate::dhours(0))   )"},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRC_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Performance metrics for circadian response — nvRC_metrics","title":"Performance metrics for circadian response — nvRC_metrics","text":"functions compare non-visual circadian response (see nvRC) measured personal light exposure nvRC reference light exposure pattern, daylight.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRC_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performance metrics for circadian response — nvRC_metrics","text":"","code":"nvRC_circadianDisturbance(nvRC, nvRC.ref, as.df = FALSE)  nvRC_circadianBias(nvRC, nvRC.ref, as.df = FALSE)  nvRC_relativeAmplitudeError(nvRC, nvRC.ref, as.df = FALSE)"},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRC_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performance metrics for circadian response — nvRC_metrics","text":"nvRC Time series non-visual circadian response (see nvRC. nvRC.ref Time series non-visual circadian response circadian response (see nvRC reference light exposure pattern (e.g., daylight). Must length nvRC. .df Logical. output returned data frame? Defaults TRUE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRC_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performance metrics for circadian response — nvRC_metrics","text":"numeric value single column data frame.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRC_metrics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Performance metrics for circadian response — nvRC_metrics","text":"nvRC_circadianDisturbance() calculates circadian disturbance (CD). expressed $$CD(,T)=\\frac{1}{T}\\int_{t_{}}^{t_{}+T}    {\\lvert r_{C}(t)-r_{C}^{ref}(t)\\rvert dt},$$ quantifies total difference measured circadian response circadian response reference profile. nvRC_circadianBias() calculates circadian bias (CB). expressed $$CB(,T)=\\frac{1}{T}\\int_{t_{}}^{t_{}+T}    {(r_{C}(t)-r_{C}^{ref}(t))dt},$$ provides measure overall trend difference circadian response, .e. positive values overestimating negative underestimating measured circadian response circadian response reference profile. nvRC_relativeAmplitudeError() calculates relative amplitude error (RAE). expressed $$RAE(,T)=r_{C,max}-r_{C,max}^{ref},$$ quantifies difference maximum response achieved period reference signal.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRC_metrics.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Performance metrics for circadian response — nvRC_metrics","text":"Amundadottir, M.L. (2016). Light-driven model identifying indicators non-visual health potential built environment [Doctoral dissertation, EPFL]. EPFL infoscience. doi:10.5075/epfl-thesis-7146","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRC_metrics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performance metrics for circadian response — nvRC_metrics","text":"","code":"dataset1 <-    tibble::tibble(     Id = rep(\"B\", 60 * 24),     Datetime = lubridate::as_datetime(0) + lubridate::minutes(0:(60*24-1)),     Illuminance = c(rep(0, 60*8), rep(sample(1:1000, 16, replace = TRUE), each = 60)),     MEDI = Illuminance * rep(sample(0.5:1.5, 24, replace = TRUE), each = 60),   ) %>%   dplyr::mutate(     nvRC = nvRC(MEDI, Illuminance, Datetime, sleep.onset = hms::as_hms(\"22:00:00\"))   )  dataset.reference <-   tibble::tibble(     Id = rep(\"Daylight\", 60 * 24),     Datetime = lubridate::as_datetime(0) + lubridate::minutes(0:(60*24-1)),     Illuminance = c(rep(0, 60*6), rep(10000, 12*60), rep(0, 60*6)),     MEDI = Illuminance   ) %>%   dplyr::mutate(     nvRC = nvRC(MEDI, Illuminance, Datetime, sleep.onset = hms::as_hms(\"22:00:00\"))   )  # Circadian disturbance nvRC_circadianDisturbance(dataset1$nvRC, dataset.reference$nvRC) #> [1] 0.2605862  # Circadian bias nvRC_circadianBias(dataset1$nvRC, dataset.reference$nvRC) #> [1] -0.04904808  # Relative amplitude error nvRC_relativeAmplitudeError(dataset1$nvRC, dataset.reference$nvRC) #> [1] 0.3263525"},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRD.html","id":null,"dir":"Reference","previous_headings":"","what":"Non-visual direct response — nvRD","title":"Non-visual direct response — nvRD","text":"function calculates non-visual direct response (nvRD). takes account assumed response dynamics non-visual system processes light exposure signal quantify effective direct input non-visual system (see Details).","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRD.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Non-visual direct response — nvRD","text":"","code":"nvRD(MEDI.vector, Illuminance.vector, Time.vector, epoch = \"dominant.epoch\")"},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRD.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Non-visual direct response — nvRD","text":"MEDI.vector Numeric vector containing melanopic EDI data. Illuminance.vector Numeric vector containing Illuminance data. Time.vector Vector containing time data. Can POSIXct(),hms::hms(), lubridate::duration(), difftime(). epoch epoch data sampled. Can either lubridate::duration() string. string, needs either \"dominant.epoch\" (default) guess based data, valid lubridate::duration() string, e.g., \"1 day\" \"10 sec\".","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRD.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Non-visual direct response — nvRD","text":"numeric vector containing nvRD data. output length Time.vector.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRD.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Non-visual direct response — nvRD","text":"timeseries assumed regular. Missing values light data replaced 0.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRD.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Non-visual direct response — nvRD","text":"Amundadottir, M.L. (2016). Light-driven model identifying indicators non-visual health potential built environment [Doctoral dissertation, EPFL]. EPFL infoscience. doi:10.5075/epfl-thesis-7146","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRD.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Non-visual direct response — nvRD","text":"","code":"# Dataset 1 with 24h measurement dataset1 <-   tibble::tibble(     Id = rep(\"A\", 60 * 24),     Datetime = lubridate::as_datetime(0) + lubridate::minutes(0:(60*24-1)),     Illuminance = c(rep(0, 60*8), rep(sample(1:1000, 16, replace = TRUE), each = 60)),     MEDI = Illuminance * rep(sample(0.5:1.5, 24, replace = TRUE), each = 60)   )  # Dataset 2 with 48h measurement dataset2 <-   tibble::tibble(     Id = rep(\"B\", 60 * 48),     Datetime = lubridate::as_datetime(0) + lubridate::minutes(0:(60*48-1)),     Illuminance = c(rep(0, 60*8), rep(sample(1:1000, 16, replace = TRUE), each = 60),                      rep(0, 60*8), rep(sample(1:1000, 16, replace = TRUE), each = 60)),     MEDI = Illuminance * rep(sample(0.5:1.5, 48, replace = TRUE), each = 60)   ) # Combined datasets dataset.combined <- rbind(dataset1, dataset2)  # Calculate nvRD per ID dataset.combined.nvRD <- dataset.combined %>%    dplyr::group_by(Id) %>%    dplyr::mutate(     nvRD = nvRD(MEDI, Illuminance, Datetime)   )"},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRD_cumulative_response.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative non-visual direct response — nvRD_cumulative_response","title":"Cumulative non-visual direct response — nvRD_cumulative_response","text":"function calculates cumulative non-visual direct response (nvRD). basically integral nvRD provided time period hours. unit resulting value thus \"nvRD*h\".","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRD_cumulative_response.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative non-visual direct response — nvRD_cumulative_response","text":"","code":"nvRD_cumulative_response(   nvRD,   Time.vector,   epoch = \"dominant.epoch\",   as.df = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRD_cumulative_response.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative non-visual direct response — nvRD_cumulative_response","text":"nvRD Numeric vector containing non-visual direct response. See nvRD. Time.vector Vector containing time data. Can POSIXct, hms, duration, difftime. epoch epoch data sampled. Can either duration string. string, needs either \"dominant.epoch\" (default) guess based data, valid duration string, e.g., \"1 day\" \"10 sec\". .df Logical. data frame returned? TRUE, data frame single column named nvRD_cumulative returned. Defaults FALSE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRD_cumulative_response.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative non-visual direct response — nvRD_cumulative_response","text":"numeric value single column data frame.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRD_cumulative_response.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cumulative non-visual direct response — nvRD_cumulative_response","text":"Amundadottir, M.L. (2016). Light-driven model identifying indicators non-visual health potential built environment [Doctoral dissertation, EPFL]. EPFL infoscience. doi:10.5075/epfl-thesis-7146","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/nvRD_cumulative_response.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative non-visual direct response — nvRD_cumulative_response","text":"","code":"dataset1 <-   tibble::tibble(     Id = rep(\"A\", 60 * 24),     Datetime = lubridate::as_datetime(0) + lubridate::minutes(0:(60*24-1)),     Illuminance = c(rep(0, 60*8), rep(sample(1:1000, 14, replace = TRUE), each = 60), rep(0, 60*2)),     MEDI = Illuminance * rep(sample(0.5:1.5, 24, replace = TRUE), each = 60)   ) %>%   dplyr::mutate(     nvRD = nvRD(MEDI, Illuminance, Datetime)   )  dataset1 %>%    dplyr::summarise(     \"cumulative nvRD\" = nvRD_cumulative_response(nvRD, Datetime)   ) #> # A tibble: 1 × 1 #>   `cumulative nvRD` #>               <dbl> #> 1              8.72"},{"path":"https://tscnlab.github.io/LightLogR/reference/period_above_threshold.html","id":null,"dir":"Reference","previous_headings":"","what":"Length of longest continuous period above/below threshold — period_above_threshold","title":"Length of longest continuous period above/below threshold — period_above_threshold","text":"function finds length longest continous period /specified threshold light level within specified range light levels.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/period_above_threshold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Length of longest continuous period above/below threshold — period_above_threshold","text":"","code":"period_above_threshold(   Light.vector,   Time.vector,   comparison = c(\"above\", \"below\"),   threshold,   epoch = \"dominant.epoch\",   loop = FALSE,   na.replace = FALSE,   na.rm = FALSE,   as.df = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/period_above_threshold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Length of longest continuous period above/below threshold — period_above_threshold","text":"Light.vector Numeric vector containing light data. Time.vector Vector containing time data. Can POSIXct, hms, duration, difftime. comparison String specifying whether period light levels threshold calculated. Can either \"\" (default) \"\". two values provided threshold, argument ignored. threshold Single numeric value two numeric values specifying threshold light level(s) compare . vector two values provided, period light levels within two thresholds calculated. epoch epoch data sampled. Can either duration string. string, needs either \"dominant.epoch\" (default) guess based data, valid duration string, e.g., \"1 day\" \"10 sec\". loop Logical. data looped? Defaults FALSE. na.replace Logical. missing values (NA) replaced calculation? TRUE missing values removed result FALSE comparing Light.vector threshold. Defaults FALSE. na.rm Logical. missing values (NA) removed calculation? TRUE, argument override na.replace. Defaults FALSE. .df Logical. data frame returned? TRUE, data frame single column named period_{comparison}_{threshold} returned. Defaults FALSE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/period_above_threshold.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Length of longest continuous period above/below threshold — period_above_threshold","text":"duration object (see duration) single value, single column data frame.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/period_above_threshold.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Length of longest continuous period above/below threshold — period_above_threshold","text":"","code":"N <- 60 # Dataset with continous period of >250lx for 35min dataset1 <-   tibble::tibble(     Id = rep(\"A\", N),     Datetime = lubridate::as_datetime(0) + lubridate::minutes(1:N),     MEDI = c(sample(1:249, N-35, replace = TRUE),               sample(250:1000, 35, replace = TRUE))   )  dataset1 %>%   dplyr::reframe(\"Period >250lx\" = period_above_threshold(MEDI, Datetime, threshold = 250)) #> # A tibble: 1 × 1 #>   `Period >250lx`     #>   <Duration>          #> 1 2100s (~35 minutes)  dataset1 %>%   dplyr::reframe(\"Period <250lx\" = period_above_threshold(MEDI, Datetime, \"below\", threshold = 250)) #> # A tibble: 1 × 1 #>   `Period <250lx`     #>   <Duration>          #> 1 1500s (~25 minutes)  # Dataset with continous period of 100-250lx for 20min dataset2 <-   tibble::tibble(     Id = rep(\"B\", N),     Datetime = lubridate::as_datetime(0) + lubridate::minutes(1:N),     MEDI = c(sample(c(1:99, 251-1000), N-20, replace = TRUE),               sample(100:250, 20, replace = TRUE)),   ) dataset2 %>%   dplyr::reframe(\"Period 250lx\" = period_above_threshold(MEDI, Datetime, threshold = c(100,250))) #> # A tibble: 1 × 1 #>   `Period 250lx`      #>   <Duration>          #> 1 1200s (~20 minutes)  # Return data frame dataset1 %>%   dplyr::reframe(period_above_threshold(MEDI, Datetime, threshold = 250, as.df = TRUE)) #> # A tibble: 1 × 1 #>   period_above_250    #>   <Duration>          #> 1 2100s (~35 minutes)"},{"path":"https://tscnlab.github.io/LightLogR/reference/photoperiod.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate photoperiod and boundary times — photoperiod","title":"Calculate photoperiod and boundary times — photoperiod","text":"family functions extract add photoperiod information. photoperiod() creates tibble calculated times dawn dusk given location date. function convenience wrapper suntools::crepuscule() calculate times dawn dusk. default, civil dawn dusk calculated, function can used calculate times changing solarDep parameter (e.g., 0 sunrise/sunset, 12 nautical, 18 astronomical). Taking light exposure dataset input, extract_photoperiod() calculates photoperiods boundary times unique day dataset, given location boundary condition (.e., solar depression angle). Basically, convenience wrapper photoperiod() takes light logger dataset extracts unique dates time zone dataset. add_photoperiod() adds photoperiod information light logger dataset. Beyond photoperiod information, categorize photoperiod.state \"day\" \"night\". overwrite set TRUE, function overwrite columns name. solar_noon() calculates solar noon given location date. function convenience wrapper suntools::solarnoon(). function companions like extract_photoperiod() add_photoperiod(), extended, sufficient interest.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/photoperiod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate photoperiod and boundary times — photoperiod","text":"","code":"photoperiod(coordinates, dates, tz, solarDep = 6)  extract_photoperiod(   dataset,   coordinates,   Datetime.colname = Datetime,   solarDep = 6 )  add_photoperiod(   dataset,   coordinates,   Datetime.colname = Datetime,   solarDep = 6,   overwrite = FALSE )  solar_noon(coordinates, dates, tz)"},{"path":"https://tscnlab.github.io/LightLogR/reference/photoperiod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate photoperiod and boundary times — photoperiod","text":"coordinates two element numeric vector representing latitude longitude location. Important note: Latitude first element Longitude second element. dates date format Date, coercible Date lubridate::as_date() tz Timezone data. Expects character. can look supported timezones OlsonNames(). solarDep numerical value representing solar depression angle 90 -90. means value 6 equals -6 degrees horizon. Default 6, equalling Civil dawn/dusk. common values 12 degrees Nautical dawn/dusk, 18 degrees Astronomical dawn/dusk, 0 degrees Sunrise/Sunset. Note output columns always named dawn dusk, regardless solarDep value. dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variable Datetime.colname. Datetime.colname column name contains datetime. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. Needs part dataset. Must type POSIXct. overwrite Logical scalar. TRUE, function overwrite columns name. FALSE (default), function stop columns already exist dataset.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/photoperiod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate photoperiod and boundary times — photoperiod","text":"photoperiod() returns tibble calculated times dawn dusk given location date, length equal dates input parameter . tibble contains following columns: date date calculation, stored class Date tz timezone output, stored class character lat lon latitude longitude location, stored class numeric solar.angle negative solar depression angle, .e. sun elevation horizon. stored class numeric dawn dusk calculated datetimes, stored class POSIXct photoperiod calculated photoperiod, stored class difftime. extract_photoperiod() returns tibble structure photoperiod(), length equal number unique dates dataset. add_photoperiod returns input dataset added photoperiod information. information appended following columns: dawn, dusk, photoperiod, photoperiod.state. solar_noon() returns tibble calculated solar noon","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/photoperiod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate photoperiod and boundary times — photoperiod","text":"Please note functions photoperiod family work one coordinate pair time. multiple locations (multiple time zones), need run function location separately. suggest using nested dataframe structure, employ purrr package iterate locations.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/photoperiod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate photoperiod and boundary times — photoperiod","text":"","code":"#example für Tübingen, Germany  coordinates <- c(48.521637, 9.057645)  dates <- c(\"2023-06-01\", \"2025-08-23\")  tz <- \"Europe/Berlin\"    #civil dawn/dusk  photoperiod(coordinates, dates, tz) #>         date            tz      lat      lon solar.angle                dawn #> 1 2023-06-01 Europe/Berlin 48.52164 9.057645          -6 2023-06-01 04:46:05 #> 2 2025-08-23 Europe/Berlin 48.52164 9.057645          -6 2025-08-23 05:55:03 #>                  dusk    photoperiod #> 1 2023-06-01 21:57:43 17.19384 hours #> 2 2025-08-23 20:56:37 15.02618 hours  #sunrise/sunset  photoperiod(coordinates, dates, tz, solarDep = 0) #>         date            tz      lat      lon solar.angle                dawn #> 1 2023-06-01 Europe/Berlin 48.52164 9.057645           0 2023-06-01 05:32:42 #> 2 2025-08-23 Europe/Berlin 48.52164 9.057645           0 2025-08-23 06:33:53 #>                  dusk    photoperiod #> 1 2023-06-01 21:10:59 15.63821 hours #> 2 2025-08-23 20:17:52 13.73304 hours  #extract_photoperiod  sample.data.environment |>     extract_photoperiod(coordinates) #>         date            tz      lat      lon solar.angle                dawn #> 1 2023-08-29 Europe/Berlin 48.52164 9.057645          -6 2023-08-29 06:03:20 #> 2 2023-08-30 Europe/Berlin 48.52164 9.057645          -6 2023-08-30 06:04:50 #> 3 2023-08-31 Europe/Berlin 48.52164 9.057645          -6 2023-08-31 06:06:20 #> 4 2023-09-01 Europe/Berlin 48.52164 9.057645          -6 2023-09-01 06:07:50 #> 5 2023-09-02 Europe/Berlin 48.52164 9.057645          -6 2023-09-02 06:09:19 #> 6 2023-09-03 Europe/Berlin 48.52164 9.057645          -6 2023-09-03 06:10:48 #>                  dusk    photoperiod #> 1 2023-08-29 20:45:14 14.69838 hours #> 2 2023-08-30 20:43:08 14.63828 hours #> 3 2023-08-31 20:41:01 14.57813 hours #> 4 2023-09-01 20:38:54 14.51793 hours #> 5 2023-09-02 20:36:47 14.45769 hours #> 6 2023-09-03 20:34:39 14.39742 hours   #add_photoperiod added_photoperiod <-  sample.data.environment |>  add_photoperiod(coordinates)  added_photoperiod |> head() #> # A tibble: 6 × 7 #> # Groups:   Id [1] #>   Id          Datetime             MEDI dawn                dusk                #>   <fct>       <dttm>              <dbl> <dttm>              <dttm>              #> 1 Participant 2023-08-29 00:00:04     0 2023-08-29 06:03:20 2023-08-29 20:45:14 #> 2 Participant 2023-08-29 00:00:14     0 2023-08-29 06:03:20 2023-08-29 20:45:14 #> 3 Participant 2023-08-29 00:00:24     0 2023-08-29 06:03:20 2023-08-29 20:45:14 #> 4 Participant 2023-08-29 00:00:34     0 2023-08-29 06:03:20 2023-08-29 20:45:14 #> 5 Participant 2023-08-29 00:00:44     0 2023-08-29 06:03:20 2023-08-29 20:45:14 #> 6 Participant 2023-08-29 00:00:54     0 2023-08-29 06:03:20 2023-08-29 20:45:14 #> # ℹ 2 more variables: photoperiod <drtn>, photoperiod.state <chr>  added_photoperiod |>   filter_Date(length = \"3 days\") |>   gg_days(aes_col = photoperiod.state,           group = dplyr::consecutive_id(photoperiod.state),           jco_color = TRUE           )   added_photoperiod |>   filter_Date(length = \"3 days\") |>   gg_day(aes_col = Id) +   ggplot2:: geom_rect(   data = \\(x) x |> dplyr::ungroup(Id) |> dplyr::summarize(dawn = mean(dawn) |> hms::as_hms()),   ggplot2::aes(xmin = 0, xmax = dawn, ymin = -Inf, ymax = Inf),   alpha = 0.1   ) +   ggplot2:: geom_rect(   data = \\(x) x |> dplyr::ungroup(Id) |> dplyr::summarize(dusk = mean(dusk) |> hms::as_hms()),   ggplot2::aes(xmin = dusk, xmax = 24*60*60, ymin = -Inf, ymax = Inf),   alpha = 0.1   )     added_photoperiod |> dplyr::summarize(dawn = mean(dawn) |> hms::as_hms()) #> # A tibble: 2 × 2 #>   Id          dawn            #>   <fct>       <time>          #> 1 Environment 18:07:04.984169 #> 2 Participant 18:07:04.984169   #solar_noon()  solar_noon(coordinates, dates, tz) #>         date            tz      lat      lon          solar.noon #> 1 2023-06-01 Europe/Berlin 48.52164 9.057645 2023-06-01 13:21:35 #> 2 2025-08-23 Europe/Berlin 48.52164 9.057645 2025-08-23 13:26:21"},{"path":"https://tscnlab.github.io/LightLogR/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://tscnlab.github.io/LightLogR/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/pulses_above_threshold.html","id":null,"dir":"Reference","previous_headings":"","what":"Pulses above threshold — pulses_above_threshold","title":"Pulses above threshold — pulses_above_threshold","text":"function clusters light data continuous clusters (pulses) light /given threshold. Clustering may fine-tuned setting minimum length clusters allowing brief interruptions included single cluster, specified maximum length interruption episodes proportion total amount interruptions light threshold.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/pulses_above_threshold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pulses above threshold — pulses_above_threshold","text":"","code":"pulses_above_threshold(   Light.vector,   Time.vector,   comparison = c(\"above\", \"below\"),   threshold,   min.length = \"2 mins\",   max.interrupt = \"8 mins\",   prop.interrupt = 0.25,   epoch = \"dominant.epoch\",   return.indices = FALSE,   na.rm = FALSE,   as.df = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/pulses_above_threshold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pulses above threshold — pulses_above_threshold","text":"Light.vector Numeric vector containing light data. Missing values considered FALSE comparing light levels threshold. Time.vector Vector containing time data. Can POSIXct, hms, duration, difftime. comparison String specifying whether time threshold calculated. Can either \"\" (default) \"\". two values provided threshold, argument ignored. threshold Single numeric value two numeric values specifying threshold light level(s) compare . vector two values provided, timing corresponding light levels two thresholds calculated. min.length minimum length pulse. Can either duration string. string, needs valid duration string, e.g., \"1 day\" \"10 sec\". Defaults \"2 mins\" Wilson et al. (2018). max.interrupt Maximum length episode interruptions. Can either duration string. string, needs valid duration string, e.g., \"1 day\" \"10 sec\". Defaults \"8 mins\" Wilson et al. (2018). prop.interrupt Numeric value 0 1 specifying maximum proportion total number interruptions. Defaults 0.25 Wilson et al. (2018). epoch epoch data sampled. Can either duration string. string, needs either \"dominant.epoch\" (default) guess based data, valid duration string, e.g., \"1 day\" \"10 sec\". return.indices Logical. cluster indices returned? works .df FALSE. Defaults FALSE. na.rm Logical. missing values removed calculation pulse metrics? Defaults FALSE. .df Logical. data frame returned? TRUE, data frame seven columns (\"n\", \"mean_level\", \"mean_duration\", \"total_duration\", \"mean_onset\", \"mean_midpoint\", \"mean_offset\") threshold (e.g., _{threshold}) returned. Defaults FALSE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/pulses_above_threshold.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pulses above threshold — pulses_above_threshold","text":"List data frame calculated values.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/pulses_above_threshold.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pulses above threshold — pulses_above_threshold","text":"timeseries assumed regular. Missing values light data replaced 0.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/pulses_above_threshold.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pulses above threshold — pulses_above_threshold","text":"Wilson, J., Reid, K. J., Braun, R. ., Abbott, S. M., & Zee, P. C. (2018). Habitual light exposure relative circadian timing delayed sleep-wake phase disorder. Sleep, 41(11). doi:10.1093/sleep/zsy166","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/pulses_above_threshold.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pulses above threshold — pulses_above_threshold","text":"","code":"# Sample data data = sample.data.environment %>%   dplyr::filter(Id == \"Participant\") %>%   filter_Datetime(length = lubridate::days(1)) %>%    dplyr::mutate(     Time = hms::as_hms(Datetime),   )  # Time vector as datetime data %>%   dplyr::reframe(pulses_above_threshold(MEDI, Datetime, threshold = 250, as.df = TRUE)) #> # A tibble: 1 × 8 #>   Id          n_pulses_above_250 mean_level_pulses_abov…¹ mean_duration_pulses…² #>   <fct>                    <int>                    <dbl> <Duration>             #> 1 Participant                  5                     717. 1044s (~17.4 minutes)  #> # ℹ abbreviated names: ¹​mean_level_pulses_above_250, #> #   ²​mean_duration_pulses_above_250 #> # ℹ 4 more variables: total_duration_pulses_above_250 <Duration>, #> #   mean_onset_pulses_above_250 <dttm>, mean_midpoint_pulses_above_250 <dttm>, #> #   mean_offset_pulses_above_250 <dttm>  # Time vector as hms time data %>%   dplyr::reframe(pulses_above_threshold(MEDI, Time, threshold = 250, as.df = TRUE)) #> # A tibble: 1 × 8 #>   Id          n_pulses_above_250 mean_level_pulses_abov…¹ mean_duration_pulses…² #>   <fct>                    <int>                    <dbl> <Duration>             #> 1 Participant                  5                     717. 1044s (~17.4 minutes)  #> # ℹ abbreviated names: ¹​mean_level_pulses_above_250, #> #   ²​mean_duration_pulses_above_250 #> # ℹ 4 more variables: total_duration_pulses_above_250 <Duration>, #> #   mean_onset_pulses_above_250 <time>, mean_midpoint_pulses_above_250 <time>, #> #   mean_offset_pulses_above_250 <time>  # Pulses below threshold  data %>%   dplyr::reframe(pulses_above_threshold(MEDI, Datetime, \"below\", threshold = 250, as.df = TRUE)) #> # A tibble: 1 × 8 #>   Id          n_pulses_below_250 mean_level_pulses_belo…¹ mean_duration_pulses…² #>   <fct>                    <int>                    <dbl> <Duration>             #> 1 Participant                  5                     40.2 16062s (~4.46 hours)   #> # ℹ abbreviated names: ¹​mean_level_pulses_below_250, #> #   ²​mean_duration_pulses_below_250 #> # ℹ 4 more variables: total_duration_pulses_below_250 <Duration>, #> #   mean_onset_pulses_below_250 <dttm>, mean_midpoint_pulses_below_250 <dttm>, #> #   mean_offset_pulses_below_250 <dttm>  # Pulses within threshold range data %>%   dplyr::reframe(pulses_above_threshold(MEDI, Datetime, threshold = c(250,1000), as.df = TRUE)) #> # A tibble: 1 × 8 #>   Id        n_pulses_within_250-…¹ mean_level_pulses_wi…² mean_duration_pulses…³ #>   <fct>                      <int>                  <dbl> <Duration>             #> 1 Particip…                      4                   491. 452s (~7.53 minutes)   #> # ℹ abbreviated names: ¹​`n_pulses_within_250-1000`, #> #   ²​`mean_level_pulses_within_250-1000`, #> #   ³​`mean_duration_pulses_within_250-1000` #> # ℹ 4 more variables: `total_duration_pulses_within_250-1000` <Duration>, #> #   `mean_onset_pulses_within_250-1000` <dttm>, #> #   `mean_midpoint_pulses_within_250-1000` <dttm>, #> #   `mean_offset_pulses_within_250-1000` <dttm>"},{"path":"https://tscnlab.github.io/LightLogR/reference/remove_partial_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove groups that have too few data points — remove_partial_data","title":"Remove groups that have too few data points — remove_partial_data","text":"function removes groups dataframe sufficient data points. Groups one data point automatically removed. Single data points common using aggregate_Datetime().","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/remove_partial_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove groups that have too few data points — remove_partial_data","text":"","code":"remove_partial_data(   dataset,   Variable.colname = Datetime,   threshold.missing = 0.2,   by.date = FALSE,   Datetime.colname = Datetime,   show.result = FALSE,   handle.gaps = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/remove_partial_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove groups that have too few data points — remove_partial_data","text":"dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variables Datetime.colname Variable.colname. Variable.colname Column name contains variable assess sufficient datapoints. Expects symbol. Needs part dataset. Default Datetime, makes sense presence single data point groups need removed. threshold.missing either percentage missing data, group gets removed. Expects numeric scalar. duration missing data, group gets removed. Expects either lubridate::duration() character can converted one, e.g., \"30 mins\". .date Logical. data (additionally) grouped day? Defaults FALSE. Additional grouping persitant beyond function call. Datetime.colname Column name contains datetime. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. Needs part dataset. Must type POSIXct. show.result Logical, whether output function summary data (TRUE), reduced dataset (FALSE, default) handle.gaps Logical, whether data shall treated gap_handler(). set FALSE default. TRUE, used argument full.days = TRUE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/remove_partial_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove groups that have too few data points — remove_partial_data","text":"show.result = FALSE(default), reduced dataframe without groups sufficient data","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/remove_partial_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove groups that have too few data points — remove_partial_data","text":"","code":"#create sample data with gaps gapped_data <-   sample.data.environment |>   dplyr::filter(MEDI < 30000)  #check their status, based on the MEDI variable gapped_data |> remove_partial_data(MEDI, handle.gaps = TRUE, show.result = TRUE) #> # A tibble: 2 × 8 #> # Groups:   Id [2] #>   marked.for.removal Id          duration             missing                #>   <lgl>              <fct>       <Duration>           <Duration>             #> 1 TRUE               Environment 403920s (~4.68 days) 114480s (~1.32 days)   #> 2 FALSE              Participant 516350s (~5.98 days) 2050s (~34.17 minutes) #> # ℹ 4 more variables: total <Duration>, missing_pct <dbl>, threshold <dbl>, #> #   interval <Duration>  #the function will produce a warning if implicit gaps are present gapped_data |> remove_partial_data(MEDI, show.result = TRUE) #> This dataset has implicit gaps. Please make sure to convert them to explicit gaps or that you really know what you are doing #> # A tibble: 2 × 8 #> # Groups:   Id [2] #>   marked.for.removal Id        duration             missing total                #>   <lgl>              <fct>     <Duration>           <Durat> <Duration>           #> 1 FALSE              Environm… 403920s (~4.68 days) 0s      403920s (~4.68 days) #> 2 FALSE              Particip… 516350s (~5.98 days) 0s      516350s (~5.98 days) #> # ℹ 3 more variables: missing_pct <dbl>, threshold <dbl>, interval <Duration>  #one group (Environment) does not make the cut of 20% missing data gapped_data |> remove_partial_data(MEDI, handle.gaps = TRUE) |> dplyr::count(Id) #> # A tibble: 1 × 2 #> # Groups:   Id [1] #>   Id              n #>   <fct>       <int> #> 1 Participant 51635 #for comparison gapped_data |> dplyr::count(Id) #> # A tibble: 2 × 2 #> # Groups:   Id [2] #>   Id              n #>   <fct>       <int> #> 1 Environment 13464 #> 2 Participant 51635 #If the threshold is set differently, e.g., to 2 days allowed missing, results vary gapped_data |>   remove_partial_data(MEDI, handle.gaps = TRUE, threshold.missing = \"2 days\") |>   dplyr::count(Id) #> # A tibble: 2 × 2 #> # Groups:   Id [2] #>   Id              n #>   <fct>       <int> #> 1 Environment 13464 #> 2 Participant 51635  #The removal can be automatically switched to daily detections within groups gapped_data |>  remove_partial_data(MEDI, handle.gaps = TRUE, by.date = TRUE, show.result = TRUE) |>  head() #> # A tibble: 6 × 9 #> # Groups:   Id, .date [6] #>   marked.for.removal Id    .date      duration              missing              #>   <lgl>              <fct> <date>     <Duration>            <Duration>           #> 1 FALSE              Envi… 2023-08-29 85020s (~23.62 hours) 1380s (~23 minutes)  #> 2 FALSE              Envi… 2023-08-30 69150s (~19.21 hours) 17250s (~4.79 hours) #> 3 TRUE               Envi… 2023-08-31 63870s (~17.74 hours) 22530s (~6.26 hours) #> 4 TRUE               Envi… 2023-09-01 65820s (~18.28 hours) 20580s (~5.72 hours) #> 5 TRUE               Envi… 2023-09-02 56880s (~15.8 hours)  29520s (~8.2 hours)  #> 6 TRUE               Envi… 2023-09-03 63180s (~17.55 hours) 23220s (~6.45 hours) #> # ℹ 4 more variables: total <Duration>, missing_pct <dbl>, threshold <dbl>, #> #   interval <Duration>"},{"path":"https://tscnlab.github.io/LightLogR/reference/reverse2_trans.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a reverse transformation function specifically for date scales — reverse2_trans","title":"Create a reverse transformation function specifically for date scales — reverse2_trans","text":"helper function exclusive gg_heatmap(), get reversed date sequence.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/reverse2_trans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a reverse transformation function specifically for date scales — reverse2_trans","text":"","code":"reverse2_trans()"},{"path":"https://tscnlab.github.io/LightLogR/reference/reverse2_trans.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Create a reverse transformation function specifically for date scales — reverse2_trans","text":"https://github.com/tidyverse/ggplot2/issues/4014","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/reverse2_trans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a reverse transformation function specifically for date scales — reverse2_trans","text":"transformation function","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/reverse2_trans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a reverse transformation function specifically for date scales — reverse2_trans","text":"","code":"reverse2_trans() #> Transformer: reverse2 [-Inf, Inf]"},{"path":"https://tscnlab.github.io/LightLogR/reference/sample.data.environment.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample of wearable data combined with environmental data — sample.data.environment","title":"Sample of wearable data combined with environmental data — sample.data.environment","text":"subset data study TSCN-Lab using ActLumus light logger. dataset contains personal light exposure information one participant course six full days. dataset measured 10 second epoch complete (missing values). Additionally environmental light data captured second light logger mounted horizontally TUM university roof, without obstructions (besides transparent plastic halfdome). epoch data 30 seconds. dataset allows interesting calculations based available daylight given point time.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/sample.data.environment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample of wearable data combined with environmental data — sample.data.environment","text":"","code":"sample.data.environment"},{"path":"https://tscnlab.github.io/LightLogR/reference/sample.data.environment.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample of wearable data combined with environmental data — sample.data.environment","text":"sample.data.environment tibble 69,120 rows 3 columns: Datetime POSIXct Datetime MEDI melanopic EDI measurement data. Unit lux. Id character vector indicating whether data Participant Environment.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/sample.data.environment.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Sample of wearable data combined with environmental data — sample.data.environment","text":"https://www.tscnlab.org","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/sample.data.irregular.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample of highly irregular wearable data — sample.data.irregular","title":"Sample of highly irregular wearable data — sample.data.irregular","text":"dataset collected wearable device somewhat irregular recording pattern. Overall, data recorded every 15 seconds. Every tenth measurement takes 16 seconds, every hundredths 17 seconds, every thousandths 18 seconds, . makes dataset prime example handling dealing irregular data.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/sample.data.irregular.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample of highly irregular wearable data — sample.data.irregular","text":"","code":"sample.data.irregular"},{"path":"https://tscnlab.github.io/LightLogR/reference/sample.data.irregular.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Sample of highly irregular wearable data — sample.data.irregular","text":"sample.data.irregular tibble 11,422 rows 13 columns: Id character vector indicating participant (P1). Datetime POSIXct Datetime lux numeric Illuminance. Unit lux. kelvin numeric correlated colour temperature (CCT). Unit Kelvin. rgbR numeric red sensor channel output. Unit W/m2/nm. rgbG numeric green sensor channel output. Unit W/m2/nm. rgbB numeric blue sensor channel output. Unit W/m2/nm. rgbIR numeric infrared sensor channel output. Unit W/m2/nm. movement numeric indicator movement (intensity) device. Movement given discrete counts correlating number instances accelerometer records instances greater 0.1875g per 15s sampling interval. MEDI melanopic EDI measurement data. Unit lux. R. Unknown, likely direct derived output red sensor channel G. Unknown, likely direct derived output green sensor channel B. Unknown, likely direct derived output blue sensor channel","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/sc2interval.html","id":null,"dir":"Reference","previous_headings":"","what":"Statechange (sc) Timestamps to Intervals — sc2interval","title":"Statechange (sc) Timestamps to Intervals — sc2interval","text":"Takes input datetimes Statechanges creates column Intervals. full = TRUE, also create intervals day prior first state change last. output.dataset = FALSE give named vector, otherwise tibble. state change info requires description name state (like \"sleep\" \"wake\", \"wear\") goes effect given Datetime. Works grouped data mix intervals participants. Missing data explicit possible. Also, maximum allowed length interval can set, implicit missing timestamps set period times can enforced.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/sc2interval.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Statechange (sc) Timestamps to Intervals — sc2interval","text":"","code":"sc2interval(   dataset,   Datetime.colname = Datetime,   Statechange.colname = State,   State.colname = State,   Interval.colname = Interval,   full = TRUE,   starting.state = NA,   output.dataset = TRUE,   Datetime.keep = FALSE,   length.restriction = 60 * 60 * 24 )"},{"path":"https://tscnlab.github.io/LightLogR/reference/sc2interval.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Statechange (sc) Timestamps to Intervals — sc2interval","text":"dataset light logger dataset. Expects dataframe. imported LightLogR, take care choose sensible variable Datetime.colname. Datetime.colname column name contains datetime. Defaults \"Datetime\" automatically correct data imported LightLogR. Expects symbol. Needs part dataset. Must type POSIXct. Statechange.colname, Interval.colname, State.colname Column names contain name/description state change contain Interval State (also default). Expects symbol. Statechange column needs part dataset. full, starting.state arguments handle state first day first state change last state change last day. full = TRUE(default, expects logical), create interval first day 00:00:00 state change. interval given state specified starting.state, NA default, can character scalar. extend interval last state change end last given day (specifically 00:00:00 next day). output.dataset output data.frame (Default TRUE) vector hms (FALSE) times? Expects logical scalar. Datetime.keep TRUE, original Datetime column kept. length.restriction length intervals great, interval state can set NA, effectively produces gap data. makes sense intervals implausibly wrong (e.g. someone slept 50 hours), data combined light logger data, e.g., interval2state(), metrics visualizations remove interval.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/sc2interval.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Statechange (sc) Timestamps to Intervals — sc2interval","text":"One data.frame object identical dataset interval instead datetime. original Statechange column now indicates State Interval. named vector intervals, names states","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/sc2interval.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Statechange (sc) Timestamps to Intervals — sc2interval","text":"","code":"library(tibble) library(lubridate) library(dplyr) sample <- tibble::tibble(Datetime = c(\"2023-08-15 6:00:00\",                                       \"2023-08-15 23:00:00\",                                       \"2023-08-16 6:00:00\",                                       \"2023-08-16 22:00:00\",                                       \"2023-08-17 6:30:00\",                                       \"2023-08-18 1:00:00\"),                          State = rep(c(\"wake\", \"sleep\"), 3),                          Id = \"Participant\") #intervals from sample sc2interval(sample) #> # A tibble: 7 × 3 #>   State Id          Interval                                         #>   <chr> <chr>       <Interval>                                       #> 1 NA    NA          2023-08-15 00:00:00 UTC--2023-08-15 06:00:00 UTC #> 2 wake  Participant 2023-08-15 06:00:00 UTC--2023-08-15 23:00:00 UTC #> 3 sleep Participant 2023-08-15 23:00:00 UTC--2023-08-16 06:00:00 UTC #> 4 wake  Participant 2023-08-16 06:00:00 UTC--2023-08-16 22:00:00 UTC #> 5 sleep Participant 2023-08-16 22:00:00 UTC--2023-08-17 06:30:00 UTC #> 6 wake  Participant 2023-08-17 06:30:00 UTC--2023-08-18 01:00:00 UTC #> 7 sleep Participant 2023-08-18 01:00:00 UTC--2023-08-19 00:00:00 UTC  #compare sample (y) and intervals (x) sc2interval(sample) %>%  mutate(Datetime = int_start(Interval)) %>%  dplyr::left_join(sample, by = c(\"Id\", \"State\"),                   relationship = \"many-to-many\") %>%  head() #> # A tibble: 6 × 5 #>   State Id          Interval                                         #>   <chr> <chr>       <Interval>                                       #> 1 NA    NA          2023-08-15 00:00:00 UTC--2023-08-15 06:00:00 UTC #> 2 wake  Participant 2023-08-15 06:00:00 UTC--2023-08-15 23:00:00 UTC #> 3 wake  Participant 2023-08-15 06:00:00 UTC--2023-08-15 23:00:00 UTC #> 4 wake  Participant 2023-08-15 06:00:00 UTC--2023-08-15 23:00:00 UTC #> 5 sleep Participant 2023-08-15 23:00:00 UTC--2023-08-16 06:00:00 UTC #> 6 sleep Participant 2023-08-15 23:00:00 UTC--2023-08-16 06:00:00 UTC #> # ℹ 2 more variables: Datetime.x <dttm>, Datetime.y <chr>"},{"path":"https://tscnlab.github.io/LightLogR/reference/sleep_int2Brown.html","id":null,"dir":"Reference","previous_headings":"","what":"Recode Sleep/Wake intervals to Brown state intervals — sleep_int2Brown","title":"Recode Sleep/Wake intervals to Brown state intervals — sleep_int2Brown","text":"Takes dataset sleep/wake intervals recodes Brown state intervals. Specifically, recodes sleep intervals night, reduces wake intervals specified evening.length recodes evening day intervals. evening.length time day night. result can used input interval2state() might used subsequently Brown2reference().","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/sleep_int2Brown.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Recode Sleep/Wake intervals to Brown state intervals — sleep_int2Brown","text":"","code":"sleep_int2Brown(   dataset,   Interval.colname = Interval,   Sleep.colname = State,   wake.state = \"wake\",   sleep.state = \"sleep\",   Brown.day = \"day\",   Brown.evening = \"evening\",   Brown.night = \"night\",   evening.length = lubridate::dhours(3),   Brown.state.colname = State.Brown,   output.dataset = TRUE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/sleep_int2Brown.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Recode Sleep/Wake intervals to Brown state intervals — sleep_int2Brown","text":"dataset dataset sleep/wake intervals. Interval.colname name column intervals. Defaults Interval. Sleep.colname name column sleep/wake states. Defaults State. wake.state, sleep.state names wake sleep states Sleep.colname. Default \"wake\" \"sleep\". Expected character scalar must exact match. Brown.day, Brown.evening, Brown.night names Brown states used. Defaults \"day\", \"evening\" \"night\". evening.length length evening interval seconds. Can also use lubridate duration period objects. Defaults 3 hours. Brown.state.colname name column newly created Brown states. Works simple renaming Sleep.colname. output.dataset Whether return whole dataset vector Brown states.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/sleep_int2Brown.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Recode Sleep/Wake intervals to Brown state intervals — sleep_int2Brown","text":"dataset Brown states vector Brown states. Brown states created new column name specified Brown.state.colname. dataset rows original dataset, wake intervals split day evening intervals.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/sleep_int2Brown.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Recode Sleep/Wake intervals to Brown state intervals — sleep_int2Brown","text":"function filter non-sleep intervals shorter specified evening.length. prevents problematic behaviour evening.length longer wake intervals , e.g., first state sleep midnight prior NA interval midnight till sleep. behavior might, however, result problematic results specialized experimental setups ultra short wake/sleep cycles. sleep_int2Brown() function applicable cases anyways.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/sleep_int2Brown.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Recode Sleep/Wake intervals to Brown state intervals — sleep_int2Brown","text":"https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001571","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/sleep_int2Brown.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Recode Sleep/Wake intervals to Brown state intervals — sleep_int2Brown","text":"","code":"#create a sample dataset sample <- tibble::tibble(Datetime = c(\"2023-08-15 6:00:00\",                                          \"2023-08-15 23:00:00\",                                          \"2023-08-16 6:00:00\",                                          \"2023-08-16 22:00:00\",                                          \"2023-08-17 6:30:00\",                                          \"2023-08-18 1:00:00\"),                          State = rep(c(\"wake\", \"sleep\"), 3),                          Id = \"Participant\") #intervals from sample sc2interval(sample)  #> # A tibble: 7 × 3 #>   State Id          Interval                                         #>   <chr> <chr>       <Interval>                                       #> 1 NA    NA          2023-08-15 00:00:00 UTC--2023-08-15 06:00:00 UTC #> 2 wake  Participant 2023-08-15 06:00:00 UTC--2023-08-15 23:00:00 UTC #> 3 sleep Participant 2023-08-15 23:00:00 UTC--2023-08-16 06:00:00 UTC #> 4 wake  Participant 2023-08-16 06:00:00 UTC--2023-08-16 22:00:00 UTC #> 5 sleep Participant 2023-08-16 22:00:00 UTC--2023-08-17 06:30:00 UTC #> 6 wake  Participant 2023-08-17 06:30:00 UTC--2023-08-18 01:00:00 UTC #> 7 sleep Participant 2023-08-18 01:00:00 UTC--2023-08-19 00:00:00 UTC #recoded intervals                        sc2interval(sample) %>% sleep_int2Brown() #> # A tibble: 10 × 3 #>    State.Brown Id          Interval                                         #>    <chr>       <chr>       <Interval>                                       #>  1 NA          NA          2023-08-15 00:00:00 UTC--2023-08-15 06:00:00 UTC #>  2 day         Participant 2023-08-15 06:00:00 UTC--2023-08-15 20:00:00 UTC #>  3 evening     Participant 2023-08-15 20:00:00 UTC--2023-08-15 23:00:00 UTC #>  4 night       Participant 2023-08-15 23:00:00 UTC--2023-08-16 06:00:00 UTC #>  5 day         Participant 2023-08-16 06:00:00 UTC--2023-08-16 19:00:00 UTC #>  6 evening     Participant 2023-08-16 19:00:00 UTC--2023-08-16 22:00:00 UTC #>  7 night       Participant 2023-08-16 22:00:00 UTC--2023-08-17 06:30:00 UTC #>  8 day         Participant 2023-08-17 06:30:00 UTC--2023-08-17 22:00:00 UTC #>  9 evening     Participant 2023-08-17 22:00:00 UTC--2023-08-18 01:00:00 UTC #> 10 night       Participant 2023-08-18 01:00:00 UTC--NA"},{"path":"https://tscnlab.github.io/LightLogR/reference/spectral_integration.html","id":null,"dir":"Reference","previous_headings":"","what":"Integrate spectral irradiance with optional weighting — spectral_integration","title":"Integrate spectral irradiance with optional weighting — spectral_integration","text":"Integrates given spectrum, optionally portion spectrum, optionally weighing function. Can used calculate spectral contributions certain wavelength ranges, calculate (alphaopically equivalent daylight) illuminance.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/spectral_integration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integrate spectral irradiance with optional weighting — spectral_integration","text":"","code":"spectral_integration(   spectrum,   wavelength.range = NULL,   action.spectrum = NULL,   general.weight = 1 )"},{"path":"https://tscnlab.github.io/LightLogR/reference/spectral_integration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integrate spectral irradiance with optional weighting — spectral_integration","text":"spectrum Tibble spectral data (1st col: wavelength, 2nd col: SPD values) wavelength.range Optional integration bounds (length-2 numeric) action.spectrum Either: Tibble wavelength weighting columns Name built-spectrum: \"photopic\", \"melanopic\", \"rhodopic\", \"l_cone_opic\", \"m_cone_opic\", \"s_cone_opic\" general.weight Scalar multiplier \"auto\" built-efficacies","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/spectral_integration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Integrate spectral irradiance with optional weighting — spectral_integration","text":"Numeric integrated value","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/spectral_integration.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Integrate spectral irradiance with optional weighting — spectral_integration","text":"function uses trapezoidal integration recognizes differing step-widths spectrum. action spectrum used, values action spectrum spectral wavelenghts interpolated stats::approx(). used efficacies auto-weighting : photopic: 683.0015478 melanopic: 1/0.0013262 rhodopic: 1/0.0014497 l_cone_opic: 1/0.0016289 m_cone_opic: 1/0.0014558 s_cone_opic: 1/0.0008173 requires input values W/(m^2) spectrum. provided units, result rescaled afterwards.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/spectral_integration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Integrate spectral irradiance with optional weighting — spectral_integration","text":"","code":"# creating an equal energy spectrum of value 1 spd <- data.frame(wl = 380:780, values = 1)  #integrating over the full spectrum spectral_integration(spd) #> [1] 400  #integrating over wavelengths 400-500 nm spectral_integration(spd, wavelength.range = c(400, 500)) #> [1] 100  #calculating the photopic illuminance of an equal energy spectrum with 1 W/(m^2*nm) spectral_integration(spd, action.spectrum = \"photopic\", general.weight = \"auto\") #> [1] 72983.09  #calculating the melanopic EDI of an equal energy spectrum with 1 W/(m^2*nm) spectral_integration(spd, action.spectrum = \"melanopic\", general.weight = \"auto\") #> [1] 66109.89  # Custom action spectrum custom_act <- data.frame(wavelength = 400:700, weight = 0.5) spectral_integration(spd, wavelength.range = c(400,700),                       action.spectrum = custom_act, general.weight = 2) #> [1] 300                       #using a spectrum that is broader then the action spectrum will not change the #output, as the action spectrum will use zeros beyond its range"},{"path":"https://tscnlab.github.io/LightLogR/reference/spectral_reconstruction.html","id":null,"dir":"Reference","previous_headings":"","what":"Reconstruct spectral irradiance from sensor counts — spectral_reconstruction","title":"Reconstruct spectral irradiance from sensor counts — spectral_reconstruction","text":"function takes sensor data form (normalized) counts reconstructs spectral power distribution (SPD) calibration matrix. matrix takes form sensor channel x wavelength, spectrum results form linear combination counts x calibration-value wavelength matrix. Handles multiple sensor readings returning list spectra","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/spectral_reconstruction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reconstruct spectral irradiance from sensor counts — spectral_reconstruction","text":"","code":"spectral_reconstruction(   sensor_channels,   calibration_matrix,   format = c(\"long\", \"wide\") )"},{"path":"https://tscnlab.github.io/LightLogR/reference/spectral_reconstruction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reconstruct spectral irradiance from sensor counts — spectral_reconstruction","text":"sensor_channels Named numeric vector dataframe sensor readings. Names must match calibration matrix columns. calibration_matrix Matrix dataframe sensor-named columns wavelength-indexed rows format Output format: \"long\" (list tibbles) \"wide\" (dataframe)","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/spectral_reconstruction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reconstruct spectral irradiance from sensor counts — spectral_reconstruction","text":"\"long\": List tibbles (wavelength, irradiance) \"wide\": Dataframe wavelength columns one row per spectrum","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/spectral_reconstruction.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reconstruct spectral irradiance from sensor counts — spectral_reconstruction","text":"Please note calibration matrices provided LightLogR, can provided wearable device manufacturer. Counts can normalized normalize_counts() function, provided output also contains gain column.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/spectral_reconstruction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reconstruct spectral irradiance from sensor counts — spectral_reconstruction","text":"","code":"# Calibration matrix example calib <- matrix(1:12, ncol=3, dimnames = list(400:403, c(\"R\", \"G\", \"B\")))  # Named vector input spectral_reconstruction(c(R=1, G=2, B=3), calib) #> # A tibble: 4 × 2 #>   wavelength irradiance #>        <dbl>      <dbl> #> 1        400         38 #> 2        401         44 #> 3        402         50 #> 4        403         56  # Dataframe input df <- data.frame(R=1, G=2, B=3, other_col=10) spectral_reconstruction(dplyr::select(df, R:B), calib) #> # A tibble: 4 × 2 #>   wavelength irradiance #>        <dbl>      <dbl> #> 1        400         38 #> 2        401         44 #> 3        402         50 #> 4        403         56  # Multiple spectra: as list columns df <- data.frame(Measurement = c(1,2), R=c(1,2), G=c(2,4), B=c(3,6)) df <-  df |>    dplyr::mutate(       Spectrum = spectral_reconstruction(dplyr::pick(R:B), calib)       ) df |> tidyr::unnest(Spectrum) #> # A tibble: 8 × 6 #>   Measurement     R     G     B wavelength irradiance #>         <dbl> <dbl> <dbl> <dbl>      <dbl>      <dbl> #> 1           1     1     2     3        400         38 #> 2           1     1     2     3        401         44 #> 3           1     1     2     3        402         50 #> 4           1     1     2     3        403         56 #> 5           2     2     4     6        400         76 #> 6           2     2     4     6        401         88 #> 7           2     2     4     6        402        100 #> 8           2     2     4     6        403        112  # Multiple spectra: as extended dataframes df |>    dplyr::mutate(       Spectrum = spectral_reconstruction(dplyr::pick(R:B), calib, \"wide\")) #>   Measurement R G B Spectrum.400 Spectrum.401 Spectrum.402 Spectrum.403 #> 1           1 1 2 3           38           44           50           56 #> 2           2 2 4 6           76           88          100          112"},{"path":"https://tscnlab.github.io/LightLogR/reference/summarize_numeric.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize numeric columns in dataframes to means — summarize_numeric","title":"Summarize numeric columns in dataframes to means — summarize_numeric","text":"simple helper function created summarize episodes gaps, clusters, states, focusing numeric variables. calculates mean values numeric columns handles Duration objects appropriately. Despite name, function actually summarizes double columns, inclusive compared just numeric columns.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/summarize_numeric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize numeric columns in dataframes to means — summarize_numeric","text":"","code":"summarize_numeric(   data,   remove = NULL,   prefix = \"mean_\",   na.rm = TRUE,   complete.groups.on = NULL,   add.total.duration = TRUE,   durations.dec = 0,   Datetime2Time = TRUE )  summarise_numeric(   data,   remove = NULL,   prefix = \"mean_\",   na.rm = TRUE,   complete.groups.on = NULL,   add.total.duration = TRUE,   durations.dec = 0,   Datetime2Time = TRUE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/summarize_numeric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize numeric columns in dataframes to means — summarize_numeric","text":"data dataframe containing numeric data, typically extract_clusters() extract_gaps(). remove Character vector columns removed summary. prefix prefix add column names summarized metrics. Defaults \"mean_\". na.rm Whether remove NA values calculating means. Defaults TRUE. complete.groups.Column name , together grouping variables, can used provide complete set. example, extract_clusters(), days might clusters. show summary output . important however, consider zero instances, one extract complete set clusters non-clusters, set .cluster argument, show zero clusters days. add.total.duration Logical, whether total duration given group calculated. relevant column duration part input data. durations.dec Numeric number decimals mean calculation durations times. Defaults 0. Datetime2Time Logical whether POSIXct columns transformed hms(time) columns, usually sensible averaging (default TRUE). Calls Datetime2Time() default settings (POSIXct affected).","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/summarize_numeric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize numeric columns in dataframes to means — summarize_numeric","text":"dataframe containing summarized metrics.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/summarize_numeric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize numeric columns in dataframes to means — summarize_numeric","text":"","code":"# Extract clusters and summarize them dataset <- sample.data.environment %>% aggregate_Datetime(unit = \"15 mins\") |> extract_clusters(MEDI > 1000)  #input to summarize_numeric dataset |> utils::head() #> # A tibble: 6 × 6 #> # Groups:   Id [1] #>   Id      state.count start               end                 epoch              #>   <fct>   <chr>       <dttm>              <dttm>              <Duration>         #> 1 Enviro… 1           2023-08-29 06:52:30 2023-08-29 19:52:30 900s (~15 minutes) #> 2 Enviro… 2           2023-08-30 06:52:30 2023-08-30 20:07:30 900s (~15 minutes) #> 3 Enviro… 3           2023-08-31 06:52:30 2023-08-31 19:37:30 900s (~15 minutes) #> 4 Enviro… 4           2023-09-01 07:07:30 2023-09-01 19:52:30 900s (~15 minutes) #> 5 Enviro… 5           2023-09-02 06:52:30 2023-09-02 19:52:30 900s (~15 minutes) #> 6 Enviro… 6           2023-09-03 06:52:30 2023-09-03 19:52:30 900s (~15 minutes) #> # ℹ 1 more variable: duration <Duration> #output of summarize_numeric (removing state.count and epoch from the summary) dataset |> summarize_numeric(c(\"state.count\", \"epoch\")) #> # A tibble: 2 × 6 #>   Id    mean_start mean_end mean_duration         total_duration        episodes #>   <fct> <time>     <time>   <Duration>            <Duration>               <int> #> 1 Envi… 06:55:00   19:52:30 46650s (~12.96 hours) 279900s (~3.24 days)         6 #> 2 Part… 13:40:30   15:27:00 6390s (~1.77 hours)   63900s (~17.75 hours)       10"},{"path":"https://tscnlab.github.io/LightLogR/reference/supported_devices.html","id":null,"dir":"Reference","previous_headings":"","what":"Get all the supported devices in LightLogR — supported_devices","title":"Get all the supported devices in LightLogR — supported_devices","text":"Returns vector supported devices LightLogR.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/supported_devices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get all the supported devices in LightLogR — supported_devices","text":"","code":"supported_devices()"},{"path":"https://tscnlab.github.io/LightLogR/reference/supported_devices.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get all the supported devices in LightLogR — supported_devices","text":"character vector supported devices","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/supported_devices.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get all the supported devices in LightLogR — supported_devices","text":"supported devices dedicated import function. Import functions can called either import_Dataset() respective device = \"device\" argument, directly, e.g., import$ActLumus().","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/supported_devices.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get all the supported devices in LightLogR — supported_devices","text":"","code":"supported_devices() #>  [1] \"ActLumus\"              \"ActTrust\"              \"Actiwatch_Spectrum\"    #>  [4] \"Actiwatch_Spectrum_de\" \"Circadian_Eye\"         \"Clouclip\"              #>  [7] \"DeLux\"                 \"GENEActiv_GGIR\"        \"Kronowise\"             #> [10] \"LIMO\"                  \"LYS\"                   \"LiDo\"                  #> [13] \"LightWatcher\"          \"MotionWatch8\"          \"OcuWEAR\"               #> [16] \"Speccy\"                \"SpectraWear\"           \"VEET\"                  #> [19] \"nanoLambda\""},{"path":"https://tscnlab.github.io/LightLogR/reference/symlog_trans.html","id":null,"dir":"Reference","previous_headings":"","what":"Scale positive and negative values on a log scale — symlog_trans","title":"Scale positive and negative values on a log scale — symlog_trans","text":"create plot positive negative (unscaled) values log-transformed axis, values need scaled accordingly. R ggplot2 built-function , following function can used create transformation function purpose. function coded based post stack overflow. symlog transformation standard transformation used e.g., gg_day().","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/symlog_trans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scale positive and negative values on a log scale — symlog_trans","text":"","code":"symlog_trans(base = 10, thr = 1, scale = 1)"},{"path":"https://tscnlab.github.io/LightLogR/reference/symlog_trans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scale positive and negative values on a log scale — symlog_trans","text":"base Base logarithmic transformation. default 10. thr Threshold logarithmic transformation applied. absolute value threshold, value transformed. default 1. scale Scaling factor logarithmically transformed values threshold. default 1.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/symlog_trans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Scale positive and negative values on a log scale — symlog_trans","text":"transformation function can used ggplot2 plotly scale positive negative values log scale.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/symlog_trans.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Scale positive and negative values on a log scale — symlog_trans","text":"symlog transformation can accessed either via trans = \"symlog\" argument scaling function, via trans = symlog_trans(). latter allows setting individual arguments.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/symlog_trans.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Scale positive and negative values on a log scale — symlog_trans","text":"function`s code straight copy post stack overflow. author answer Julius Vainora, author question Brian B","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/symlog_trans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scale positive and negative values on a log scale — symlog_trans","text":"","code":"dataset <-  sample.data.environment %>% filter_Date(end = \"2023-08-29\") %>%  dplyr::mutate(MEDI = dplyr::case_when(                                      Id == \"Environment\" ~ -MEDI,                                      .default = MEDI)) #basic application where transformation, breaks and labels are set manually dataset %>%                                      gg_day(aes_col = Id) + ggplot2::scale_y_continuous( trans = \"symlog\") #> Scale for y is already present. #> Adding another scale for y, which will replace the existing scale.   #the same plot, but with breaks and labels set manually                             dataset %>%                                      gg_day(aes_col = Id) + ggplot2::scale_y_continuous( trans = \"symlog\",  breaks = c(-10^(5:0), 0, 10^(0:5)), labels = function(x) format(x, scientific = FALSE, big.mark = \" \")) #> Scale for y is already present. #> Adding another scale for y, which will replace the existing scale.   #setting individual arguments of the symlog function manually allows #e.g., to emphasize values smaller than 1 dataset %>%                                      gg_day(aes_col = Id) + ggplot2::scale_y_continuous( trans = symlog_trans(thr = 0.01), breaks = c(-10^(5:-1), 0, 10^(-1:5)), labels = function(x) format(x, scientific = FALSE, big.mark = \" \")) #> Scale for y is already present. #> Adding another scale for y, which will replace the existing scale."},{"path":"https://tscnlab.github.io/LightLogR/reference/threshold_for_duration.html","id":null,"dir":"Reference","previous_headings":"","what":"Find threshold for given duration — threshold_for_duration","title":"Find threshold for given duration — threshold_for_duration","text":"function finds threshold light levels /given duration. function can considered inverse duration_above_threshold.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/threshold_for_duration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find threshold for given duration — threshold_for_duration","text":"","code":"threshold_for_duration(   Light.vector,   Time.vector,   duration,   comparison = c(\"above\", \"below\"),   epoch = \"dominant.epoch\",   na.rm = FALSE,   as.df = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/threshold_for_duration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find threshold for given duration — threshold_for_duration","text":"Light.vector Numeric vector containing light data. Time.vector Vector containing time data. Can POSIXct, hms, duration, difftime. duration duration threshold found. Can either duration string. string, needs valid duration string, e.g., \"1 day\" \"10 sec\". comparison String specifying whether light levels threshold considered. Can either \"\" (default) \"\". epoch epoch data sampled. Can either duration string. string, needs either \"dominant.epoch\" (default) guess based data, valid duration string, e.g., \"1 day\" \"10 sec\". na.rm Logical. missing values (NA) removed calculation? Defaults FALSE. .df Logical. data frame returned? TRUE, data frame single column named threshold_{comparison}_for_{duration} returned. Defaults FALSE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/threshold_for_duration.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find threshold for given duration — threshold_for_duration","text":"Single numeric value single column data frame.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/threshold_for_duration.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find threshold for given duration — threshold_for_duration","text":"","code":"N <- 60 # Dataset with 30 min < 250lx and 30min > 250lx dataset1 <-   tibble::tibble(     Id = rep(\"A\", N),     Datetime = lubridate::as_datetime(0) + lubridate::minutes(1:N),     MEDI = sample(c(sample(1:249, N / 2, replace = TRUE),                      sample(250:1000, N / 2, replace = TRUE))),   )  dataset1 %>%   dplyr::reframe(\"Threshold above which for 30 mins\" =                     threshold_for_duration(MEDI, Datetime, duration = \"30 mins\")) #> # A tibble: 1 × 1 #>   `Threshold above which for 30 mins` #>                                 <int> #> 1                                 291  dataset1 %>%   dplyr::reframe(\"Threshold below which for 30 mins\" =                     threshold_for_duration(MEDI, Datetime, duration = \"30 mins\",                                           comparison = \"below\")) #> # A tibble: 1 × 1 #>   `Threshold below which for 30 mins` #>                                 <int> #> 1                                 248  dataset1 %>%   dplyr::reframe(threshold_for_duration(MEDI, Datetime, duration = \"30 mins\",                                         as.df = TRUE)) #> # A tibble: 1 × 1 #>   threshold_above_for_30_minutes #>                            <int> #> 1                            291"},{"path":"https://tscnlab.github.io/LightLogR/reference/timing_above_threshold.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean/first/last timing above/below threshold. — timing_above_threshold","title":"Mean/first/last timing above/below threshold. — timing_above_threshold","text":"function calculates mean, first, last timepoint (MLiT, FLiT, LLiT) light levels given threshold intensity within given time interval.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/timing_above_threshold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean/first/last timing above/below threshold. — timing_above_threshold","text":"","code":"timing_above_threshold(   Light.vector,   Time.vector,   comparison = c(\"above\", \"below\"),   threshold,   na.rm = FALSE,   as.df = FALSE )"},{"path":"https://tscnlab.github.io/LightLogR/reference/timing_above_threshold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mean/first/last timing above/below threshold. — timing_above_threshold","text":"Light.vector Numeric vector containing light data. Time.vector Vector containing time data. Can POSIXct, hms, duration, difftime. comparison String specifying whether time threshold calculated. Can either \"\" (default) \"\". two values provided threshold, argument ignored. threshold Single numeric value two numeric values specifying threshold light level(s) compare . vector two values provided, timing corresponding light levels two thresholds calculated. na.rm Logical. missing values removed calculation? Defaults FALSE. .df Logical. data frame returned? TRUE, data frame three columns (MLiT, FLiT, LLiT) threshold (e.g., MLiT_{threshold}) returned. Defaults FALSE.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/timing_above_threshold.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean/first/last timing above/below threshold. — timing_above_threshold","text":"List dataframe three values: mean, first, last timing threshold. output type corresponds type Time.vector, e.g., Time.vector HMS, timing metrics also HMS, vice versa POSIXct numeric.","code":""},{"path":"https://tscnlab.github.io/LightLogR/reference/timing_above_threshold.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Mean/first/last timing above/below threshold. — timing_above_threshold","text":"Reid, K. J., Santostasi, G., Baron, K. G., Wilson, J., Kang, J., & Zee, P. C. (2014). Timing Intensity Light Correlate Body Weight Adults. PLOS ONE, 9(4), e92251. doi:10.1371/journal.pone.0092251 Hartmeyer, S.L., Andersen, M. (2023). Towards framework light-dosimetry studies: Quantification metrics. Lighting Research & Technology. doi:10.1177/14771535231170500","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/reference/timing_above_threshold.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mean/first/last timing above/below threshold. — timing_above_threshold","text":"","code":"# Dataset with light > 250lx between 06:00 and 18:00 dataset1 <-   tibble::tibble(     Id = rep(\"A\", 24),     Datetime = lubridate::as_datetime(0) + lubridate::hours(0:23),     MEDI = c(rep(1, 6), rep(250, 13), rep(1, 5))   )  # Above threshold dataset1 %>%   dplyr::reframe(timing_above_threshold(MEDI, Datetime, \"above\", 250, as.df = TRUE)) #> # A tibble: 1 × 3 #>   mean_timing_above_250 first_timing_above_250 last_timing_above_250 #>   <dttm>                <dttm>                 <dttm>                #> 1 1970-01-01 12:00:00   1970-01-01 06:00:00    1970-01-01 18:00:00    # Below threshold dataset1 %>%   dplyr::reframe(timing_above_threshold(MEDI, Datetime, \"below\", 10, as.df = TRUE)) #> # A tibble: 1 × 3 #>   mean_timing_below_10 first_timing_below_10 last_timing_below_10 #>   <dttm>               <dttm>                <dttm>               #> 1 1970-01-01 10:54:33  1970-01-01 00:00:00   1970-01-01 23:00:00   # Input = HMS -> Output = HMS dataset1 %>%   dplyr::reframe(timing_above_threshold(MEDI, hms::as_hms(Datetime), \"above\", 250, as.df = TRUE)) #> # A tibble: 1 × 3 #>   mean_timing_above_250 first_timing_above_250 last_timing_above_250 #>   <time>                <time>                 <time>                #> 1 12:00                 06:00                  18:00"},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-092","dir":"Changelog","previous_headings":"","what":"LightLogR 0.9.2","title":"LightLogR 0.9.2","text":"CRAN release: 2025-06-10","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-091","dir":"Changelog","previous_headings":"","what":"LightLogR 0.9.1","title":"LightLogR 0.9.1","text":"add_Date_col() new convenience function add Date column dataset, optionally showing weekday. Datetime2Time() new convenience function used functions average datetimes, often sensible times. reworked README file reflect features LightLogR gained time summarize_numeric() now calculates total_duration correctly, even prefix removed. added sample.data.irregular internal dataset removed LYS wearable sample file, due package size limitations add_Time_col() replaces create_Time_data(), also, new column called Time default instead Time.data extract_clusters() option show cluster condition output add.label = TRUE, e.g., MEDI>500|d≥30min|≤5min clusters melanopic EDI larger 500, least 30 minutes long (d), allowing interruptions 5 minutes time (). add_clusters() now drops empty groups, led warnings Added many unit tests - 888 counting! Removed nasty bug internal functions lead shift dominant epochs assigned durations groups dropped due singular observations gapless_datetimes(): fixed bug prohibited use durations. downstream effects basically gap functions extract_gaps() now warns correctly implicit gaps non-default epoch import option remove data specified date. Default .= 2001-01-01. devices fall back time stamp year 2000 battery drained completely. makes import problematic terms gap searching. extract_states() option group extracted state. extract_clusters() extract_states() drop empty groups, important summaries. extract_clusters() default, extract_states() . summarize_numeric() option show zero-instances groups. Helpful make certain groups zero instances dropped, especially chain mean_daily() mean_daily(): Automatic conversion weekdays dates. option replace NA zeros calculating mean daily values","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-090-sunrise","dir":"Changelog","previous_headings":"","what":"LightLogR 0.9.0 Sunrise","title":"LightLogR 0.9.0 Sunrise","text":"huge update LightLogR, bringing many new features twenty-two new functions","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"light-spectrum-0-9-0","dir":"Changelog","previous_headings":"New functions & datasets","what":"Light spectrum","title":"LightLogR 0.9.0 Sunrise","text":"spectral_reconstruction():reconstruct spectral power distribution (SPD) sensor channels provide (normalized) counts, calibration matrix. Examples devices include ActLumus Condor instruments, VEET Meta Reality labs (normalization counts, e.g., normalize_counts()) alphaopic.action.spectra: New dataset containing alphaopic action spectra (CIE S026) plus photopic action spectrum 1-nm wavelength steps. spectral_integration(): integrate just parts spectrum, including option weigh spectrum action spectrum (e.g., alphaopic.action.spectra)","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"missing-data-0-9-0","dir":"Changelog","previous_headings":"New functions & datasets","what":"Missing data","title":"LightLogR 0.9.0 Sunrise","text":"remove_partial_data(): remove groups user-specified amount data extract_gaps(): provides start end times, well durations gaps dataset. has_gaps(), has_irregulars(); provide logical feedback whether dataset (implicit) gaps irregular data. gap_table() provides comprehensive summary available missing data.","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"metrics-and-summaries-0-9-0","dir":"Changelog","previous_headings":"New functions & datasets","what":"Metrics and summaries","title":"LightLogR 0.9.0 Sunrise","text":"durations(): calculate groupwise duration dataset, based datapoints, dominant interval, missing data mean_daily() mean_daily_metric(): give three-row summary weekday, weekend, mean daily (numeric) values. mean_daily_metric() skips prior metric calculation duration-based metrics, directly calculates mean daily value. extract_clusters(), add_clusters(): find clusters user-specified condition either summarize add dataset. extract_states(), add_states(): provides summary every state dataset add dataset. extract_metric(): add calculation extracted data, extract_state() extract_clusters(). summarize_numeric()/summarise_numeric(): calculate means across numeric values, ideal summarize results extract_state(), extract_gaps(), extract_clusters. Brown_cut(): divide light exposure variables sections ≤1lx, ≤10lx, ≥250lx according Brown et al. 2022 log_zero_inflated() `exp_zero_inflated(): apply reverse logarithmic transformation adding small value vector provide zero values logarithmic transformation, especially important light exposure.","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"visualizations-0-9-0","dir":"Changelog","previous_headings":"New functions & datasets","what":"Visualizations","title":"LightLogR 0.9.0 Sunrise","text":"gg_gaps(): visualize gaps shows instances irregular data. gg_state(): addon-function gg_day() gg_days(), adds state cluster indicator plot gg_heatmap(): visualize condensed version time series patterns, optionally double plots.","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"misc-and-housekeeping-0-9-0","dir":"Changelog","previous_headings":"","what":"Misc and Housekeeping","title":"LightLogR 0.9.0 Sunrise","text":"Import support Clouclip device. number_states() added option just output count number without original state gg_days(): jco_color = TRUE now default","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"bug-fixes-0-9-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"LightLogR 0.9.0 Sunrise","text":"import_Dataset() longer changes pre-existing Id column (called Id). function also informative daylight savings time handling files one Id. gg_photoperiod() longer throw error main plots y.axis based MEDI column. gapless_Datetimes() now ignores groups single measurement, instead throwing error. function basis calculations regarding gaps.","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-054","dir":"Changelog","previous_headings":"","what":"LightLogR 0.5.4","title":"LightLogR 0.5.4","text":"changed behavior metric functions calculate -value (duration light 250 1000 lux). now, function use inclusive bounds sides, .e. value 250 lux 1000 lux included calculation. now changed right exclusive bounds, .e. value 250 lux still included calculation, whereas 1000 lux . little practical difference realistic dataset (exact values matching threshold likely present), relevant calculating, e.g., time spent various levels light variable. sum times always add total time. inclusive bounds sides, sum theoretically larger, right exclusive bounds . Metrics intradaily_variability() interdaily_stability() now use population variance (divide N), instead sample variance (divide N-1). legacy behavior can still accessed setting argument use.samplevar = TRUE. #55 Metric now correctly uses overall mean relation variance, instead mean hourly averages across days. #56","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-053","dir":"Changelog","previous_headings":"","what":"LightLogR 0.5.3","title":"LightLogR 0.5.3","text":"CRAN release: 2025-02-24 small cleanup changes CRAN submission","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-052","dir":"Changelog","previous_headings":"","what":"LightLogR 0.5.2","title":"LightLogR 0.5.2","text":"passed 300 unit tests LightLogR 🎉 normalize_counts() added low-level helper function accompanying dataset gain.ratio.tables facilitate calculating normalized sensor values comparing across different sensors, e.g. assess daylighting conditions based UV, IR, photopic sensing ranges. See documentation infos. Update import function GENEActiv devices, based input author GGIR package. timezone tz argument LightLogR now just set timestamp provided GGIR export, instead shifting datetime. requires correct setting desiredtz/configtz arguments GGIR preprocessing.","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-051","dir":"Changelog","previous_headings":"","what":"LightLogR 0.5.1","title":"LightLogR 0.5.1","text":"refinement cross-referencing tutorials photoperiod fixing bug photoperiod family functions using timezone large offset coordinates photoperiod calculated crosses date.","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-050-civil-dawn","dir":"Changelog","previous_headings":"","what":"LightLogR 0.5.0 “Civil dawn”","title":"LightLogR 0.5.0 “Civil dawn”","text":"added suite functions deal photoperiod: photoperiod() solar_noon() calculate dusk, dawn, noon times day. extract_photoperiod() add_photoperiod() utilize datasets imported LightLogR calculate deal photoperiods context datasets. gg_photoperiod() brings functionality visualization tools LightLogR easy powerful way. added function number_states() relabels states based non-consecutive appearance. especially useful labelling photoperiod states, function allow easy classifier “day 1”, “day 2”, …, “night 1”, “night 2”, …. can used , e.g., calculate metrics individual photoperiod sections throughout observed time frame. added tutorial new functions Photoperiod. also details calculate metrics based photoperiod (#39). implemented changes paper.md based JOSS Reviews","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-043","dir":"Changelog","previous_headings":"","what":"LightLogR 0.4.3","title":"LightLogR 0.4.3","text":"implemented changes based JOSS Reviews added Code Conduct Contributing file project","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-042","dir":"Changelog","previous_headings":"","what":"LightLogR 0.4.2","title":"LightLogR 0.4.2","text":"updated license MIT: LightLogR now permissively licensed import functions now give warning message identical observations provided data files, stop import process return tibble duplicate rows. remove_duplicates parameter, user can decide automatically remove duplicates import. Note: identical observations refers identical rows disregarding filename.","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-041","dir":"Changelog","previous_headings":"","what":"LightLogR 0.4.1","title":"LightLogR 0.4.1","text":"added support OcuWEAR devices added support MotionWatch 8 devices #32 added support LIMO devices added support GENEActiv devices, data preprocessed GGIR package. function import$GENEActiv_GGIR() takes GGIR output imports LightLogR naming schemes. #27","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-040-nautical-dawn","dir":"Changelog","previous_headings":"","what":"LightLogR 0.4.0 “Nautical dawn”","title":"LightLogR 0.4.0 “Nautical dawn”","text":"release CRAN! changed supported.devices list function supported_devices() instead, documentation automatically updates list supported devices. Similarly, ll_import_expr now ll_import_expr(). added support Meta VEET device visual experience measurements added support Kronowise device added support MPI melanopiQ Circadian Eye (Prototype) rewrote import function Actiwatch_Spectrum, sample file original based , specific formatting German standards. Now, German version can still called Actiwatch_Spectrum_de, wheras main function refers english/international format. updated landing page website list supported devices table metrics small changes documentation","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-038","dir":"Changelog","previous_headings":"","what":"LightLogR 0.3.8","title":"LightLogR 0.3.8","text":"CRAN release: 2024-07-04 Submission CRAN","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-037-astronomical-dawn","dir":"Changelog","previous_headings":"","what":"LightLogR 0.3.7 “Astronomical dawn”","title":"LightLogR 0.3.7 “Astronomical dawn”","text":"Changes tutorial articles website Integration community survey website Github Readme.","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-036","dir":"Changelog","previous_headings":"","what":"LightLogR 0.3.6","title":"LightLogR 0.3.6","text":"bright_dark_period() now maintains date looping data. Added articles Import & Cleaning, Metrics, Visualizations website. Added option print rows observation intervals import. Added option set length dataset starting end filter_Datetime() family.","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-035","dir":"Changelog","previous_headings":"","what":"LightLogR 0.3.5","title":"LightLogR 0.3.5","text":"Added function aggregate_Date() aggregate long datasets one day per group. New function gg_doubleplot() … well, double plots.","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-034","dir":"Changelog","previous_headings":"","what":"LightLogR 0.3.4","title":"LightLogR 0.3.4","text":"Backup Zenodo, DOI ","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-033","dir":"Changelog","previous_headings":"","what":"LightLogR 0.3.3","title":"LightLogR 0.3.3","text":"New updated metric functions. LightLogR now contains 16 metric families 60 sub-metrics.","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-032","dir":"Changelog","previous_headings":"","what":"LightLogR 0.3.2","title":"LightLogR 0.3.2","text":"added import functions nanoLambdaand LightWatcher devices new Logo!","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-031","dir":"Changelog","previous_headings":"","what":"LightLogR 0.3.1","title":"LightLogR 0.3.1","text":"fixed bug interval2state() dismiss first state starts actual data fixed bug interval2state() add columns State column present interval dataset output dataset, leave empty. Added example shows add multiple columns output dataset correctly. aggregate_Datetime(), added option set dominant.epoch, .e., common interval, unit parameter, effectively deal irregular data.","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-030","dir":"Changelog","previous_headings":"","what":"LightLogR 0.3.0","title":"LightLogR 0.3.0","text":"Added functions dst_change_summary() dst_change_handler() detect deal Daylight Savings. functionality also integrated import functions, user can automatically apply import process. Added Steffen Hartmeyer collaborator, added number light metrics lightdosimetry package. Added import_adjustment() function flexibility importing light logger data conform standard format. goes hand hand ll_import_expr list contains specific expressions supported devices. lots bug fixes improvements","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-022","dir":"Changelog","previous_headings":"","what":"LightLogR 0.2.2","title":"LightLogR 0.2.2","text":"Bugfix LiDo import Added import support new devices: LiDo, DeLux, Speccy Removed minor inconsistencies naming conventions. Also, imported columns syntactic naming now Added option gap functions, extend gapless Datetime range full days.","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-021","dir":"Changelog","previous_headings":"","what":"LightLogR 0.2.1","title":"LightLogR 0.2.1","text":"Exports now internal function count_difftime() basis dominant_epoch(). whereas latter gets common epoch, count_difftime() returns table counts epochs. useful conjunction gap_finder(), check distribution data intervals. Added gg_days() function visualize multiple days data single plot. Alongside come two helper functions, Datetime_limits() Datetime_breaks(), set limits breaks x-axis. Added filter_Datetime_multiple() function filter multiple Datetime ranges depending certain conditions, e.g. different filter cutoffs different participants. wraps around filter_Datetime() filter_Date(). Reworked internals light logger data import functions. now use straightforward function factory approach. users visible change device specific functions now form import$device() instead old import.device(). Added symlog_trans() function post stack overflow. function leads better visualization light logger data, logarithmic transformation necessary, values 0 common. function integrated default gg_day() likely basis upcoming visualization functions. Added aggregate_Datetime() function aggregate data given time interval. Added gg_overview() function get sense timeframe measurement data. Added family regularize functions find deal implicit missing data. functions include dominant_epoch(), gapless_Datetimes(), gap_handler(), gap_finder(). ton updates documentation, unit tests, bug fixes.","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-020","dir":"Changelog","previous_headings":"","what":"LightLogR 0.2.0","title":"LightLogR 0.2.0","text":"Added Unit tests documentation new functions. filter_Datetime() filter_Date() added option filter group specific dates. Added family functions around States Reference import, process, add states light logger data, like sleep/wake times, wear times, data. family includes import_Statechanges(), sc2interval(), ìnterval2state(), data2reference(), sleep_int2Brown(), Brown_check(), Brown_rec(), Brown2reference(). Added Article/Vignette “´s Day” demonstrate LightLogR workflow. Added convenience function create_Timedata() create Time--Day column datasets. Added family filter_Datetime(), filter_Date() filter_Time() functions easily filter datasets. Added unit tests first functions. Added several helper functions work states like sleep wear times. Added automatic ID creation import streamlined import functions. Added function join_datasets combine imported datasets sensible constraints.","code":""},{"path":[]},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"gg_day-0-1-1","dir":"Changelog","previous_headings":"","what":"gg_day():","title":"LightLogR 0.1.1","text":"Added major grid marks y-axis. Added message using start end dates make clear, Date portion input used. Changed behavior, already Day.data column present data. create new column none present, otherwise use existing column faceting (factorization) Added option create interactive plot feeding plot [plotly] package.","code":""},{"path":"https://tscnlab.github.io/LightLogR/news/index.html","id":"lightlogr-010","dir":"Changelog","previous_headings":"","what":"LightLogR 0.1.0","title":"LightLogR 0.1.0","text":"Added NEWS.md file track changes package.","code":""}]
